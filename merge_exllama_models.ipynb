{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors import safe_open\n",
    "from safetensors.torch import save_file, save_model\n",
    "from pprint import pprint\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['lm_head.q_groups', 'lm_head.q_invperm', 'lm_head.q_scale', 'lm_head.q_scale_max', 'lm_head.q_weight', 'model.layers.78.mlp.down_proj.q_weight', 'model.layers.79.input_layernorm.weight', 'model.layers.79.mlp.down_proj.q_groups', 'model.layers.79.mlp.down_proj.q_invperm', 'model.layers.79.mlp.down_proj.q_scale', 'model.layers.79.mlp.down_proj.q_scale_max', 'model.layers.79.mlp.down_proj.q_weight', 'model.layers.79.mlp.gate_proj.q_groups', 'model.layers.79.mlp.gate_proj.q_invperm', 'model.layers.79.mlp.gate_proj.q_scale', 'model.layers.79.mlp.gate_proj.q_scale_max', 'model.layers.79.mlp.gate_proj.q_weight', 'model.layers.79.mlp.up_proj.q_groups', 'model.layers.79.mlp.up_proj.q_invperm', 'model.layers.79.mlp.up_proj.q_scale', 'model.layers.79.mlp.up_proj.q_scale_max', 'model.layers.79.mlp.up_proj.q_weight', 'model.layers.79.post_attention_layernorm.weight', 'model.layers.79.self_attn.k_proj.q_groups', 'model.layers.79.self_attn.k_proj.q_invperm', 'model.layers.79.self_attn.k_proj.q_scale', 'model.layers.79.self_attn.k_proj.q_scale_max', 'model.layers.79.self_attn.k_proj.q_weight', 'model.layers.79.self_attn.o_proj.q_groups', 'model.layers.79.self_attn.o_proj.q_invperm', 'model.layers.79.self_attn.o_proj.q_scale', 'model.layers.79.self_attn.o_proj.q_scale_max', 'model.layers.79.self_attn.o_proj.q_weight', 'model.layers.79.self_attn.q_proj.q_groups', 'model.layers.79.self_attn.q_proj.q_invperm', 'model.layers.79.self_attn.q_proj.q_scale', 'model.layers.79.self_attn.q_proj.q_scale_max', 'model.layers.79.self_attn.q_proj.q_weight', 'model.layers.79.self_attn.v_proj.q_groups', 'model.layers.79.self_attn.v_proj.q_invperm', 'model.layers.79.self_attn.v_proj.q_scale', 'model.layers.79.self_attn.v_proj.q_scale_max', 'model.layers.79.self_attn.v_proj.q_weight', 'model.norm.weight'])\n"
     ]
    }
   ],
   "source": [
    "tensors = {}\n",
    "with safe_open(\"/home/dnhkng/Documents/models/miqu-1-70b-sf-4.0bpw-h6-exl2/model-00005-of-00005.safetensors\", framework=\"pt\", device=0) as f:\n",
    "    for k in f.keys():\n",
    "        tensors[k] = f.get_tensor(k) # loads the full tensor given a key\n",
    "print(tensors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layerNames = list(tensors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lm_head.q_groups',\n",
      " 'lm_head.q_invperm',\n",
      " 'lm_head.q_scale',\n",
      " 'lm_head.q_scale_max',\n",
      " 'lm_head.q_weight',\n",
      " 'model.layers.78.mlp.down_proj.q_weight',\n",
      " 'model.layers.79.input_layernorm.weight',\n",
      " 'model.layers.79.mlp.down_proj.q_groups',\n",
      " 'model.layers.79.mlp.down_proj.q_invperm',\n",
      " 'model.layers.79.mlp.down_proj.q_scale',\n",
      " 'model.layers.79.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.79.mlp.down_proj.q_weight',\n",
      " 'model.layers.79.mlp.gate_proj.q_groups',\n",
      " 'model.layers.79.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.79.mlp.gate_proj.q_scale',\n",
      " 'model.layers.79.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.79.mlp.gate_proj.q_weight',\n",
      " 'model.layers.79.mlp.up_proj.q_groups',\n",
      " 'model.layers.79.mlp.up_proj.q_invperm',\n",
      " 'model.layers.79.mlp.up_proj.q_scale',\n",
      " 'model.layers.79.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.79.mlp.up_proj.q_weight',\n",
      " 'model.layers.79.post_attention_layernorm.weight',\n",
      " 'model.layers.79.self_attn.k_proj.q_groups',\n",
      " 'model.layers.79.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.79.self_attn.k_proj.q_scale',\n",
      " 'model.layers.79.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.79.self_attn.k_proj.q_weight',\n",
      " 'model.layers.79.self_attn.o_proj.q_groups',\n",
      " 'model.layers.79.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.79.self_attn.o_proj.q_scale',\n",
      " 'model.layers.79.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.79.self_attn.o_proj.q_weight',\n",
      " 'model.layers.79.self_attn.q_proj.q_groups',\n",
      " 'model.layers.79.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.79.self_attn.q_proj.q_scale',\n",
      " 'model.layers.79.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.79.self_attn.q_proj.q_weight',\n",
      " 'model.layers.79.self_attn.v_proj.q_groups',\n",
      " 'model.layers.79.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.79.self_attn.v_proj.q_scale',\n",
      " 'model.layers.79.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.79.self_attn.v_proj.q_weight',\n",
      " 'model.norm.weight']\n"
     ]
    }
   ],
   "source": [
    "pprint(layerNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.10.input_layernorm.weight\n",
      "model.layers.10.mlp.down_proj.q_groups\n",
      "model.layers.10.mlp.down_proj.q_invperm\n",
      "model.layers.10.mlp.down_proj.q_scale\n",
      "model.layers.10.mlp.down_proj.q_scale_max\n",
      "model.layers.10.mlp.down_proj.q_weight\n",
      "model.layers.10.mlp.gate_proj.q_groups\n",
      "model.layers.10.mlp.gate_proj.q_invperm\n",
      "model.layers.10.mlp.gate_proj.q_scale\n",
      "model.layers.10.mlp.gate_proj.q_scale_max\n",
      "model.layers.10.mlp.gate_proj.q_weight\n",
      "model.layers.10.mlp.up_proj.q_groups\n",
      "model.layers.10.mlp.up_proj.q_invperm\n",
      "model.layers.10.mlp.up_proj.q_scale\n",
      "model.layers.10.mlp.up_proj.q_scale_max\n",
      "model.layers.10.mlp.up_proj.q_weight\n",
      "model.layers.10.post_attention_layernorm.weight\n",
      "model.layers.10.self_attn.k_proj.q_groups\n",
      "model.layers.10.self_attn.k_proj.q_invperm\n",
      "model.layers.10.self_attn.k_proj.q_scale\n",
      "model.layers.10.self_attn.k_proj.q_scale_max\n",
      "model.layers.10.self_attn.k_proj.q_weight\n",
      "model.layers.10.self_attn.o_proj.q_groups\n",
      "model.layers.10.self_attn.o_proj.q_invperm\n",
      "model.layers.10.self_attn.o_proj.q_scale\n",
      "model.layers.10.self_attn.o_proj.q_scale_max\n",
      "model.layers.10.self_attn.o_proj.q_weight\n",
      "model.layers.10.self_attn.q_proj.q_groups\n",
      "model.layers.10.self_attn.q_proj.q_invperm\n",
      "model.layers.10.self_attn.q_proj.q_scale\n",
      "model.layers.10.self_attn.q_proj.q_scale_max\n",
      "model.layers.10.self_attn.q_proj.q_weight\n",
      "model.layers.10.self_attn.v_proj.q_groups\n",
      "model.layers.10.self_attn.v_proj.q_invperm\n",
      "model.layers.10.self_attn.v_proj.q_scale\n",
      "model.layers.10.self_attn.v_proj.q_scale_max\n",
      "model.layers.10.self_attn.v_proj.q_weight\n",
      "model.layers.11.input_layernorm.weight\n",
      "model.layers.11.mlp.down_proj.q_groups\n",
      "model.layers.11.mlp.down_proj.q_invperm\n",
      "model.layers.11.mlp.down_proj.q_scale\n",
      "model.layers.11.mlp.down_proj.q_scale_max\n",
      "model.layers.11.mlp.down_proj.q_weight\n",
      "model.layers.11.mlp.gate_proj.q_groups\n",
      "model.layers.11.mlp.gate_proj.q_invperm\n",
      "model.layers.11.mlp.gate_proj.q_scale\n",
      "model.layers.11.mlp.gate_proj.q_scale_max\n",
      "model.layers.11.mlp.gate_proj.q_weight\n",
      "model.layers.11.mlp.up_proj.q_groups\n",
      "model.layers.11.mlp.up_proj.q_invperm\n",
      "model.layers.11.mlp.up_proj.q_scale\n",
      "model.layers.11.mlp.up_proj.q_scale_max\n",
      "model.layers.11.mlp.up_proj.q_weight\n",
      "model.layers.11.post_attention_layernorm.weight\n",
      "model.layers.11.self_attn.k_proj.q_groups\n",
      "model.layers.11.self_attn.k_proj.q_invperm\n",
      "model.layers.11.self_attn.k_proj.q_scale\n",
      "model.layers.11.self_attn.k_proj.q_scale_max\n",
      "model.layers.11.self_attn.k_proj.q_weight\n",
      "model.layers.11.self_attn.o_proj.q_groups\n",
      "model.layers.11.self_attn.o_proj.q_invperm\n",
      "model.layers.11.self_attn.o_proj.q_scale\n",
      "model.layers.11.self_attn.o_proj.q_scale_max\n",
      "model.layers.11.self_attn.o_proj.q_weight\n",
      "model.layers.11.self_attn.q_proj.q_groups\n",
      "model.layers.11.self_attn.q_proj.q_invperm\n",
      "model.layers.11.self_attn.q_proj.q_scale\n",
      "model.layers.11.self_attn.q_proj.q_scale_max\n",
      "model.layers.11.self_attn.q_proj.q_weight\n",
      "model.layers.11.self_attn.v_proj.q_groups\n",
      "model.layers.11.self_attn.v_proj.q_invperm\n",
      "model.layers.11.self_attn.v_proj.q_scale\n",
      "model.layers.11.self_attn.v_proj.q_scale_max\n",
      "model.layers.11.self_attn.v_proj.q_weight\n",
      "model.layers.12.input_layernorm.weight\n",
      "model.layers.12.mlp.down_proj.q_groups\n",
      "model.layers.12.mlp.down_proj.q_invperm\n",
      "model.layers.12.mlp.down_proj.q_scale\n",
      "model.layers.12.mlp.down_proj.q_scale_max\n",
      "model.layers.12.mlp.down_proj.q_weight\n",
      "model.layers.12.mlp.gate_proj.q_groups\n",
      "model.layers.12.mlp.gate_proj.q_invperm\n",
      "model.layers.12.mlp.gate_proj.q_scale\n",
      "model.layers.12.mlp.gate_proj.q_scale_max\n",
      "model.layers.12.mlp.gate_proj.q_weight\n",
      "model.layers.12.mlp.up_proj.q_groups\n",
      "model.layers.12.mlp.up_proj.q_invperm\n",
      "model.layers.12.mlp.up_proj.q_scale\n",
      "model.layers.12.mlp.up_proj.q_scale_max\n",
      "model.layers.12.mlp.up_proj.q_weight\n",
      "model.layers.12.post_attention_layernorm.weight\n",
      "model.layers.12.self_attn.k_proj.q_groups\n",
      "model.layers.12.self_attn.k_proj.q_invperm\n",
      "model.layers.12.self_attn.k_proj.q_scale\n",
      "model.layers.12.self_attn.k_proj.q_scale_max\n",
      "model.layers.12.self_attn.k_proj.q_weight\n",
      "model.layers.12.self_attn.o_proj.q_groups\n",
      "model.layers.12.self_attn.o_proj.q_invperm\n",
      "model.layers.12.self_attn.o_proj.q_scale\n",
      "model.layers.12.self_attn.o_proj.q_scale_max\n",
      "model.layers.12.self_attn.o_proj.q_weight\n",
      "model.layers.12.self_attn.q_proj.q_groups\n",
      "model.layers.12.self_attn.q_proj.q_invperm\n",
      "model.layers.12.self_attn.q_proj.q_scale\n",
      "model.layers.12.self_attn.q_proj.q_scale_max\n",
      "model.layers.12.self_attn.q_proj.q_weight\n",
      "model.layers.12.self_attn.v_proj.q_groups\n",
      "model.layers.12.self_attn.v_proj.q_invperm\n",
      "model.layers.12.self_attn.v_proj.q_scale\n",
      "model.layers.12.self_attn.v_proj.q_scale_max\n",
      "model.layers.12.self_attn.v_proj.q_weight\n",
      "model.layers.13.input_layernorm.weight\n",
      "model.layers.13.mlp.down_proj.q_groups\n",
      "model.layers.13.mlp.down_proj.q_invperm\n",
      "model.layers.13.mlp.down_proj.q_scale\n",
      "model.layers.13.mlp.down_proj.q_scale_max\n",
      "model.layers.13.mlp.down_proj.q_weight\n",
      "model.layers.13.mlp.gate_proj.q_groups\n",
      "model.layers.13.mlp.gate_proj.q_invperm\n",
      "model.layers.13.mlp.gate_proj.q_scale\n",
      "model.layers.13.mlp.gate_proj.q_scale_max\n",
      "model.layers.13.mlp.gate_proj.q_weight\n",
      "model.layers.13.mlp.up_proj.q_groups\n",
      "model.layers.13.mlp.up_proj.q_invperm\n",
      "model.layers.13.mlp.up_proj.q_scale\n",
      "model.layers.13.mlp.up_proj.q_scale_max\n",
      "model.layers.13.mlp.up_proj.q_weight\n",
      "model.layers.13.post_attention_layernorm.weight\n",
      "model.layers.13.self_attn.k_proj.q_groups\n",
      "model.layers.13.self_attn.k_proj.q_invperm\n",
      "model.layers.13.self_attn.k_proj.q_scale\n",
      "model.layers.13.self_attn.k_proj.q_scale_max\n",
      "model.layers.13.self_attn.k_proj.q_weight\n",
      "model.layers.13.self_attn.o_proj.q_groups\n",
      "model.layers.13.self_attn.o_proj.q_invperm\n",
      "model.layers.13.self_attn.o_proj.q_scale\n",
      "model.layers.13.self_attn.o_proj.q_scale_max\n",
      "model.layers.13.self_attn.o_proj.q_weight\n",
      "model.layers.13.self_attn.q_proj.q_groups\n",
      "model.layers.13.self_attn.q_proj.q_invperm\n",
      "model.layers.13.self_attn.q_proj.q_scale\n",
      "model.layers.13.self_attn.q_proj.q_scale_max\n",
      "model.layers.13.self_attn.q_proj.q_weight\n",
      "model.layers.13.self_attn.v_proj.q_groups\n",
      "model.layers.13.self_attn.v_proj.q_invperm\n",
      "model.layers.13.self_attn.v_proj.q_scale\n",
      "model.layers.13.self_attn.v_proj.q_scale_max\n",
      "model.layers.13.self_attn.v_proj.q_weight\n",
      "model.layers.14.input_layernorm.weight\n",
      "model.layers.14.mlp.down_proj.q_groups\n",
      "model.layers.14.mlp.down_proj.q_invperm\n",
      "model.layers.14.mlp.down_proj.q_scale\n",
      "model.layers.14.mlp.down_proj.q_scale_max\n",
      "model.layers.14.mlp.down_proj.q_weight\n",
      "model.layers.14.mlp.gate_proj.q_groups\n",
      "model.layers.14.mlp.gate_proj.q_invperm\n",
      "model.layers.14.mlp.gate_proj.q_scale\n",
      "model.layers.14.mlp.gate_proj.q_scale_max\n",
      "model.layers.14.mlp.gate_proj.q_weight\n",
      "model.layers.14.mlp.up_proj.q_groups\n",
      "model.layers.14.mlp.up_proj.q_invperm\n",
      "model.layers.14.mlp.up_proj.q_scale\n",
      "model.layers.14.mlp.up_proj.q_scale_max\n",
      "model.layers.14.mlp.up_proj.q_weight\n",
      "model.layers.14.post_attention_layernorm.weight\n",
      "model.layers.14.self_attn.k_proj.q_groups\n",
      "model.layers.14.self_attn.k_proj.q_invperm\n",
      "model.layers.14.self_attn.k_proj.q_scale\n",
      "model.layers.14.self_attn.k_proj.q_scale_max\n",
      "model.layers.14.self_attn.k_proj.q_weight\n",
      "model.layers.14.self_attn.o_proj.q_groups\n",
      "model.layers.14.self_attn.o_proj.q_invperm\n",
      "model.layers.14.self_attn.o_proj.q_scale\n",
      "model.layers.14.self_attn.o_proj.q_scale_max\n",
      "model.layers.14.self_attn.o_proj.q_weight\n",
      "model.layers.14.self_attn.q_proj.q_groups\n",
      "model.layers.14.self_attn.q_proj.q_invperm\n",
      "model.layers.14.self_attn.q_proj.q_scale\n",
      "model.layers.14.self_attn.q_proj.q_scale_max\n",
      "model.layers.14.self_attn.q_proj.q_weight\n",
      "model.layers.14.self_attn.v_proj.q_groups\n",
      "model.layers.14.self_attn.v_proj.q_invperm\n",
      "model.layers.14.self_attn.v_proj.q_scale\n",
      "model.layers.14.self_attn.v_proj.q_scale_max\n",
      "model.layers.14.self_attn.v_proj.q_weight\n",
      "model.layers.15.input_layernorm.weight\n",
      "model.layers.15.mlp.down_proj.q_groups\n",
      "model.layers.15.mlp.down_proj.q_invperm\n",
      "model.layers.15.mlp.down_proj.q_scale\n",
      "model.layers.15.mlp.down_proj.q_scale_max\n",
      "model.layers.15.mlp.down_proj.q_weight\n",
      "model.layers.15.mlp.gate_proj.q_groups\n",
      "model.layers.15.mlp.gate_proj.q_invperm\n",
      "model.layers.15.mlp.gate_proj.q_scale\n",
      "model.layers.15.mlp.gate_proj.q_scale_max\n",
      "model.layers.15.mlp.gate_proj.q_weight\n",
      "model.layers.15.mlp.up_proj.q_groups\n",
      "model.layers.15.mlp.up_proj.q_invperm\n",
      "model.layers.15.mlp.up_proj.q_scale\n",
      "model.layers.15.mlp.up_proj.q_scale_max\n",
      "model.layers.15.mlp.up_proj.q_weight\n",
      "model.layers.15.post_attention_layernorm.weight\n",
      "model.layers.15.self_attn.k_proj.q_groups\n",
      "model.layers.15.self_attn.k_proj.q_invperm\n",
      "model.layers.15.self_attn.k_proj.q_scale\n",
      "model.layers.15.self_attn.k_proj.q_scale_max\n",
      "model.layers.15.self_attn.k_proj.q_weight\n",
      "model.layers.15.self_attn.o_proj.q_groups\n",
      "model.layers.15.self_attn.o_proj.q_invperm\n",
      "model.layers.15.self_attn.o_proj.q_scale\n",
      "model.layers.15.self_attn.o_proj.q_scale_max\n",
      "model.layers.15.self_attn.o_proj.q_weight\n",
      "model.layers.15.self_attn.q_proj.q_groups\n",
      "model.layers.15.self_attn.q_proj.q_invperm\n",
      "model.layers.15.self_attn.q_proj.q_scale\n",
      "model.layers.15.self_attn.q_proj.q_scale_max\n",
      "model.layers.15.self_attn.q_proj.q_weight\n",
      "model.layers.15.self_attn.v_proj.q_groups\n",
      "model.layers.15.self_attn.v_proj.q_invperm\n",
      "model.layers.15.self_attn.v_proj.q_scale\n",
      "model.layers.15.self_attn.v_proj.q_scale_max\n",
      "model.layers.15.self_attn.v_proj.q_weight\n",
      "model.layers.16.input_layernorm.weight\n",
      "model.layers.16.mlp.down_proj.q_groups\n",
      "model.layers.16.mlp.down_proj.q_invperm\n",
      "model.layers.16.mlp.down_proj.q_scale\n",
      "model.layers.16.mlp.down_proj.q_scale_max\n",
      "model.layers.16.mlp.down_proj.q_weight\n",
      "model.layers.16.mlp.gate_proj.q_groups\n",
      "model.layers.16.mlp.gate_proj.q_invperm\n",
      "model.layers.16.mlp.gate_proj.q_scale\n",
      "model.layers.16.mlp.gate_proj.q_scale_max\n",
      "model.layers.16.mlp.gate_proj.q_weight\n",
      "model.layers.16.mlp.up_proj.q_groups\n",
      "model.layers.16.mlp.up_proj.q_invperm\n",
      "model.layers.16.mlp.up_proj.q_scale\n",
      "model.layers.16.mlp.up_proj.q_scale_max\n",
      "model.layers.16.mlp.up_proj.q_weight\n",
      "model.layers.16.post_attention_layernorm.weight\n",
      "model.layers.16.self_attn.k_proj.q_groups\n",
      "model.layers.16.self_attn.k_proj.q_invperm\n",
      "model.layers.16.self_attn.k_proj.q_scale\n",
      "model.layers.16.self_attn.k_proj.q_scale_max\n",
      "model.layers.16.self_attn.k_proj.q_weight\n",
      "model.layers.16.self_attn.o_proj.q_groups\n",
      "model.layers.16.self_attn.o_proj.q_invperm\n",
      "model.layers.16.self_attn.o_proj.q_scale\n",
      "model.layers.16.self_attn.o_proj.q_scale_max\n",
      "model.layers.16.self_attn.o_proj.q_weight\n",
      "model.layers.16.self_attn.q_proj.q_groups\n",
      "model.layers.16.self_attn.q_proj.q_invperm\n",
      "model.layers.16.self_attn.q_proj.q_scale\n",
      "model.layers.16.self_attn.q_proj.q_scale_max\n",
      "model.layers.16.self_attn.q_proj.q_weight\n",
      "model.layers.16.self_attn.v_proj.q_groups\n",
      "model.layers.16.self_attn.v_proj.q_invperm\n",
      "model.layers.16.self_attn.v_proj.q_scale\n",
      "model.layers.16.self_attn.v_proj.q_scale_max\n",
      "model.layers.16.self_attn.v_proj.q_weight\n",
      "model.layers.17.input_layernorm.weight\n",
      "model.layers.17.mlp.down_proj.q_groups\n",
      "model.layers.17.mlp.down_proj.q_invperm\n",
      "model.layers.17.mlp.down_proj.q_scale\n",
      "model.layers.17.mlp.down_proj.q_scale_max\n",
      "model.layers.17.mlp.down_proj.q_weight\n",
      "model.layers.17.mlp.gate_proj.q_groups\n",
      "model.layers.17.mlp.gate_proj.q_invperm\n",
      "model.layers.17.mlp.gate_proj.q_scale\n",
      "model.layers.17.mlp.gate_proj.q_scale_max\n",
      "model.layers.17.mlp.gate_proj.q_weight\n",
      "model.layers.17.mlp.up_proj.q_groups\n",
      "model.layers.17.mlp.up_proj.q_invperm\n",
      "model.layers.17.mlp.up_proj.q_scale\n",
      "model.layers.17.mlp.up_proj.q_scale_max\n",
      "model.layers.17.mlp.up_proj.q_weight\n",
      "model.layers.17.post_attention_layernorm.weight\n",
      "model.layers.17.self_attn.k_proj.q_groups\n",
      "model.layers.17.self_attn.k_proj.q_invperm\n",
      "model.layers.17.self_attn.k_proj.q_scale\n",
      "model.layers.17.self_attn.k_proj.q_scale_max\n",
      "model.layers.17.self_attn.k_proj.q_weight\n",
      "model.layers.17.self_attn.o_proj.q_groups\n",
      "model.layers.17.self_attn.o_proj.q_invperm\n",
      "model.layers.17.self_attn.o_proj.q_scale\n",
      "model.layers.17.self_attn.o_proj.q_scale_max\n",
      "model.layers.17.self_attn.o_proj.q_weight\n",
      "model.layers.17.self_attn.q_proj.q_groups\n",
      "model.layers.17.self_attn.q_proj.q_invperm\n",
      "model.layers.17.self_attn.q_proj.q_scale\n",
      "model.layers.17.self_attn.q_proj.q_scale_max\n",
      "model.layers.17.self_attn.q_proj.q_weight\n",
      "model.layers.17.self_attn.v_proj.q_groups\n",
      "model.layers.17.self_attn.v_proj.q_invperm\n",
      "model.layers.17.self_attn.v_proj.q_scale\n",
      "model.layers.17.self_attn.v_proj.q_scale_max\n",
      "model.layers.17.self_attn.v_proj.q_weight\n",
      "model.layers.18.input_layernorm.weight\n",
      "model.layers.18.mlp.down_proj.q_groups\n",
      "model.layers.18.mlp.down_proj.q_invperm\n",
      "model.layers.18.mlp.down_proj.q_scale\n",
      "model.layers.18.mlp.down_proj.q_scale_max\n",
      "model.layers.18.mlp.down_proj.q_weight\n",
      "model.layers.18.mlp.gate_proj.q_groups\n",
      "model.layers.18.mlp.gate_proj.q_invperm\n",
      "model.layers.18.mlp.gate_proj.q_scale\n",
      "model.layers.18.mlp.gate_proj.q_scale_max\n",
      "model.layers.18.mlp.gate_proj.q_weight\n",
      "model.layers.18.mlp.up_proj.q_groups\n",
      "model.layers.18.mlp.up_proj.q_invperm\n",
      "model.layers.18.mlp.up_proj.q_scale\n",
      "model.layers.18.mlp.up_proj.q_scale_max\n",
      "model.layers.18.mlp.up_proj.q_weight\n",
      "model.layers.18.post_attention_layernorm.weight\n",
      "model.layers.18.self_attn.k_proj.q_groups\n",
      "model.layers.18.self_attn.k_proj.q_invperm\n",
      "model.layers.18.self_attn.k_proj.q_scale\n",
      "model.layers.18.self_attn.k_proj.q_scale_max\n",
      "model.layers.18.self_attn.k_proj.q_weight\n",
      "model.layers.18.self_attn.o_proj.q_groups\n",
      "model.layers.18.self_attn.o_proj.q_invperm\n",
      "model.layers.18.self_attn.o_proj.q_scale\n",
      "model.layers.18.self_attn.o_proj.q_scale_max\n",
      "model.layers.18.self_attn.o_proj.q_weight\n",
      "model.layers.18.self_attn.q_proj.q_groups\n",
      "model.layers.18.self_attn.q_proj.q_invperm\n",
      "model.layers.18.self_attn.q_proj.q_scale\n",
      "model.layers.18.self_attn.q_proj.q_scale_max\n",
      "model.layers.18.self_attn.q_proj.q_weight\n",
      "model.layers.18.self_attn.v_proj.q_groups\n",
      "model.layers.18.self_attn.v_proj.q_invperm\n",
      "model.layers.18.self_attn.v_proj.q_scale\n",
      "model.layers.18.self_attn.v_proj.q_scale_max\n",
      "model.layers.18.self_attn.v_proj.q_weight\n",
      "model.layers.19.input_layernorm.weight\n",
      "model.layers.19.mlp.down_proj.q_groups\n",
      "model.layers.19.mlp.down_proj.q_invperm\n",
      "model.layers.19.mlp.down_proj.q_scale\n",
      "model.layers.19.mlp.down_proj.q_scale_max\n",
      "model.layers.19.mlp.down_proj.q_weight\n",
      "model.layers.19.mlp.gate_proj.q_groups\n",
      "model.layers.19.mlp.gate_proj.q_invperm\n",
      "model.layers.19.mlp.gate_proj.q_scale\n",
      "model.layers.19.mlp.gate_proj.q_scale_max\n",
      "model.layers.19.mlp.gate_proj.q_weight\n",
      "model.layers.19.mlp.up_proj.q_groups\n",
      "model.layers.19.mlp.up_proj.q_invperm\n",
      "model.layers.19.mlp.up_proj.q_scale\n",
      "model.layers.19.mlp.up_proj.q_scale_max\n",
      "model.layers.19.mlp.up_proj.q_weight\n",
      "model.layers.19.post_attention_layernorm.weight\n",
      "model.layers.19.self_attn.k_proj.q_groups\n",
      "model.layers.19.self_attn.k_proj.q_invperm\n",
      "model.layers.19.self_attn.k_proj.q_scale\n",
      "model.layers.19.self_attn.k_proj.q_scale_max\n",
      "model.layers.19.self_attn.k_proj.q_weight\n",
      "model.layers.19.self_attn.o_proj.q_groups\n",
      "model.layers.19.self_attn.o_proj.q_invperm\n",
      "model.layers.19.self_attn.o_proj.q_scale\n",
      "model.layers.19.self_attn.o_proj.q_scale_max\n",
      "model.layers.19.self_attn.o_proj.q_weight\n",
      "model.layers.19.self_attn.q_proj.q_groups\n",
      "model.layers.19.self_attn.q_proj.q_invperm\n",
      "model.layers.19.self_attn.q_proj.q_scale\n",
      "model.layers.19.self_attn.q_proj.q_scale_max\n",
      "model.layers.19.self_attn.q_proj.q_weight\n",
      "model.layers.19.self_attn.v_proj.q_groups\n",
      "model.layers.19.self_attn.v_proj.q_invperm\n",
      "model.layers.19.self_attn.v_proj.q_scale\n",
      "model.layers.19.self_attn.v_proj.q_scale_max\n",
      "model.layers.19.self_attn.v_proj.q_weight\n",
      "model.layers.20.input_layernorm.weight\n",
      "model.layers.20.mlp.down_proj.q_groups\n",
      "model.layers.20.mlp.down_proj.q_invperm\n",
      "model.layers.20.mlp.down_proj.q_scale\n",
      "model.layers.20.mlp.down_proj.q_scale_max\n",
      "model.layers.20.mlp.down_proj.q_weight\n",
      "model.layers.20.mlp.gate_proj.q_groups\n",
      "model.layers.20.mlp.gate_proj.q_invperm\n",
      "model.layers.20.mlp.gate_proj.q_scale\n",
      "model.layers.20.mlp.gate_proj.q_scale_max\n",
      "model.layers.20.mlp.gate_proj.q_weight\n",
      "model.layers.20.mlp.up_proj.q_groups\n",
      "model.layers.20.mlp.up_proj.q_invperm\n",
      "model.layers.20.mlp.up_proj.q_scale\n",
      "model.layers.20.mlp.up_proj.q_scale_max\n",
      "model.layers.20.mlp.up_proj.q_weight\n",
      "model.layers.20.post_attention_layernorm.weight\n",
      "model.layers.20.self_attn.k_proj.q_groups\n",
      "model.layers.20.self_attn.k_proj.q_invperm\n",
      "model.layers.20.self_attn.k_proj.q_scale\n",
      "model.layers.20.self_attn.k_proj.q_scale_max\n",
      "model.layers.20.self_attn.k_proj.q_weight\n",
      "model.layers.20.self_attn.o_proj.q_groups\n",
      "model.layers.20.self_attn.o_proj.q_invperm\n",
      "model.layers.20.self_attn.o_proj.q_scale\n",
      "model.layers.20.self_attn.o_proj.q_scale_max\n",
      "model.layers.20.self_attn.o_proj.q_weight\n",
      "model.layers.20.self_attn.q_proj.q_groups\n",
      "model.layers.20.self_attn.q_proj.q_invperm\n",
      "model.layers.20.self_attn.q_proj.q_scale\n",
      "model.layers.20.self_attn.q_proj.q_scale_max\n",
      "model.layers.20.self_attn.q_proj.q_weight\n",
      "model.layers.20.self_attn.v_proj.q_groups\n",
      "model.layers.20.self_attn.v_proj.q_invperm\n",
      "model.layers.20.self_attn.v_proj.q_scale\n",
      "model.layers.20.self_attn.v_proj.q_scale_max\n",
      "model.layers.20.self_attn.v_proj.q_weight\n",
      "model.layers.21.input_layernorm.weight\n",
      "model.layers.21.mlp.down_proj.q_groups\n",
      "model.layers.21.mlp.down_proj.q_invperm\n",
      "model.layers.21.mlp.down_proj.q_scale\n",
      "model.layers.21.mlp.down_proj.q_scale_max\n",
      "model.layers.21.mlp.down_proj.q_weight\n",
      "model.layers.21.mlp.gate_proj.q_groups\n",
      "model.layers.21.mlp.gate_proj.q_invperm\n",
      "model.layers.21.mlp.gate_proj.q_scale\n",
      "model.layers.21.mlp.gate_proj.q_scale_max\n",
      "model.layers.21.mlp.gate_proj.q_weight\n",
      "model.layers.21.mlp.up_proj.q_groups\n",
      "model.layers.21.mlp.up_proj.q_invperm\n",
      "model.layers.21.mlp.up_proj.q_scale\n",
      "model.layers.21.mlp.up_proj.q_scale_max\n",
      "model.layers.21.mlp.up_proj.q_weight\n",
      "model.layers.21.post_attention_layernorm.weight\n",
      "model.layers.21.self_attn.k_proj.q_groups\n",
      "model.layers.21.self_attn.k_proj.q_invperm\n",
      "model.layers.21.self_attn.k_proj.q_scale\n",
      "model.layers.21.self_attn.k_proj.q_scale_max\n",
      "model.layers.21.self_attn.k_proj.q_weight\n",
      "model.layers.21.self_attn.o_proj.q_groups\n",
      "model.layers.21.self_attn.o_proj.q_invperm\n",
      "model.layers.21.self_attn.o_proj.q_scale\n",
      "model.layers.21.self_attn.o_proj.q_scale_max\n",
      "model.layers.21.self_attn.o_proj.q_weight\n",
      "model.layers.21.self_attn.q_proj.q_groups\n",
      "model.layers.21.self_attn.q_proj.q_invperm\n",
      "model.layers.21.self_attn.q_proj.q_scale\n",
      "model.layers.21.self_attn.q_proj.q_scale_max\n",
      "model.layers.21.self_attn.q_proj.q_weight\n",
      "model.layers.21.self_attn.v_proj.q_groups\n",
      "model.layers.21.self_attn.v_proj.q_invperm\n",
      "model.layers.21.self_attn.v_proj.q_scale\n",
      "model.layers.21.self_attn.v_proj.q_scale_max\n",
      "model.layers.21.self_attn.v_proj.q_weight\n",
      "model.layers.22.input_layernorm.weight\n",
      "model.layers.22.mlp.down_proj.q_groups\n",
      "model.layers.22.mlp.down_proj.q_invperm\n",
      "model.layers.22.mlp.down_proj.q_scale\n",
      "model.layers.22.mlp.down_proj.q_scale_max\n",
      "model.layers.22.mlp.down_proj.q_weight\n",
      "model.layers.22.mlp.gate_proj.q_groups\n",
      "model.layers.22.mlp.gate_proj.q_invperm\n",
      "model.layers.22.mlp.gate_proj.q_scale\n",
      "model.layers.22.mlp.gate_proj.q_scale_max\n",
      "model.layers.22.mlp.gate_proj.q_weight\n",
      "model.layers.22.mlp.up_proj.q_groups\n",
      "model.layers.22.mlp.up_proj.q_invperm\n",
      "model.layers.22.mlp.up_proj.q_scale\n",
      "model.layers.22.mlp.up_proj.q_scale_max\n",
      "model.layers.22.mlp.up_proj.q_weight\n",
      "model.layers.22.post_attention_layernorm.weight\n",
      "model.layers.22.self_attn.k_proj.q_groups\n",
      "model.layers.22.self_attn.k_proj.q_invperm\n",
      "model.layers.22.self_attn.k_proj.q_scale\n",
      "model.layers.22.self_attn.k_proj.q_scale_max\n",
      "model.layers.22.self_attn.k_proj.q_weight\n",
      "model.layers.22.self_attn.o_proj.q_groups\n",
      "model.layers.22.self_attn.o_proj.q_invperm\n",
      "model.layers.22.self_attn.o_proj.q_scale\n",
      "model.layers.22.self_attn.o_proj.q_scale_max\n",
      "model.layers.22.self_attn.o_proj.q_weight\n",
      "model.layers.22.self_attn.q_proj.q_groups\n",
      "model.layers.22.self_attn.q_proj.q_invperm\n",
      "model.layers.22.self_attn.q_proj.q_scale\n",
      "model.layers.22.self_attn.q_proj.q_scale_max\n",
      "model.layers.22.self_attn.q_proj.q_weight\n",
      "model.layers.22.self_attn.v_proj.q_groups\n",
      "model.layers.22.self_attn.v_proj.q_invperm\n",
      "model.layers.22.self_attn.v_proj.q_scale\n",
      "model.layers.22.self_attn.v_proj.q_scale_max\n",
      "model.layers.22.self_attn.v_proj.q_weight\n",
      "model.layers.23.input_layernorm.weight\n",
      "model.layers.23.mlp.down_proj.q_groups\n",
      "model.layers.23.mlp.down_proj.q_invperm\n",
      "model.layers.23.mlp.down_proj.q_scale\n",
      "model.layers.23.mlp.down_proj.q_scale_max\n",
      "model.layers.23.mlp.down_proj.q_weight\n",
      "model.layers.23.mlp.gate_proj.q_groups\n",
      "model.layers.23.mlp.gate_proj.q_invperm\n",
      "model.layers.23.mlp.gate_proj.q_scale\n",
      "model.layers.23.mlp.gate_proj.q_scale_max\n",
      "model.layers.23.mlp.gate_proj.q_weight\n",
      "model.layers.23.mlp.up_proj.q_groups\n",
      "model.layers.23.mlp.up_proj.q_invperm\n",
      "model.layers.23.mlp.up_proj.q_scale\n",
      "model.layers.23.mlp.up_proj.q_scale_max\n",
      "model.layers.23.mlp.up_proj.q_weight\n",
      "model.layers.23.post_attention_layernorm.weight\n",
      "model.layers.23.self_attn.k_proj.q_groups\n",
      "model.layers.23.self_attn.k_proj.q_invperm\n",
      "model.layers.23.self_attn.k_proj.q_scale\n",
      "model.layers.23.self_attn.k_proj.q_scale_max\n",
      "model.layers.23.self_attn.k_proj.q_weight\n",
      "model.layers.23.self_attn.o_proj.q_groups\n",
      "model.layers.23.self_attn.o_proj.q_invperm\n",
      "model.layers.23.self_attn.o_proj.q_scale\n",
      "model.layers.23.self_attn.o_proj.q_scale_max\n",
      "model.layers.23.self_attn.o_proj.q_weight\n",
      "model.layers.23.self_attn.q_proj.q_groups\n",
      "model.layers.23.self_attn.q_proj.q_invperm\n",
      "model.layers.23.self_attn.q_proj.q_scale\n",
      "model.layers.23.self_attn.q_proj.q_scale_max\n",
      "model.layers.23.self_attn.q_proj.q_weight\n",
      "model.layers.23.self_attn.v_proj.q_groups\n",
      "model.layers.23.self_attn.v_proj.q_invperm\n",
      "model.layers.23.self_attn.v_proj.q_scale\n",
      "model.layers.23.self_attn.v_proj.q_scale_max\n",
      "model.layers.23.self_attn.v_proj.q_weight\n",
      "model.layers.24.input_layernorm.weight\n",
      "model.layers.24.mlp.down_proj.q_groups\n",
      "model.layers.24.mlp.down_proj.q_invperm\n",
      "model.layers.24.mlp.down_proj.q_scale\n",
      "model.layers.24.mlp.down_proj.q_scale_max\n",
      "model.layers.24.mlp.down_proj.q_weight\n",
      "model.layers.24.mlp.gate_proj.q_groups\n",
      "model.layers.24.mlp.gate_proj.q_invperm\n",
      "model.layers.24.mlp.gate_proj.q_scale\n",
      "model.layers.24.mlp.gate_proj.q_scale_max\n",
      "model.layers.24.mlp.gate_proj.q_weight\n",
      "model.layers.24.mlp.up_proj.q_groups\n",
      "model.layers.24.mlp.up_proj.q_invperm\n",
      "model.layers.24.mlp.up_proj.q_scale\n",
      "model.layers.24.mlp.up_proj.q_scale_max\n",
      "model.layers.24.mlp.up_proj.q_weight\n",
      "model.layers.24.post_attention_layernorm.weight\n",
      "model.layers.24.self_attn.k_proj.q_groups\n",
      "model.layers.24.self_attn.k_proj.q_invperm\n",
      "model.layers.24.self_attn.k_proj.q_scale\n",
      "model.layers.24.self_attn.k_proj.q_scale_max\n",
      "model.layers.24.self_attn.k_proj.q_weight\n",
      "model.layers.24.self_attn.o_proj.q_groups\n",
      "model.layers.24.self_attn.o_proj.q_invperm\n",
      "model.layers.24.self_attn.o_proj.q_scale\n",
      "model.layers.24.self_attn.o_proj.q_scale_max\n",
      "model.layers.24.self_attn.o_proj.q_weight\n",
      "model.layers.24.self_attn.q_proj.q_groups\n",
      "model.layers.24.self_attn.q_proj.q_invperm\n",
      "model.layers.24.self_attn.q_proj.q_scale\n",
      "model.layers.24.self_attn.q_proj.q_scale_max\n",
      "model.layers.24.self_attn.q_proj.q_weight\n",
      "model.layers.24.self_attn.v_proj.q_groups\n",
      "model.layers.24.self_attn.v_proj.q_invperm\n",
      "model.layers.24.self_attn.v_proj.q_scale\n",
      "model.layers.24.self_attn.v_proj.q_scale_max\n",
      "model.layers.24.self_attn.v_proj.q_weight\n",
      "model.layers.25.input_layernorm.weight\n",
      "model.layers.25.mlp.down_proj.q_groups\n",
      "model.layers.25.mlp.down_proj.q_invperm\n",
      "model.layers.25.mlp.down_proj.q_scale\n",
      "model.layers.25.mlp.down_proj.q_scale_max\n",
      "model.layers.25.mlp.down_proj.q_weight\n",
      "model.layers.25.mlp.gate_proj.q_groups\n",
      "model.layers.25.mlp.gate_proj.q_invperm\n",
      "model.layers.25.mlp.gate_proj.q_scale\n",
      "model.layers.25.mlp.gate_proj.q_scale_max\n",
      "model.layers.25.mlp.gate_proj.q_weight\n",
      "model.layers.25.mlp.up_proj.q_groups\n",
      "model.layers.25.mlp.up_proj.q_invperm\n",
      "model.layers.25.mlp.up_proj.q_scale\n",
      "model.layers.25.mlp.up_proj.q_scale_max\n",
      "model.layers.25.mlp.up_proj.q_weight\n",
      "model.layers.25.post_attention_layernorm.weight\n",
      "model.layers.25.self_attn.k_proj.q_groups\n",
      "model.layers.25.self_attn.k_proj.q_invperm\n",
      "model.layers.25.self_attn.k_proj.q_scale\n",
      "model.layers.25.self_attn.k_proj.q_scale_max\n",
      "model.layers.25.self_attn.k_proj.q_weight\n",
      "model.layers.25.self_attn.o_proj.q_groups\n",
      "model.layers.25.self_attn.o_proj.q_invperm\n",
      "model.layers.25.self_attn.o_proj.q_scale\n",
      "model.layers.25.self_attn.o_proj.q_scale_max\n",
      "model.layers.25.self_attn.o_proj.q_weight\n",
      "model.layers.25.self_attn.q_proj.q_groups\n",
      "model.layers.25.self_attn.q_proj.q_invperm\n",
      "model.layers.25.self_attn.q_proj.q_scale\n",
      "model.layers.25.self_attn.q_proj.q_scale_max\n",
      "model.layers.25.self_attn.q_proj.q_weight\n",
      "model.layers.25.self_attn.v_proj.q_groups\n",
      "model.layers.25.self_attn.v_proj.q_invperm\n",
      "model.layers.25.self_attn.v_proj.q_scale\n",
      "model.layers.25.self_attn.v_proj.q_scale_max\n",
      "model.layers.25.self_attn.v_proj.q_weight\n",
      "model.layers.26.input_layernorm.weight\n",
      "model.layers.26.mlp.down_proj.q_groups\n",
      "model.layers.26.mlp.down_proj.q_invperm\n",
      "model.layers.26.mlp.down_proj.q_scale\n",
      "model.layers.26.mlp.down_proj.q_scale_max\n",
      "model.layers.26.mlp.down_proj.q_weight\n",
      "model.layers.26.mlp.gate_proj.q_groups\n",
      "model.layers.26.mlp.gate_proj.q_invperm\n",
      "model.layers.26.mlp.gate_proj.q_scale\n",
      "model.layers.26.mlp.gate_proj.q_scale_max\n",
      "model.layers.26.mlp.gate_proj.q_weight\n",
      "model.layers.26.mlp.up_proj.q_groups\n",
      "model.layers.26.mlp.up_proj.q_invperm\n",
      "model.layers.26.mlp.up_proj.q_scale\n",
      "model.layers.26.mlp.up_proj.q_scale_max\n",
      "model.layers.26.mlp.up_proj.q_weight\n",
      "model.layers.26.post_attention_layernorm.weight\n",
      "model.layers.26.self_attn.k_proj.q_groups\n",
      "model.layers.26.self_attn.k_proj.q_invperm\n",
      "model.layers.26.self_attn.k_proj.q_scale\n",
      "model.layers.26.self_attn.k_proj.q_scale_max\n",
      "model.layers.26.self_attn.k_proj.q_weight\n",
      "model.layers.26.self_attn.o_proj.q_groups\n",
      "model.layers.26.self_attn.o_proj.q_invperm\n",
      "model.layers.26.self_attn.o_proj.q_scale\n",
      "model.layers.26.self_attn.o_proj.q_scale_max\n",
      "model.layers.26.self_attn.o_proj.q_weight\n",
      "model.layers.26.self_attn.q_proj.q_groups\n",
      "model.layers.26.self_attn.q_proj.q_invperm\n",
      "model.layers.26.self_attn.q_proj.q_scale\n",
      "model.layers.26.self_attn.q_proj.q_scale_max\n",
      "model.layers.26.self_attn.q_proj.q_weight\n",
      "model.layers.26.self_attn.v_proj.q_groups\n",
      "model.layers.26.self_attn.v_proj.q_invperm\n",
      "model.layers.26.self_attn.v_proj.q_scale\n",
      "model.layers.26.self_attn.v_proj.q_scale_max\n",
      "model.layers.26.self_attn.v_proj.q_weight\n",
      "model.layers.27.input_layernorm.weight\n",
      "model.layers.27.mlp.down_proj.q_groups\n",
      "model.layers.27.mlp.down_proj.q_invperm\n",
      "model.layers.27.mlp.down_proj.q_scale\n",
      "model.layers.27.mlp.down_proj.q_scale_max\n",
      "model.layers.27.mlp.down_proj.q_weight\n",
      "model.layers.27.mlp.gate_proj.q_groups\n",
      "model.layers.27.mlp.gate_proj.q_invperm\n",
      "model.layers.27.mlp.gate_proj.q_scale\n",
      "model.layers.27.mlp.gate_proj.q_scale_max\n",
      "model.layers.27.mlp.gate_proj.q_weight\n",
      "model.layers.27.mlp.up_proj.q_groups\n",
      "model.layers.27.mlp.up_proj.q_invperm\n",
      "model.layers.27.mlp.up_proj.q_scale\n",
      "model.layers.27.mlp.up_proj.q_scale_max\n",
      "model.layers.27.mlp.up_proj.q_weight\n",
      "model.layers.27.post_attention_layernorm.weight\n",
      "model.layers.27.self_attn.k_proj.q_groups\n",
      "model.layers.27.self_attn.k_proj.q_invperm\n",
      "model.layers.27.self_attn.k_proj.q_scale\n",
      "model.layers.27.self_attn.k_proj.q_scale_max\n",
      "model.layers.27.self_attn.k_proj.q_weight\n",
      "model.layers.27.self_attn.o_proj.q_groups\n",
      "model.layers.27.self_attn.o_proj.q_invperm\n",
      "model.layers.27.self_attn.o_proj.q_scale\n",
      "model.layers.27.self_attn.o_proj.q_scale_max\n",
      "model.layers.27.self_attn.o_proj.q_weight\n",
      "model.layers.27.self_attn.q_proj.q_groups\n",
      "model.layers.27.self_attn.q_proj.q_invperm\n",
      "model.layers.27.self_attn.q_proj.q_scale\n",
      "model.layers.27.self_attn.q_proj.q_scale_max\n",
      "model.layers.27.self_attn.q_proj.q_weight\n",
      "model.layers.27.self_attn.v_proj.q_groups\n",
      "model.layers.27.self_attn.v_proj.q_invperm\n",
      "model.layers.27.self_attn.v_proj.q_scale\n",
      "model.layers.27.self_attn.v_proj.q_scale_max\n",
      "model.layers.27.self_attn.v_proj.q_weight\n",
      "model.layers.28.input_layernorm.weight\n",
      "model.layers.28.mlp.down_proj.q_groups\n",
      "model.layers.28.mlp.down_proj.q_invperm\n",
      "model.layers.28.mlp.down_proj.q_scale\n",
      "model.layers.28.mlp.down_proj.q_scale_max\n",
      "model.layers.28.mlp.down_proj.q_weight\n",
      "model.layers.28.mlp.gate_proj.q_groups\n",
      "model.layers.28.mlp.gate_proj.q_invperm\n",
      "model.layers.28.mlp.gate_proj.q_scale\n",
      "model.layers.28.mlp.gate_proj.q_scale_max\n",
      "model.layers.28.mlp.gate_proj.q_weight\n",
      "model.layers.28.mlp.up_proj.q_groups\n",
      "model.layers.28.mlp.up_proj.q_invperm\n",
      "model.layers.28.mlp.up_proj.q_scale\n",
      "model.layers.28.mlp.up_proj.q_scale_max\n",
      "model.layers.28.mlp.up_proj.q_weight\n",
      "model.layers.28.post_attention_layernorm.weight\n",
      "model.layers.28.self_attn.k_proj.q_groups\n",
      "model.layers.28.self_attn.k_proj.q_invperm\n",
      "model.layers.28.self_attn.k_proj.q_scale\n",
      "model.layers.28.self_attn.k_proj.q_scale_max\n",
      "model.layers.28.self_attn.k_proj.q_weight\n",
      "model.layers.28.self_attn.o_proj.q_groups\n",
      "model.layers.28.self_attn.o_proj.q_invperm\n",
      "model.layers.28.self_attn.o_proj.q_scale\n",
      "model.layers.28.self_attn.o_proj.q_scale_max\n",
      "model.layers.28.self_attn.o_proj.q_weight\n",
      "model.layers.28.self_attn.q_proj.q_groups\n",
      "model.layers.28.self_attn.q_proj.q_invperm\n",
      "model.layers.28.self_attn.q_proj.q_scale\n",
      "model.layers.28.self_attn.q_proj.q_scale_max\n",
      "model.layers.28.self_attn.q_proj.q_weight\n",
      "model.layers.28.self_attn.v_proj.q_groups\n",
      "model.layers.28.self_attn.v_proj.q_invperm\n",
      "model.layers.28.self_attn.v_proj.q_scale\n",
      "model.layers.28.self_attn.v_proj.q_scale_max\n",
      "model.layers.28.self_attn.v_proj.q_weight\n",
      "model.layers.29.input_layernorm.weight\n",
      "model.layers.29.mlp.down_proj.q_groups\n",
      "model.layers.29.mlp.down_proj.q_invperm\n",
      "model.layers.29.mlp.down_proj.q_scale\n",
      "model.layers.29.mlp.down_proj.q_scale_max\n",
      "model.layers.29.mlp.down_proj.q_weight\n",
      "model.layers.29.mlp.gate_proj.q_groups\n",
      "model.layers.29.mlp.gate_proj.q_invperm\n",
      "model.layers.29.mlp.gate_proj.q_scale\n",
      "model.layers.29.mlp.gate_proj.q_scale_max\n",
      "model.layers.29.mlp.gate_proj.q_weight\n",
      "model.layers.29.mlp.up_proj.q_groups\n",
      "model.layers.29.mlp.up_proj.q_invperm\n",
      "model.layers.29.mlp.up_proj.q_scale\n",
      "model.layers.29.mlp.up_proj.q_scale_max\n",
      "model.layers.29.mlp.up_proj.q_weight\n",
      "model.layers.29.post_attention_layernorm.weight\n",
      "model.layers.29.self_attn.k_proj.q_groups\n",
      "model.layers.29.self_attn.k_proj.q_invperm\n",
      "model.layers.29.self_attn.k_proj.q_scale\n",
      "model.layers.29.self_attn.k_proj.q_scale_max\n",
      "model.layers.29.self_attn.k_proj.q_weight\n",
      "model.layers.29.self_attn.o_proj.q_groups\n",
      "model.layers.29.self_attn.o_proj.q_invperm\n",
      "model.layers.29.self_attn.o_proj.q_scale\n",
      "model.layers.29.self_attn.o_proj.q_scale_max\n",
      "model.layers.29.self_attn.o_proj.q_weight\n",
      "model.layers.29.self_attn.q_proj.q_groups\n",
      "model.layers.29.self_attn.q_proj.q_invperm\n",
      "model.layers.29.self_attn.q_proj.q_scale\n",
      "model.layers.29.self_attn.q_proj.q_scale_max\n",
      "model.layers.29.self_attn.q_proj.q_weight\n",
      "model.layers.29.self_attn.v_proj.q_groups\n",
      "model.layers.29.self_attn.v_proj.q_invperm\n",
      "model.layers.29.self_attn.v_proj.q_scale\n",
      "model.layers.29.self_attn.v_proj.q_scale_max\n",
      "model.layers.29.self_attn.v_proj.q_weight\n"
     ]
    }
   ],
   "source": [
    "for layerName in layerNames:\n",
    "    # print(layerName)\n",
    "    splitName = layerName.split('.')\n",
    "    if len(splitName) > 2:\n",
    "\n",
    "        for i in range(10,30):\n",
    "            try:\n",
    "                layerNumber = int(splitName[2])\n",
    "            \n",
    "                if layerNumber == i:\n",
    "                    print(layerName)\n",
    "\n",
    "                    newName = splitName\n",
    "                    newName[2] = str(layerNumber + 30)\n",
    "                    tensors['.'.join(newName)] = tensors[layerName]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lm_head.q_groups',\n",
      " 'lm_head.q_invperm',\n",
      " 'lm_head.q_scale',\n",
      " 'lm_head.q_scale_max',\n",
      " 'lm_head.q_weight',\n",
      " 'model.embed_tokens.weight',\n",
      " 'model.layers.0.input_layernorm.weight',\n",
      " 'model.layers.0.mlp.down_proj.q_groups',\n",
      " 'model.layers.0.mlp.down_proj.q_invperm',\n",
      " 'model.layers.0.mlp.down_proj.q_scale',\n",
      " 'model.layers.0.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.0.mlp.down_proj.q_weight',\n",
      " 'model.layers.0.mlp.gate_proj.q_groups',\n",
      " 'model.layers.0.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.0.mlp.gate_proj.q_scale',\n",
      " 'model.layers.0.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.0.mlp.gate_proj.q_weight',\n",
      " 'model.layers.0.mlp.up_proj.q_groups',\n",
      " 'model.layers.0.mlp.up_proj.q_invperm',\n",
      " 'model.layers.0.mlp.up_proj.q_scale',\n",
      " 'model.layers.0.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.0.mlp.up_proj.q_weight',\n",
      " 'model.layers.0.post_attention_layernorm.weight',\n",
      " 'model.layers.0.self_attn.k_proj.q_groups',\n",
      " 'model.layers.0.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.0.self_attn.k_proj.q_scale',\n",
      " 'model.layers.0.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.0.self_attn.k_proj.q_weight',\n",
      " 'model.layers.0.self_attn.o_proj.q_groups',\n",
      " 'model.layers.0.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.0.self_attn.o_proj.q_scale',\n",
      " 'model.layers.0.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.0.self_attn.o_proj.q_weight',\n",
      " 'model.layers.0.self_attn.q_proj.q_groups',\n",
      " 'model.layers.0.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.0.self_attn.q_proj.q_scale',\n",
      " 'model.layers.0.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.0.self_attn.q_proj.q_weight',\n",
      " 'model.layers.0.self_attn.v_proj.q_groups',\n",
      " 'model.layers.0.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.0.self_attn.v_proj.q_scale',\n",
      " 'model.layers.0.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.0.self_attn.v_proj.q_weight',\n",
      " 'model.layers.1.input_layernorm.weight',\n",
      " 'model.layers.1.mlp.down_proj.q_groups',\n",
      " 'model.layers.1.mlp.down_proj.q_invperm',\n",
      " 'model.layers.1.mlp.down_proj.q_scale',\n",
      " 'model.layers.1.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.1.mlp.down_proj.q_weight',\n",
      " 'model.layers.1.mlp.gate_proj.q_groups',\n",
      " 'model.layers.1.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.1.mlp.gate_proj.q_scale',\n",
      " 'model.layers.1.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.1.mlp.gate_proj.q_weight',\n",
      " 'model.layers.1.mlp.up_proj.q_groups',\n",
      " 'model.layers.1.mlp.up_proj.q_invperm',\n",
      " 'model.layers.1.mlp.up_proj.q_scale',\n",
      " 'model.layers.1.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.1.mlp.up_proj.q_weight',\n",
      " 'model.layers.1.post_attention_layernorm.weight',\n",
      " 'model.layers.1.self_attn.k_proj.q_groups',\n",
      " 'model.layers.1.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.1.self_attn.k_proj.q_scale',\n",
      " 'model.layers.1.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.1.self_attn.k_proj.q_weight',\n",
      " 'model.layers.1.self_attn.o_proj.q_groups',\n",
      " 'model.layers.1.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.1.self_attn.o_proj.q_scale',\n",
      " 'model.layers.1.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.1.self_attn.o_proj.q_weight',\n",
      " 'model.layers.1.self_attn.q_proj.q_groups',\n",
      " 'model.layers.1.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.1.self_attn.q_proj.q_scale',\n",
      " 'model.layers.1.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.1.self_attn.q_proj.q_weight',\n",
      " 'model.layers.1.self_attn.v_proj.q_groups',\n",
      " 'model.layers.1.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.1.self_attn.v_proj.q_scale',\n",
      " 'model.layers.1.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.1.self_attn.v_proj.q_weight',\n",
      " 'model.layers.10.input_layernorm.weight',\n",
      " 'model.layers.10.mlp.down_proj.q_groups',\n",
      " 'model.layers.10.mlp.down_proj.q_invperm',\n",
      " 'model.layers.10.mlp.down_proj.q_scale',\n",
      " 'model.layers.10.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.10.mlp.down_proj.q_weight',\n",
      " 'model.layers.10.mlp.gate_proj.q_groups',\n",
      " 'model.layers.10.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.10.mlp.gate_proj.q_scale',\n",
      " 'model.layers.10.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.10.mlp.gate_proj.q_weight',\n",
      " 'model.layers.10.mlp.up_proj.q_groups',\n",
      " 'model.layers.10.mlp.up_proj.q_invperm',\n",
      " 'model.layers.10.mlp.up_proj.q_scale',\n",
      " 'model.layers.10.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.10.mlp.up_proj.q_weight',\n",
      " 'model.layers.10.post_attention_layernorm.weight',\n",
      " 'model.layers.10.self_attn.k_proj.q_groups',\n",
      " 'model.layers.10.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.10.self_attn.k_proj.q_scale',\n",
      " 'model.layers.10.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.10.self_attn.k_proj.q_weight',\n",
      " 'model.layers.10.self_attn.o_proj.q_groups',\n",
      " 'model.layers.10.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.10.self_attn.o_proj.q_scale',\n",
      " 'model.layers.10.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.10.self_attn.o_proj.q_weight',\n",
      " 'model.layers.10.self_attn.q_proj.q_groups',\n",
      " 'model.layers.10.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.10.self_attn.q_proj.q_scale',\n",
      " 'model.layers.10.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.10.self_attn.q_proj.q_weight',\n",
      " 'model.layers.10.self_attn.v_proj.q_groups',\n",
      " 'model.layers.10.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.10.self_attn.v_proj.q_scale',\n",
      " 'model.layers.10.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.10.self_attn.v_proj.q_weight',\n",
      " 'model.layers.11.input_layernorm.weight',\n",
      " 'model.layers.11.mlp.down_proj.q_groups',\n",
      " 'model.layers.11.mlp.down_proj.q_invperm',\n",
      " 'model.layers.11.mlp.down_proj.q_scale',\n",
      " 'model.layers.11.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.11.mlp.down_proj.q_weight',\n",
      " 'model.layers.11.mlp.gate_proj.q_groups',\n",
      " 'model.layers.11.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.11.mlp.gate_proj.q_scale',\n",
      " 'model.layers.11.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.11.mlp.gate_proj.q_weight',\n",
      " 'model.layers.11.mlp.up_proj.q_groups',\n",
      " 'model.layers.11.mlp.up_proj.q_invperm',\n",
      " 'model.layers.11.mlp.up_proj.q_scale',\n",
      " 'model.layers.11.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.11.mlp.up_proj.q_weight',\n",
      " 'model.layers.11.post_attention_layernorm.weight',\n",
      " 'model.layers.11.self_attn.k_proj.q_groups',\n",
      " 'model.layers.11.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.11.self_attn.k_proj.q_scale',\n",
      " 'model.layers.11.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.11.self_attn.k_proj.q_weight',\n",
      " 'model.layers.11.self_attn.o_proj.q_groups',\n",
      " 'model.layers.11.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.11.self_attn.o_proj.q_scale',\n",
      " 'model.layers.11.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.11.self_attn.o_proj.q_weight',\n",
      " 'model.layers.11.self_attn.q_proj.q_groups',\n",
      " 'model.layers.11.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.11.self_attn.q_proj.q_scale',\n",
      " 'model.layers.11.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.11.self_attn.q_proj.q_weight',\n",
      " 'model.layers.11.self_attn.v_proj.q_groups',\n",
      " 'model.layers.11.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.11.self_attn.v_proj.q_scale',\n",
      " 'model.layers.11.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.11.self_attn.v_proj.q_weight',\n",
      " 'model.layers.12.input_layernorm.weight',\n",
      " 'model.layers.12.mlp.down_proj.q_groups',\n",
      " 'model.layers.12.mlp.down_proj.q_invperm',\n",
      " 'model.layers.12.mlp.down_proj.q_scale',\n",
      " 'model.layers.12.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.12.mlp.down_proj.q_weight',\n",
      " 'model.layers.12.mlp.gate_proj.q_groups',\n",
      " 'model.layers.12.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.12.mlp.gate_proj.q_scale',\n",
      " 'model.layers.12.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.12.mlp.gate_proj.q_weight',\n",
      " 'model.layers.12.mlp.up_proj.q_groups',\n",
      " 'model.layers.12.mlp.up_proj.q_invperm',\n",
      " 'model.layers.12.mlp.up_proj.q_scale',\n",
      " 'model.layers.12.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.12.mlp.up_proj.q_weight',\n",
      " 'model.layers.12.post_attention_layernorm.weight',\n",
      " 'model.layers.12.self_attn.k_proj.q_groups',\n",
      " 'model.layers.12.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.12.self_attn.k_proj.q_scale',\n",
      " 'model.layers.12.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.12.self_attn.k_proj.q_weight',\n",
      " 'model.layers.12.self_attn.o_proj.q_groups',\n",
      " 'model.layers.12.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.12.self_attn.o_proj.q_scale',\n",
      " 'model.layers.12.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.12.self_attn.o_proj.q_weight',\n",
      " 'model.layers.12.self_attn.q_proj.q_groups',\n",
      " 'model.layers.12.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.12.self_attn.q_proj.q_scale',\n",
      " 'model.layers.12.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.12.self_attn.q_proj.q_weight',\n",
      " 'model.layers.12.self_attn.v_proj.q_groups',\n",
      " 'model.layers.12.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.12.self_attn.v_proj.q_scale',\n",
      " 'model.layers.12.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.12.self_attn.v_proj.q_weight',\n",
      " 'model.layers.13.input_layernorm.weight',\n",
      " 'model.layers.13.mlp.down_proj.q_groups',\n",
      " 'model.layers.13.mlp.down_proj.q_invperm',\n",
      " 'model.layers.13.mlp.down_proj.q_scale',\n",
      " 'model.layers.13.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.13.mlp.down_proj.q_weight',\n",
      " 'model.layers.13.mlp.gate_proj.q_groups',\n",
      " 'model.layers.13.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.13.mlp.gate_proj.q_scale',\n",
      " 'model.layers.13.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.13.mlp.gate_proj.q_weight',\n",
      " 'model.layers.13.mlp.up_proj.q_groups',\n",
      " 'model.layers.13.mlp.up_proj.q_invperm',\n",
      " 'model.layers.13.mlp.up_proj.q_scale',\n",
      " 'model.layers.13.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.13.mlp.up_proj.q_weight',\n",
      " 'model.layers.13.post_attention_layernorm.weight',\n",
      " 'model.layers.13.self_attn.k_proj.q_groups',\n",
      " 'model.layers.13.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.13.self_attn.k_proj.q_scale',\n",
      " 'model.layers.13.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.13.self_attn.k_proj.q_weight',\n",
      " 'model.layers.13.self_attn.o_proj.q_groups',\n",
      " 'model.layers.13.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.13.self_attn.o_proj.q_scale',\n",
      " 'model.layers.13.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.13.self_attn.o_proj.q_weight',\n",
      " 'model.layers.13.self_attn.q_proj.q_groups',\n",
      " 'model.layers.13.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.13.self_attn.q_proj.q_scale',\n",
      " 'model.layers.13.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.13.self_attn.q_proj.q_weight',\n",
      " 'model.layers.13.self_attn.v_proj.q_groups',\n",
      " 'model.layers.13.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.13.self_attn.v_proj.q_scale',\n",
      " 'model.layers.13.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.13.self_attn.v_proj.q_weight',\n",
      " 'model.layers.14.input_layernorm.weight',\n",
      " 'model.layers.14.mlp.down_proj.q_groups',\n",
      " 'model.layers.14.mlp.down_proj.q_invperm',\n",
      " 'model.layers.14.mlp.down_proj.q_scale',\n",
      " 'model.layers.14.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.14.mlp.down_proj.q_weight',\n",
      " 'model.layers.14.mlp.gate_proj.q_groups',\n",
      " 'model.layers.14.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.14.mlp.gate_proj.q_scale',\n",
      " 'model.layers.14.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.14.mlp.gate_proj.q_weight',\n",
      " 'model.layers.14.mlp.up_proj.q_groups',\n",
      " 'model.layers.14.mlp.up_proj.q_invperm',\n",
      " 'model.layers.14.mlp.up_proj.q_scale',\n",
      " 'model.layers.14.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.14.mlp.up_proj.q_weight',\n",
      " 'model.layers.14.post_attention_layernorm.weight',\n",
      " 'model.layers.14.self_attn.k_proj.q_groups',\n",
      " 'model.layers.14.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.14.self_attn.k_proj.q_scale',\n",
      " 'model.layers.14.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.14.self_attn.k_proj.q_weight',\n",
      " 'model.layers.14.self_attn.o_proj.q_groups',\n",
      " 'model.layers.14.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.14.self_attn.o_proj.q_scale',\n",
      " 'model.layers.14.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.14.self_attn.o_proj.q_weight',\n",
      " 'model.layers.14.self_attn.q_proj.q_groups',\n",
      " 'model.layers.14.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.14.self_attn.q_proj.q_scale',\n",
      " 'model.layers.14.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.14.self_attn.q_proj.q_weight',\n",
      " 'model.layers.14.self_attn.v_proj.q_groups',\n",
      " 'model.layers.14.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.14.self_attn.v_proj.q_scale',\n",
      " 'model.layers.14.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.14.self_attn.v_proj.q_weight',\n",
      " 'model.layers.15.input_layernorm.weight',\n",
      " 'model.layers.15.mlp.down_proj.q_groups',\n",
      " 'model.layers.15.mlp.down_proj.q_invperm',\n",
      " 'model.layers.15.mlp.down_proj.q_scale',\n",
      " 'model.layers.15.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.15.mlp.down_proj.q_weight',\n",
      " 'model.layers.15.mlp.gate_proj.q_groups',\n",
      " 'model.layers.15.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.15.mlp.gate_proj.q_scale',\n",
      " 'model.layers.15.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.15.mlp.gate_proj.q_weight',\n",
      " 'model.layers.15.mlp.up_proj.q_groups',\n",
      " 'model.layers.15.mlp.up_proj.q_invperm',\n",
      " 'model.layers.15.mlp.up_proj.q_scale',\n",
      " 'model.layers.15.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.15.mlp.up_proj.q_weight',\n",
      " 'model.layers.15.post_attention_layernorm.weight',\n",
      " 'model.layers.15.self_attn.k_proj.q_groups',\n",
      " 'model.layers.15.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.15.self_attn.k_proj.q_scale',\n",
      " 'model.layers.15.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.15.self_attn.k_proj.q_weight',\n",
      " 'model.layers.15.self_attn.o_proj.q_groups',\n",
      " 'model.layers.15.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.15.self_attn.o_proj.q_scale',\n",
      " 'model.layers.15.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.15.self_attn.o_proj.q_weight',\n",
      " 'model.layers.15.self_attn.q_proj.q_groups',\n",
      " 'model.layers.15.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.15.self_attn.q_proj.q_scale',\n",
      " 'model.layers.15.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.15.self_attn.q_proj.q_weight',\n",
      " 'model.layers.15.self_attn.v_proj.q_groups',\n",
      " 'model.layers.15.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.15.self_attn.v_proj.q_scale',\n",
      " 'model.layers.15.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.15.self_attn.v_proj.q_weight',\n",
      " 'model.layers.16.input_layernorm.weight',\n",
      " 'model.layers.16.mlp.down_proj.q_groups',\n",
      " 'model.layers.16.mlp.down_proj.q_invperm',\n",
      " 'model.layers.16.mlp.down_proj.q_scale',\n",
      " 'model.layers.16.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.16.mlp.down_proj.q_weight',\n",
      " 'model.layers.16.mlp.gate_proj.q_groups',\n",
      " 'model.layers.16.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.16.mlp.gate_proj.q_scale',\n",
      " 'model.layers.16.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.16.mlp.gate_proj.q_weight',\n",
      " 'model.layers.16.mlp.up_proj.q_groups',\n",
      " 'model.layers.16.mlp.up_proj.q_invperm',\n",
      " 'model.layers.16.mlp.up_proj.q_scale',\n",
      " 'model.layers.16.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.16.mlp.up_proj.q_weight',\n",
      " 'model.layers.16.post_attention_layernorm.weight',\n",
      " 'model.layers.16.self_attn.k_proj.q_groups',\n",
      " 'model.layers.16.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.16.self_attn.k_proj.q_scale',\n",
      " 'model.layers.16.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.16.self_attn.k_proj.q_weight',\n",
      " 'model.layers.16.self_attn.o_proj.q_groups',\n",
      " 'model.layers.16.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.16.self_attn.o_proj.q_scale',\n",
      " 'model.layers.16.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.16.self_attn.o_proj.q_weight',\n",
      " 'model.layers.16.self_attn.q_proj.q_groups',\n",
      " 'model.layers.16.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.16.self_attn.q_proj.q_scale',\n",
      " 'model.layers.16.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.16.self_attn.q_proj.q_weight',\n",
      " 'model.layers.16.self_attn.v_proj.q_groups',\n",
      " 'model.layers.16.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.16.self_attn.v_proj.q_scale',\n",
      " 'model.layers.16.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.16.self_attn.v_proj.q_weight',\n",
      " 'model.layers.17.input_layernorm.weight',\n",
      " 'model.layers.17.mlp.down_proj.q_groups',\n",
      " 'model.layers.17.mlp.down_proj.q_invperm',\n",
      " 'model.layers.17.mlp.down_proj.q_scale',\n",
      " 'model.layers.17.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.17.mlp.down_proj.q_weight',\n",
      " 'model.layers.17.mlp.gate_proj.q_groups',\n",
      " 'model.layers.17.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.17.mlp.gate_proj.q_scale',\n",
      " 'model.layers.17.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.17.mlp.gate_proj.q_weight',\n",
      " 'model.layers.17.mlp.up_proj.q_groups',\n",
      " 'model.layers.17.mlp.up_proj.q_invperm',\n",
      " 'model.layers.17.mlp.up_proj.q_scale',\n",
      " 'model.layers.17.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.17.mlp.up_proj.q_weight',\n",
      " 'model.layers.17.post_attention_layernorm.weight',\n",
      " 'model.layers.17.self_attn.k_proj.q_groups',\n",
      " 'model.layers.17.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.17.self_attn.k_proj.q_scale',\n",
      " 'model.layers.17.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.17.self_attn.k_proj.q_weight',\n",
      " 'model.layers.17.self_attn.o_proj.q_groups',\n",
      " 'model.layers.17.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.17.self_attn.o_proj.q_scale',\n",
      " 'model.layers.17.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.17.self_attn.o_proj.q_weight',\n",
      " 'model.layers.17.self_attn.q_proj.q_groups',\n",
      " 'model.layers.17.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.17.self_attn.q_proj.q_scale',\n",
      " 'model.layers.17.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.17.self_attn.q_proj.q_weight',\n",
      " 'model.layers.17.self_attn.v_proj.q_groups',\n",
      " 'model.layers.17.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.17.self_attn.v_proj.q_scale',\n",
      " 'model.layers.17.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.17.self_attn.v_proj.q_weight',\n",
      " 'model.layers.18.input_layernorm.weight',\n",
      " 'model.layers.18.mlp.down_proj.q_groups',\n",
      " 'model.layers.18.mlp.down_proj.q_invperm',\n",
      " 'model.layers.18.mlp.down_proj.q_scale',\n",
      " 'model.layers.18.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.18.mlp.down_proj.q_weight',\n",
      " 'model.layers.18.mlp.gate_proj.q_groups',\n",
      " 'model.layers.18.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.18.mlp.gate_proj.q_scale',\n",
      " 'model.layers.18.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.18.mlp.gate_proj.q_weight',\n",
      " 'model.layers.18.mlp.up_proj.q_groups',\n",
      " 'model.layers.18.mlp.up_proj.q_invperm',\n",
      " 'model.layers.18.mlp.up_proj.q_scale',\n",
      " 'model.layers.18.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.18.mlp.up_proj.q_weight',\n",
      " 'model.layers.18.post_attention_layernorm.weight',\n",
      " 'model.layers.18.self_attn.k_proj.q_groups',\n",
      " 'model.layers.18.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.18.self_attn.k_proj.q_scale',\n",
      " 'model.layers.18.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.18.self_attn.k_proj.q_weight',\n",
      " 'model.layers.18.self_attn.o_proj.q_groups',\n",
      " 'model.layers.18.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.18.self_attn.o_proj.q_scale',\n",
      " 'model.layers.18.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.18.self_attn.o_proj.q_weight',\n",
      " 'model.layers.18.self_attn.q_proj.q_groups',\n",
      " 'model.layers.18.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.18.self_attn.q_proj.q_scale',\n",
      " 'model.layers.18.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.18.self_attn.q_proj.q_weight',\n",
      " 'model.layers.18.self_attn.v_proj.q_groups',\n",
      " 'model.layers.18.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.18.self_attn.v_proj.q_scale',\n",
      " 'model.layers.18.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.18.self_attn.v_proj.q_weight',\n",
      " 'model.layers.19.input_layernorm.weight',\n",
      " 'model.layers.19.mlp.down_proj.q_groups',\n",
      " 'model.layers.19.mlp.down_proj.q_invperm',\n",
      " 'model.layers.19.mlp.down_proj.q_scale',\n",
      " 'model.layers.19.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.19.mlp.down_proj.q_weight',\n",
      " 'model.layers.19.mlp.gate_proj.q_groups',\n",
      " 'model.layers.19.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.19.mlp.gate_proj.q_scale',\n",
      " 'model.layers.19.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.19.mlp.gate_proj.q_weight',\n",
      " 'model.layers.19.mlp.up_proj.q_groups',\n",
      " 'model.layers.19.mlp.up_proj.q_invperm',\n",
      " 'model.layers.19.mlp.up_proj.q_scale',\n",
      " 'model.layers.19.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.19.mlp.up_proj.q_weight',\n",
      " 'model.layers.19.post_attention_layernorm.weight',\n",
      " 'model.layers.19.self_attn.k_proj.q_groups',\n",
      " 'model.layers.19.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.19.self_attn.k_proj.q_scale',\n",
      " 'model.layers.19.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.19.self_attn.k_proj.q_weight',\n",
      " 'model.layers.19.self_attn.o_proj.q_groups',\n",
      " 'model.layers.19.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.19.self_attn.o_proj.q_scale',\n",
      " 'model.layers.19.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.19.self_attn.o_proj.q_weight',\n",
      " 'model.layers.19.self_attn.q_proj.q_groups',\n",
      " 'model.layers.19.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.19.self_attn.q_proj.q_scale',\n",
      " 'model.layers.19.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.19.self_attn.q_proj.q_weight',\n",
      " 'model.layers.19.self_attn.v_proj.q_groups',\n",
      " 'model.layers.19.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.19.self_attn.v_proj.q_scale',\n",
      " 'model.layers.19.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.19.self_attn.v_proj.q_weight',\n",
      " 'model.layers.2.input_layernorm.weight',\n",
      " 'model.layers.2.mlp.down_proj.q_groups',\n",
      " 'model.layers.2.mlp.down_proj.q_invperm',\n",
      " 'model.layers.2.mlp.down_proj.q_scale',\n",
      " 'model.layers.2.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.2.mlp.down_proj.q_weight',\n",
      " 'model.layers.2.mlp.gate_proj.q_groups',\n",
      " 'model.layers.2.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.2.mlp.gate_proj.q_scale',\n",
      " 'model.layers.2.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.2.mlp.gate_proj.q_weight',\n",
      " 'model.layers.2.mlp.up_proj.q_groups',\n",
      " 'model.layers.2.mlp.up_proj.q_invperm',\n",
      " 'model.layers.2.mlp.up_proj.q_scale',\n",
      " 'model.layers.2.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.2.mlp.up_proj.q_weight',\n",
      " 'model.layers.2.post_attention_layernorm.weight',\n",
      " 'model.layers.2.self_attn.k_proj.q_groups',\n",
      " 'model.layers.2.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.2.self_attn.k_proj.q_scale',\n",
      " 'model.layers.2.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.2.self_attn.k_proj.q_weight',\n",
      " 'model.layers.2.self_attn.o_proj.q_groups',\n",
      " 'model.layers.2.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.2.self_attn.o_proj.q_scale',\n",
      " 'model.layers.2.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.2.self_attn.o_proj.q_weight',\n",
      " 'model.layers.2.self_attn.q_proj.q_groups',\n",
      " 'model.layers.2.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.2.self_attn.q_proj.q_scale',\n",
      " 'model.layers.2.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.2.self_attn.q_proj.q_weight',\n",
      " 'model.layers.2.self_attn.v_proj.q_groups',\n",
      " 'model.layers.2.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.2.self_attn.v_proj.q_scale',\n",
      " 'model.layers.2.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.2.self_attn.v_proj.q_weight',\n",
      " 'model.layers.20.input_layernorm.weight',\n",
      " 'model.layers.20.mlp.down_proj.q_groups',\n",
      " 'model.layers.20.mlp.down_proj.q_invperm',\n",
      " 'model.layers.20.mlp.down_proj.q_scale',\n",
      " 'model.layers.20.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.20.mlp.down_proj.q_weight',\n",
      " 'model.layers.20.mlp.gate_proj.q_groups',\n",
      " 'model.layers.20.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.20.mlp.gate_proj.q_scale',\n",
      " 'model.layers.20.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.20.mlp.gate_proj.q_weight',\n",
      " 'model.layers.20.mlp.up_proj.q_groups',\n",
      " 'model.layers.20.mlp.up_proj.q_invperm',\n",
      " 'model.layers.20.mlp.up_proj.q_scale',\n",
      " 'model.layers.20.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.20.mlp.up_proj.q_weight',\n",
      " 'model.layers.20.post_attention_layernorm.weight',\n",
      " 'model.layers.20.self_attn.k_proj.q_groups',\n",
      " 'model.layers.20.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.20.self_attn.k_proj.q_scale',\n",
      " 'model.layers.20.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.20.self_attn.k_proj.q_weight',\n",
      " 'model.layers.20.self_attn.o_proj.q_groups',\n",
      " 'model.layers.20.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.20.self_attn.o_proj.q_scale',\n",
      " 'model.layers.20.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.20.self_attn.o_proj.q_weight',\n",
      " 'model.layers.20.self_attn.q_proj.q_groups',\n",
      " 'model.layers.20.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.20.self_attn.q_proj.q_scale',\n",
      " 'model.layers.20.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.20.self_attn.q_proj.q_weight',\n",
      " 'model.layers.20.self_attn.v_proj.q_groups',\n",
      " 'model.layers.20.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.20.self_attn.v_proj.q_scale',\n",
      " 'model.layers.20.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.20.self_attn.v_proj.q_weight',\n",
      " 'model.layers.21.input_layernorm.weight',\n",
      " 'model.layers.21.mlp.down_proj.q_groups',\n",
      " 'model.layers.21.mlp.down_proj.q_invperm',\n",
      " 'model.layers.21.mlp.down_proj.q_scale',\n",
      " 'model.layers.21.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.21.mlp.down_proj.q_weight',\n",
      " 'model.layers.21.mlp.gate_proj.q_groups',\n",
      " 'model.layers.21.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.21.mlp.gate_proj.q_scale',\n",
      " 'model.layers.21.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.21.mlp.gate_proj.q_weight',\n",
      " 'model.layers.21.mlp.up_proj.q_groups',\n",
      " 'model.layers.21.mlp.up_proj.q_invperm',\n",
      " 'model.layers.21.mlp.up_proj.q_scale',\n",
      " 'model.layers.21.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.21.mlp.up_proj.q_weight',\n",
      " 'model.layers.21.post_attention_layernorm.weight',\n",
      " 'model.layers.21.self_attn.k_proj.q_groups',\n",
      " 'model.layers.21.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.21.self_attn.k_proj.q_scale',\n",
      " 'model.layers.21.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.21.self_attn.k_proj.q_weight',\n",
      " 'model.layers.21.self_attn.o_proj.q_groups',\n",
      " 'model.layers.21.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.21.self_attn.o_proj.q_scale',\n",
      " 'model.layers.21.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.21.self_attn.o_proj.q_weight',\n",
      " 'model.layers.21.self_attn.q_proj.q_groups',\n",
      " 'model.layers.21.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.21.self_attn.q_proj.q_scale',\n",
      " 'model.layers.21.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.21.self_attn.q_proj.q_weight',\n",
      " 'model.layers.21.self_attn.v_proj.q_groups',\n",
      " 'model.layers.21.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.21.self_attn.v_proj.q_scale',\n",
      " 'model.layers.21.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.21.self_attn.v_proj.q_weight',\n",
      " 'model.layers.22.input_layernorm.weight',\n",
      " 'model.layers.22.mlp.down_proj.q_groups',\n",
      " 'model.layers.22.mlp.down_proj.q_invperm',\n",
      " 'model.layers.22.mlp.down_proj.q_scale',\n",
      " 'model.layers.22.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.22.mlp.down_proj.q_weight',\n",
      " 'model.layers.22.mlp.gate_proj.q_groups',\n",
      " 'model.layers.22.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.22.mlp.gate_proj.q_scale',\n",
      " 'model.layers.22.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.22.mlp.gate_proj.q_weight',\n",
      " 'model.layers.22.mlp.up_proj.q_groups',\n",
      " 'model.layers.22.mlp.up_proj.q_invperm',\n",
      " 'model.layers.22.mlp.up_proj.q_scale',\n",
      " 'model.layers.22.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.22.mlp.up_proj.q_weight',\n",
      " 'model.layers.22.post_attention_layernorm.weight',\n",
      " 'model.layers.22.self_attn.k_proj.q_groups',\n",
      " 'model.layers.22.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.22.self_attn.k_proj.q_scale',\n",
      " 'model.layers.22.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.22.self_attn.k_proj.q_weight',\n",
      " 'model.layers.22.self_attn.o_proj.q_groups',\n",
      " 'model.layers.22.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.22.self_attn.o_proj.q_scale',\n",
      " 'model.layers.22.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.22.self_attn.o_proj.q_weight',\n",
      " 'model.layers.22.self_attn.q_proj.q_groups',\n",
      " 'model.layers.22.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.22.self_attn.q_proj.q_scale',\n",
      " 'model.layers.22.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.22.self_attn.q_proj.q_weight',\n",
      " 'model.layers.22.self_attn.v_proj.q_groups',\n",
      " 'model.layers.22.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.22.self_attn.v_proj.q_scale',\n",
      " 'model.layers.22.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.22.self_attn.v_proj.q_weight',\n",
      " 'model.layers.23.input_layernorm.weight',\n",
      " 'model.layers.23.mlp.down_proj.q_groups',\n",
      " 'model.layers.23.mlp.down_proj.q_invperm',\n",
      " 'model.layers.23.mlp.down_proj.q_scale',\n",
      " 'model.layers.23.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.23.mlp.down_proj.q_weight',\n",
      " 'model.layers.23.mlp.gate_proj.q_groups',\n",
      " 'model.layers.23.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.23.mlp.gate_proj.q_scale',\n",
      " 'model.layers.23.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.23.mlp.gate_proj.q_weight',\n",
      " 'model.layers.23.mlp.up_proj.q_groups',\n",
      " 'model.layers.23.mlp.up_proj.q_invperm',\n",
      " 'model.layers.23.mlp.up_proj.q_scale',\n",
      " 'model.layers.23.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.23.mlp.up_proj.q_weight',\n",
      " 'model.layers.23.post_attention_layernorm.weight',\n",
      " 'model.layers.23.self_attn.k_proj.q_groups',\n",
      " 'model.layers.23.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.23.self_attn.k_proj.q_scale',\n",
      " 'model.layers.23.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.23.self_attn.k_proj.q_weight',\n",
      " 'model.layers.23.self_attn.o_proj.q_groups',\n",
      " 'model.layers.23.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.23.self_attn.o_proj.q_scale',\n",
      " 'model.layers.23.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.23.self_attn.o_proj.q_weight',\n",
      " 'model.layers.23.self_attn.q_proj.q_groups',\n",
      " 'model.layers.23.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.23.self_attn.q_proj.q_scale',\n",
      " 'model.layers.23.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.23.self_attn.q_proj.q_weight',\n",
      " 'model.layers.23.self_attn.v_proj.q_groups',\n",
      " 'model.layers.23.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.23.self_attn.v_proj.q_scale',\n",
      " 'model.layers.23.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.23.self_attn.v_proj.q_weight',\n",
      " 'model.layers.24.input_layernorm.weight',\n",
      " 'model.layers.24.mlp.down_proj.q_groups',\n",
      " 'model.layers.24.mlp.down_proj.q_invperm',\n",
      " 'model.layers.24.mlp.down_proj.q_scale',\n",
      " 'model.layers.24.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.24.mlp.down_proj.q_weight',\n",
      " 'model.layers.24.mlp.gate_proj.q_groups',\n",
      " 'model.layers.24.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.24.mlp.gate_proj.q_scale',\n",
      " 'model.layers.24.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.24.mlp.gate_proj.q_weight',\n",
      " 'model.layers.24.mlp.up_proj.q_groups',\n",
      " 'model.layers.24.mlp.up_proj.q_invperm',\n",
      " 'model.layers.24.mlp.up_proj.q_scale',\n",
      " 'model.layers.24.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.24.mlp.up_proj.q_weight',\n",
      " 'model.layers.24.post_attention_layernorm.weight',\n",
      " 'model.layers.24.self_attn.k_proj.q_groups',\n",
      " 'model.layers.24.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.24.self_attn.k_proj.q_scale',\n",
      " 'model.layers.24.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.24.self_attn.k_proj.q_weight',\n",
      " 'model.layers.24.self_attn.o_proj.q_groups',\n",
      " 'model.layers.24.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.24.self_attn.o_proj.q_scale',\n",
      " 'model.layers.24.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.24.self_attn.o_proj.q_weight',\n",
      " 'model.layers.24.self_attn.q_proj.q_groups',\n",
      " 'model.layers.24.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.24.self_attn.q_proj.q_scale',\n",
      " 'model.layers.24.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.24.self_attn.q_proj.q_weight',\n",
      " 'model.layers.24.self_attn.v_proj.q_groups',\n",
      " 'model.layers.24.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.24.self_attn.v_proj.q_scale',\n",
      " 'model.layers.24.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.24.self_attn.v_proj.q_weight',\n",
      " 'model.layers.25.input_layernorm.weight',\n",
      " 'model.layers.25.mlp.down_proj.q_groups',\n",
      " 'model.layers.25.mlp.down_proj.q_invperm',\n",
      " 'model.layers.25.mlp.down_proj.q_scale',\n",
      " 'model.layers.25.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.25.mlp.down_proj.q_weight',\n",
      " 'model.layers.25.mlp.gate_proj.q_groups',\n",
      " 'model.layers.25.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.25.mlp.gate_proj.q_scale',\n",
      " 'model.layers.25.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.25.mlp.gate_proj.q_weight',\n",
      " 'model.layers.25.mlp.up_proj.q_groups',\n",
      " 'model.layers.25.mlp.up_proj.q_invperm',\n",
      " 'model.layers.25.mlp.up_proj.q_scale',\n",
      " 'model.layers.25.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.25.mlp.up_proj.q_weight',\n",
      " 'model.layers.25.post_attention_layernorm.weight',\n",
      " 'model.layers.25.self_attn.k_proj.q_groups',\n",
      " 'model.layers.25.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.25.self_attn.k_proj.q_scale',\n",
      " 'model.layers.25.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.25.self_attn.k_proj.q_weight',\n",
      " 'model.layers.25.self_attn.o_proj.q_groups',\n",
      " 'model.layers.25.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.25.self_attn.o_proj.q_scale',\n",
      " 'model.layers.25.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.25.self_attn.o_proj.q_weight',\n",
      " 'model.layers.25.self_attn.q_proj.q_groups',\n",
      " 'model.layers.25.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.25.self_attn.q_proj.q_scale',\n",
      " 'model.layers.25.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.25.self_attn.q_proj.q_weight',\n",
      " 'model.layers.25.self_attn.v_proj.q_groups',\n",
      " 'model.layers.25.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.25.self_attn.v_proj.q_scale',\n",
      " 'model.layers.25.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.25.self_attn.v_proj.q_weight',\n",
      " 'model.layers.26.input_layernorm.weight',\n",
      " 'model.layers.26.mlp.down_proj.q_groups',\n",
      " 'model.layers.26.mlp.down_proj.q_invperm',\n",
      " 'model.layers.26.mlp.down_proj.q_scale',\n",
      " 'model.layers.26.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.26.mlp.down_proj.q_weight',\n",
      " 'model.layers.26.mlp.gate_proj.q_groups',\n",
      " 'model.layers.26.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.26.mlp.gate_proj.q_scale',\n",
      " 'model.layers.26.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.26.mlp.gate_proj.q_weight',\n",
      " 'model.layers.26.mlp.up_proj.q_groups',\n",
      " 'model.layers.26.mlp.up_proj.q_invperm',\n",
      " 'model.layers.26.mlp.up_proj.q_scale',\n",
      " 'model.layers.26.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.26.mlp.up_proj.q_weight',\n",
      " 'model.layers.26.post_attention_layernorm.weight',\n",
      " 'model.layers.26.self_attn.k_proj.q_groups',\n",
      " 'model.layers.26.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.26.self_attn.k_proj.q_scale',\n",
      " 'model.layers.26.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.26.self_attn.k_proj.q_weight',\n",
      " 'model.layers.26.self_attn.o_proj.q_groups',\n",
      " 'model.layers.26.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.26.self_attn.o_proj.q_scale',\n",
      " 'model.layers.26.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.26.self_attn.o_proj.q_weight',\n",
      " 'model.layers.26.self_attn.q_proj.q_groups',\n",
      " 'model.layers.26.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.26.self_attn.q_proj.q_scale',\n",
      " 'model.layers.26.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.26.self_attn.q_proj.q_weight',\n",
      " 'model.layers.26.self_attn.v_proj.q_groups',\n",
      " 'model.layers.26.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.26.self_attn.v_proj.q_scale',\n",
      " 'model.layers.26.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.26.self_attn.v_proj.q_weight',\n",
      " 'model.layers.27.input_layernorm.weight',\n",
      " 'model.layers.27.mlp.down_proj.q_groups',\n",
      " 'model.layers.27.mlp.down_proj.q_invperm',\n",
      " 'model.layers.27.mlp.down_proj.q_scale',\n",
      " 'model.layers.27.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.27.mlp.down_proj.q_weight',\n",
      " 'model.layers.27.mlp.gate_proj.q_groups',\n",
      " 'model.layers.27.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.27.mlp.gate_proj.q_scale',\n",
      " 'model.layers.27.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.27.mlp.gate_proj.q_weight',\n",
      " 'model.layers.27.mlp.up_proj.q_groups',\n",
      " 'model.layers.27.mlp.up_proj.q_invperm',\n",
      " 'model.layers.27.mlp.up_proj.q_scale',\n",
      " 'model.layers.27.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.27.mlp.up_proj.q_weight',\n",
      " 'model.layers.27.post_attention_layernorm.weight',\n",
      " 'model.layers.27.self_attn.k_proj.q_groups',\n",
      " 'model.layers.27.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.27.self_attn.k_proj.q_scale',\n",
      " 'model.layers.27.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.27.self_attn.k_proj.q_weight',\n",
      " 'model.layers.27.self_attn.o_proj.q_groups',\n",
      " 'model.layers.27.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.27.self_attn.o_proj.q_scale',\n",
      " 'model.layers.27.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.27.self_attn.o_proj.q_weight',\n",
      " 'model.layers.27.self_attn.q_proj.q_groups',\n",
      " 'model.layers.27.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.27.self_attn.q_proj.q_scale',\n",
      " 'model.layers.27.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.27.self_attn.q_proj.q_weight',\n",
      " 'model.layers.27.self_attn.v_proj.q_groups',\n",
      " 'model.layers.27.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.27.self_attn.v_proj.q_scale',\n",
      " 'model.layers.27.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.27.self_attn.v_proj.q_weight',\n",
      " 'model.layers.28.input_layernorm.weight',\n",
      " 'model.layers.28.mlp.down_proj.q_groups',\n",
      " 'model.layers.28.mlp.down_proj.q_invperm',\n",
      " 'model.layers.28.mlp.down_proj.q_scale',\n",
      " 'model.layers.28.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.28.mlp.down_proj.q_weight',\n",
      " 'model.layers.28.mlp.gate_proj.q_groups',\n",
      " 'model.layers.28.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.28.mlp.gate_proj.q_scale',\n",
      " 'model.layers.28.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.28.mlp.gate_proj.q_weight',\n",
      " 'model.layers.28.mlp.up_proj.q_groups',\n",
      " 'model.layers.28.mlp.up_proj.q_invperm',\n",
      " 'model.layers.28.mlp.up_proj.q_scale',\n",
      " 'model.layers.28.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.28.mlp.up_proj.q_weight',\n",
      " 'model.layers.28.post_attention_layernorm.weight',\n",
      " 'model.layers.28.self_attn.k_proj.q_groups',\n",
      " 'model.layers.28.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.28.self_attn.k_proj.q_scale',\n",
      " 'model.layers.28.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.28.self_attn.k_proj.q_weight',\n",
      " 'model.layers.28.self_attn.o_proj.q_groups',\n",
      " 'model.layers.28.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.28.self_attn.o_proj.q_scale',\n",
      " 'model.layers.28.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.28.self_attn.o_proj.q_weight',\n",
      " 'model.layers.28.self_attn.q_proj.q_groups',\n",
      " 'model.layers.28.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.28.self_attn.q_proj.q_scale',\n",
      " 'model.layers.28.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.28.self_attn.q_proj.q_weight',\n",
      " 'model.layers.28.self_attn.v_proj.q_groups',\n",
      " 'model.layers.28.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.28.self_attn.v_proj.q_scale',\n",
      " 'model.layers.28.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.28.self_attn.v_proj.q_weight',\n",
      " 'model.layers.29.input_layernorm.weight',\n",
      " 'model.layers.29.mlp.down_proj.q_groups',\n",
      " 'model.layers.29.mlp.down_proj.q_invperm',\n",
      " 'model.layers.29.mlp.down_proj.q_scale',\n",
      " 'model.layers.29.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.29.mlp.down_proj.q_weight',\n",
      " 'model.layers.29.mlp.gate_proj.q_groups',\n",
      " 'model.layers.29.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.29.mlp.gate_proj.q_scale',\n",
      " 'model.layers.29.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.29.mlp.gate_proj.q_weight',\n",
      " 'model.layers.29.mlp.up_proj.q_groups',\n",
      " 'model.layers.29.mlp.up_proj.q_invperm',\n",
      " 'model.layers.29.mlp.up_proj.q_scale',\n",
      " 'model.layers.29.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.29.mlp.up_proj.q_weight',\n",
      " 'model.layers.29.post_attention_layernorm.weight',\n",
      " 'model.layers.29.self_attn.k_proj.q_groups',\n",
      " 'model.layers.29.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.29.self_attn.k_proj.q_scale',\n",
      " 'model.layers.29.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.29.self_attn.k_proj.q_weight',\n",
      " 'model.layers.29.self_attn.o_proj.q_groups',\n",
      " 'model.layers.29.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.29.self_attn.o_proj.q_scale',\n",
      " 'model.layers.29.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.29.self_attn.o_proj.q_weight',\n",
      " 'model.layers.29.self_attn.q_proj.q_groups',\n",
      " 'model.layers.29.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.29.self_attn.q_proj.q_scale',\n",
      " 'model.layers.29.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.29.self_attn.q_proj.q_weight',\n",
      " 'model.layers.29.self_attn.v_proj.q_groups',\n",
      " 'model.layers.29.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.29.self_attn.v_proj.q_scale',\n",
      " 'model.layers.29.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.29.self_attn.v_proj.q_weight',\n",
      " 'model.layers.3.input_layernorm.weight',\n",
      " 'model.layers.3.mlp.down_proj.q_groups',\n",
      " 'model.layers.3.mlp.down_proj.q_invperm',\n",
      " 'model.layers.3.mlp.down_proj.q_scale',\n",
      " 'model.layers.3.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.3.mlp.down_proj.q_weight',\n",
      " 'model.layers.3.mlp.gate_proj.q_groups',\n",
      " 'model.layers.3.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.3.mlp.gate_proj.q_scale',\n",
      " 'model.layers.3.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.3.mlp.gate_proj.q_weight',\n",
      " 'model.layers.3.mlp.up_proj.q_groups',\n",
      " 'model.layers.3.mlp.up_proj.q_invperm',\n",
      " 'model.layers.3.mlp.up_proj.q_scale',\n",
      " 'model.layers.3.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.3.mlp.up_proj.q_weight',\n",
      " 'model.layers.3.post_attention_layernorm.weight',\n",
      " 'model.layers.3.self_attn.k_proj.q_groups',\n",
      " 'model.layers.3.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.3.self_attn.k_proj.q_scale',\n",
      " 'model.layers.3.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.3.self_attn.k_proj.q_weight',\n",
      " 'model.layers.3.self_attn.o_proj.q_groups',\n",
      " 'model.layers.3.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.3.self_attn.o_proj.q_scale',\n",
      " 'model.layers.3.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.3.self_attn.o_proj.q_weight',\n",
      " 'model.layers.3.self_attn.q_proj.q_groups',\n",
      " 'model.layers.3.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.3.self_attn.q_proj.q_scale',\n",
      " 'model.layers.3.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.3.self_attn.q_proj.q_weight',\n",
      " 'model.layers.3.self_attn.v_proj.q_groups',\n",
      " 'model.layers.3.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.3.self_attn.v_proj.q_scale',\n",
      " 'model.layers.3.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.3.self_attn.v_proj.q_weight',\n",
      " 'model.layers.30.input_layernorm.weight',\n",
      " 'model.layers.30.mlp.down_proj.q_groups',\n",
      " 'model.layers.30.mlp.down_proj.q_invperm',\n",
      " 'model.layers.30.mlp.down_proj.q_scale',\n",
      " 'model.layers.30.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.30.mlp.down_proj.q_weight',\n",
      " 'model.layers.30.mlp.gate_proj.q_groups',\n",
      " 'model.layers.30.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.30.mlp.gate_proj.q_scale',\n",
      " 'model.layers.30.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.30.mlp.gate_proj.q_weight',\n",
      " 'model.layers.30.mlp.up_proj.q_groups',\n",
      " 'model.layers.30.mlp.up_proj.q_invperm',\n",
      " 'model.layers.30.mlp.up_proj.q_scale',\n",
      " 'model.layers.30.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.30.mlp.up_proj.q_weight',\n",
      " 'model.layers.30.post_attention_layernorm.weight',\n",
      " 'model.layers.30.self_attn.k_proj.q_groups',\n",
      " 'model.layers.30.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.30.self_attn.k_proj.q_scale',\n",
      " 'model.layers.30.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.30.self_attn.k_proj.q_weight',\n",
      " 'model.layers.30.self_attn.o_proj.q_groups',\n",
      " 'model.layers.30.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.30.self_attn.o_proj.q_scale',\n",
      " 'model.layers.30.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.30.self_attn.o_proj.q_weight',\n",
      " 'model.layers.30.self_attn.q_proj.q_groups',\n",
      " 'model.layers.30.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.30.self_attn.q_proj.q_scale',\n",
      " 'model.layers.30.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.30.self_attn.q_proj.q_weight',\n",
      " 'model.layers.30.self_attn.v_proj.q_groups',\n",
      " 'model.layers.30.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.30.self_attn.v_proj.q_scale',\n",
      " 'model.layers.30.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.30.self_attn.v_proj.q_weight',\n",
      " 'model.layers.31.input_layernorm.weight',\n",
      " 'model.layers.31.mlp.down_proj.q_groups',\n",
      " 'model.layers.31.mlp.down_proj.q_invperm',\n",
      " 'model.layers.31.mlp.down_proj.q_scale',\n",
      " 'model.layers.31.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.31.mlp.down_proj.q_weight',\n",
      " 'model.layers.31.mlp.gate_proj.q_groups',\n",
      " 'model.layers.31.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.31.mlp.gate_proj.q_scale',\n",
      " 'model.layers.31.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.31.mlp.gate_proj.q_weight',\n",
      " 'model.layers.31.mlp.up_proj.q_groups',\n",
      " 'model.layers.31.mlp.up_proj.q_invperm',\n",
      " 'model.layers.31.mlp.up_proj.q_scale',\n",
      " 'model.layers.31.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.31.mlp.up_proj.q_weight',\n",
      " 'model.layers.31.post_attention_layernorm.weight',\n",
      " 'model.layers.31.self_attn.k_proj.q_groups',\n",
      " 'model.layers.31.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.31.self_attn.k_proj.q_scale',\n",
      " 'model.layers.31.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.31.self_attn.k_proj.q_weight',\n",
      " 'model.layers.31.self_attn.o_proj.q_groups',\n",
      " 'model.layers.31.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.31.self_attn.o_proj.q_scale',\n",
      " 'model.layers.31.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.31.self_attn.o_proj.q_weight',\n",
      " 'model.layers.31.self_attn.q_proj.q_groups',\n",
      " 'model.layers.31.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.31.self_attn.q_proj.q_scale',\n",
      " 'model.layers.31.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.31.self_attn.q_proj.q_weight',\n",
      " 'model.layers.31.self_attn.v_proj.q_groups',\n",
      " 'model.layers.31.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.31.self_attn.v_proj.q_scale',\n",
      " 'model.layers.31.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.31.self_attn.v_proj.q_weight',\n",
      " 'model.layers.32.input_layernorm.weight',\n",
      " 'model.layers.32.mlp.down_proj.q_groups',\n",
      " 'model.layers.32.mlp.down_proj.q_invperm',\n",
      " 'model.layers.32.mlp.down_proj.q_scale',\n",
      " 'model.layers.32.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.32.mlp.down_proj.q_weight',\n",
      " 'model.layers.32.mlp.gate_proj.q_groups',\n",
      " 'model.layers.32.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.32.mlp.gate_proj.q_scale',\n",
      " 'model.layers.32.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.32.mlp.gate_proj.q_weight',\n",
      " 'model.layers.32.mlp.up_proj.q_groups',\n",
      " 'model.layers.32.mlp.up_proj.q_invperm',\n",
      " 'model.layers.32.mlp.up_proj.q_scale',\n",
      " 'model.layers.32.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.32.mlp.up_proj.q_weight',\n",
      " 'model.layers.32.post_attention_layernorm.weight',\n",
      " 'model.layers.32.self_attn.k_proj.q_groups',\n",
      " 'model.layers.32.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.32.self_attn.k_proj.q_scale',\n",
      " 'model.layers.32.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.32.self_attn.k_proj.q_weight',\n",
      " 'model.layers.32.self_attn.o_proj.q_groups',\n",
      " 'model.layers.32.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.32.self_attn.o_proj.q_scale',\n",
      " 'model.layers.32.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.32.self_attn.o_proj.q_weight',\n",
      " 'model.layers.32.self_attn.q_proj.q_groups',\n",
      " 'model.layers.32.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.32.self_attn.q_proj.q_scale',\n",
      " 'model.layers.32.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.32.self_attn.q_proj.q_weight',\n",
      " 'model.layers.32.self_attn.v_proj.q_groups',\n",
      " 'model.layers.32.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.32.self_attn.v_proj.q_scale',\n",
      " 'model.layers.32.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.32.self_attn.v_proj.q_weight',\n",
      " 'model.layers.33.input_layernorm.weight',\n",
      " 'model.layers.33.mlp.down_proj.q_groups',\n",
      " 'model.layers.33.mlp.down_proj.q_invperm',\n",
      " 'model.layers.33.mlp.down_proj.q_scale',\n",
      " 'model.layers.33.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.33.mlp.down_proj.q_weight',\n",
      " 'model.layers.33.mlp.gate_proj.q_groups',\n",
      " 'model.layers.33.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.33.mlp.gate_proj.q_scale',\n",
      " 'model.layers.33.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.33.mlp.gate_proj.q_weight',\n",
      " 'model.layers.33.mlp.up_proj.q_groups',\n",
      " 'model.layers.33.mlp.up_proj.q_invperm',\n",
      " 'model.layers.33.mlp.up_proj.q_scale',\n",
      " 'model.layers.33.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.33.mlp.up_proj.q_weight',\n",
      " 'model.layers.33.post_attention_layernorm.weight',\n",
      " 'model.layers.33.self_attn.k_proj.q_groups',\n",
      " 'model.layers.33.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.33.self_attn.k_proj.q_scale',\n",
      " 'model.layers.33.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.33.self_attn.k_proj.q_weight',\n",
      " 'model.layers.33.self_attn.o_proj.q_groups',\n",
      " 'model.layers.33.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.33.self_attn.o_proj.q_scale',\n",
      " 'model.layers.33.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.33.self_attn.o_proj.q_weight',\n",
      " 'model.layers.33.self_attn.q_proj.q_groups',\n",
      " 'model.layers.33.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.33.self_attn.q_proj.q_scale',\n",
      " 'model.layers.33.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.33.self_attn.q_proj.q_weight',\n",
      " 'model.layers.33.self_attn.v_proj.q_groups',\n",
      " 'model.layers.33.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.33.self_attn.v_proj.q_scale',\n",
      " 'model.layers.33.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.33.self_attn.v_proj.q_weight',\n",
      " 'model.layers.34.input_layernorm.weight',\n",
      " 'model.layers.34.mlp.down_proj.q_groups',\n",
      " 'model.layers.34.mlp.down_proj.q_invperm',\n",
      " 'model.layers.34.mlp.down_proj.q_scale',\n",
      " 'model.layers.34.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.34.mlp.down_proj.q_weight',\n",
      " 'model.layers.34.mlp.gate_proj.q_groups',\n",
      " 'model.layers.34.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.34.mlp.gate_proj.q_scale',\n",
      " 'model.layers.34.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.34.mlp.gate_proj.q_weight',\n",
      " 'model.layers.34.mlp.up_proj.q_groups',\n",
      " 'model.layers.34.mlp.up_proj.q_invperm',\n",
      " 'model.layers.34.mlp.up_proj.q_scale',\n",
      " 'model.layers.34.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.34.mlp.up_proj.q_weight',\n",
      " 'model.layers.34.post_attention_layernorm.weight',\n",
      " 'model.layers.34.self_attn.k_proj.q_groups',\n",
      " 'model.layers.34.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.34.self_attn.k_proj.q_scale',\n",
      " 'model.layers.34.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.34.self_attn.k_proj.q_weight',\n",
      " 'model.layers.34.self_attn.o_proj.q_groups',\n",
      " 'model.layers.34.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.34.self_attn.o_proj.q_scale',\n",
      " 'model.layers.34.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.34.self_attn.o_proj.q_weight',\n",
      " 'model.layers.34.self_attn.q_proj.q_groups',\n",
      " 'model.layers.34.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.34.self_attn.q_proj.q_scale',\n",
      " 'model.layers.34.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.34.self_attn.q_proj.q_weight',\n",
      " 'model.layers.34.self_attn.v_proj.q_groups',\n",
      " 'model.layers.34.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.34.self_attn.v_proj.q_scale',\n",
      " 'model.layers.34.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.34.self_attn.v_proj.q_weight',\n",
      " 'model.layers.35.input_layernorm.weight',\n",
      " 'model.layers.35.mlp.down_proj.q_groups',\n",
      " 'model.layers.35.mlp.down_proj.q_invperm',\n",
      " 'model.layers.35.mlp.down_proj.q_scale',\n",
      " 'model.layers.35.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.35.mlp.down_proj.q_weight',\n",
      " 'model.layers.35.mlp.gate_proj.q_groups',\n",
      " 'model.layers.35.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.35.mlp.gate_proj.q_scale',\n",
      " 'model.layers.35.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.35.mlp.gate_proj.q_weight',\n",
      " 'model.layers.35.mlp.up_proj.q_groups',\n",
      " 'model.layers.35.mlp.up_proj.q_invperm',\n",
      " 'model.layers.35.mlp.up_proj.q_scale',\n",
      " 'model.layers.35.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.35.mlp.up_proj.q_weight',\n",
      " 'model.layers.35.post_attention_layernorm.weight',\n",
      " 'model.layers.35.self_attn.k_proj.q_groups',\n",
      " 'model.layers.35.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.35.self_attn.k_proj.q_scale',\n",
      " 'model.layers.35.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.35.self_attn.k_proj.q_weight',\n",
      " 'model.layers.35.self_attn.o_proj.q_groups',\n",
      " 'model.layers.35.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.35.self_attn.o_proj.q_scale',\n",
      " 'model.layers.35.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.35.self_attn.o_proj.q_weight',\n",
      " 'model.layers.35.self_attn.q_proj.q_groups',\n",
      " 'model.layers.35.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.35.self_attn.q_proj.q_scale',\n",
      " 'model.layers.35.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.35.self_attn.q_proj.q_weight',\n",
      " 'model.layers.35.self_attn.v_proj.q_groups',\n",
      " 'model.layers.35.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.35.self_attn.v_proj.q_scale',\n",
      " 'model.layers.35.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.35.self_attn.v_proj.q_weight',\n",
      " 'model.layers.36.input_layernorm.weight',\n",
      " 'model.layers.36.mlp.down_proj.q_groups',\n",
      " 'model.layers.36.mlp.down_proj.q_invperm',\n",
      " 'model.layers.36.mlp.down_proj.q_scale',\n",
      " 'model.layers.36.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.36.mlp.down_proj.q_weight',\n",
      " 'model.layers.36.mlp.gate_proj.q_groups',\n",
      " 'model.layers.36.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.36.mlp.gate_proj.q_scale',\n",
      " 'model.layers.36.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.36.mlp.gate_proj.q_weight',\n",
      " 'model.layers.36.mlp.up_proj.q_groups',\n",
      " 'model.layers.36.mlp.up_proj.q_invperm',\n",
      " 'model.layers.36.mlp.up_proj.q_scale',\n",
      " 'model.layers.36.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.36.mlp.up_proj.q_weight',\n",
      " 'model.layers.36.post_attention_layernorm.weight',\n",
      " 'model.layers.36.self_attn.k_proj.q_groups',\n",
      " 'model.layers.36.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.36.self_attn.k_proj.q_scale',\n",
      " 'model.layers.36.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.36.self_attn.k_proj.q_weight',\n",
      " 'model.layers.36.self_attn.o_proj.q_groups',\n",
      " 'model.layers.36.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.36.self_attn.o_proj.q_scale',\n",
      " 'model.layers.36.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.36.self_attn.o_proj.q_weight',\n",
      " 'model.layers.36.self_attn.q_proj.q_groups',\n",
      " 'model.layers.36.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.36.self_attn.q_proj.q_scale',\n",
      " 'model.layers.36.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.36.self_attn.q_proj.q_weight',\n",
      " 'model.layers.36.self_attn.v_proj.q_groups',\n",
      " 'model.layers.36.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.36.self_attn.v_proj.q_scale',\n",
      " 'model.layers.36.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.36.self_attn.v_proj.q_weight',\n",
      " 'model.layers.37.input_layernorm.weight',\n",
      " 'model.layers.37.mlp.down_proj.q_groups',\n",
      " 'model.layers.37.mlp.down_proj.q_invperm',\n",
      " 'model.layers.37.mlp.down_proj.q_scale',\n",
      " 'model.layers.37.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.37.mlp.down_proj.q_weight',\n",
      " 'model.layers.37.mlp.gate_proj.q_groups',\n",
      " 'model.layers.37.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.37.mlp.gate_proj.q_scale',\n",
      " 'model.layers.37.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.37.mlp.gate_proj.q_weight',\n",
      " 'model.layers.37.mlp.up_proj.q_groups',\n",
      " 'model.layers.37.mlp.up_proj.q_invperm',\n",
      " 'model.layers.37.mlp.up_proj.q_scale',\n",
      " 'model.layers.37.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.37.mlp.up_proj.q_weight',\n",
      " 'model.layers.37.post_attention_layernorm.weight',\n",
      " 'model.layers.37.self_attn.k_proj.q_groups',\n",
      " 'model.layers.37.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.37.self_attn.k_proj.q_scale',\n",
      " 'model.layers.37.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.37.self_attn.k_proj.q_weight',\n",
      " 'model.layers.37.self_attn.o_proj.q_groups',\n",
      " 'model.layers.37.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.37.self_attn.o_proj.q_scale',\n",
      " 'model.layers.37.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.37.self_attn.o_proj.q_weight',\n",
      " 'model.layers.37.self_attn.q_proj.q_groups',\n",
      " 'model.layers.37.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.37.self_attn.q_proj.q_scale',\n",
      " 'model.layers.37.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.37.self_attn.q_proj.q_weight',\n",
      " 'model.layers.37.self_attn.v_proj.q_groups',\n",
      " 'model.layers.37.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.37.self_attn.v_proj.q_scale',\n",
      " 'model.layers.37.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.37.self_attn.v_proj.q_weight',\n",
      " 'model.layers.38.input_layernorm.weight',\n",
      " 'model.layers.38.mlp.down_proj.q_groups',\n",
      " 'model.layers.38.mlp.down_proj.q_invperm',\n",
      " 'model.layers.38.mlp.down_proj.q_scale',\n",
      " 'model.layers.38.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.38.mlp.down_proj.q_weight',\n",
      " 'model.layers.38.mlp.gate_proj.q_groups',\n",
      " 'model.layers.38.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.38.mlp.gate_proj.q_scale',\n",
      " 'model.layers.38.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.38.mlp.gate_proj.q_weight',\n",
      " 'model.layers.38.mlp.up_proj.q_groups',\n",
      " 'model.layers.38.mlp.up_proj.q_invperm',\n",
      " 'model.layers.38.mlp.up_proj.q_scale',\n",
      " 'model.layers.38.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.38.mlp.up_proj.q_weight',\n",
      " 'model.layers.38.post_attention_layernorm.weight',\n",
      " 'model.layers.38.self_attn.k_proj.q_groups',\n",
      " 'model.layers.38.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.38.self_attn.k_proj.q_scale',\n",
      " 'model.layers.38.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.38.self_attn.k_proj.q_weight',\n",
      " 'model.layers.38.self_attn.o_proj.q_groups',\n",
      " 'model.layers.38.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.38.self_attn.o_proj.q_scale',\n",
      " 'model.layers.38.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.38.self_attn.o_proj.q_weight',\n",
      " 'model.layers.38.self_attn.q_proj.q_groups',\n",
      " 'model.layers.38.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.38.self_attn.q_proj.q_scale',\n",
      " 'model.layers.38.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.38.self_attn.q_proj.q_weight',\n",
      " 'model.layers.38.self_attn.v_proj.q_groups',\n",
      " 'model.layers.38.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.38.self_attn.v_proj.q_scale',\n",
      " 'model.layers.38.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.38.self_attn.v_proj.q_weight',\n",
      " 'model.layers.39.input_layernorm.weight',\n",
      " 'model.layers.39.mlp.down_proj.q_groups',\n",
      " 'model.layers.39.mlp.down_proj.q_invperm',\n",
      " 'model.layers.39.mlp.down_proj.q_scale',\n",
      " 'model.layers.39.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.39.mlp.down_proj.q_weight',\n",
      " 'model.layers.39.mlp.gate_proj.q_groups',\n",
      " 'model.layers.39.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.39.mlp.gate_proj.q_scale',\n",
      " 'model.layers.39.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.39.mlp.gate_proj.q_weight',\n",
      " 'model.layers.39.mlp.up_proj.q_groups',\n",
      " 'model.layers.39.mlp.up_proj.q_invperm',\n",
      " 'model.layers.39.mlp.up_proj.q_scale',\n",
      " 'model.layers.39.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.39.mlp.up_proj.q_weight',\n",
      " 'model.layers.39.post_attention_layernorm.weight',\n",
      " 'model.layers.39.self_attn.k_proj.q_groups',\n",
      " 'model.layers.39.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.39.self_attn.k_proj.q_scale',\n",
      " 'model.layers.39.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.39.self_attn.k_proj.q_weight',\n",
      " 'model.layers.39.self_attn.o_proj.q_groups',\n",
      " 'model.layers.39.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.39.self_attn.o_proj.q_scale',\n",
      " 'model.layers.39.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.39.self_attn.o_proj.q_weight',\n",
      " 'model.layers.39.self_attn.q_proj.q_groups',\n",
      " 'model.layers.39.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.39.self_attn.q_proj.q_scale',\n",
      " 'model.layers.39.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.39.self_attn.q_proj.q_weight',\n",
      " 'model.layers.39.self_attn.v_proj.q_groups',\n",
      " 'model.layers.39.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.39.self_attn.v_proj.q_scale',\n",
      " 'model.layers.39.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.39.self_attn.v_proj.q_weight',\n",
      " 'model.layers.4.input_layernorm.weight',\n",
      " 'model.layers.4.mlp.down_proj.q_groups',\n",
      " 'model.layers.4.mlp.down_proj.q_invperm',\n",
      " 'model.layers.4.mlp.down_proj.q_scale',\n",
      " 'model.layers.4.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.4.mlp.down_proj.q_weight',\n",
      " 'model.layers.4.mlp.gate_proj.q_groups',\n",
      " 'model.layers.4.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.4.mlp.gate_proj.q_scale',\n",
      " 'model.layers.4.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.4.mlp.gate_proj.q_weight',\n",
      " 'model.layers.4.mlp.up_proj.q_groups',\n",
      " 'model.layers.4.mlp.up_proj.q_invperm',\n",
      " 'model.layers.4.mlp.up_proj.q_scale',\n",
      " 'model.layers.4.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.4.mlp.up_proj.q_weight',\n",
      " 'model.layers.4.post_attention_layernorm.weight',\n",
      " 'model.layers.4.self_attn.k_proj.q_groups',\n",
      " 'model.layers.4.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.4.self_attn.k_proj.q_scale',\n",
      " 'model.layers.4.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.4.self_attn.k_proj.q_weight',\n",
      " 'model.layers.4.self_attn.o_proj.q_groups',\n",
      " 'model.layers.4.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.4.self_attn.o_proj.q_scale',\n",
      " 'model.layers.4.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.4.self_attn.o_proj.q_weight',\n",
      " 'model.layers.4.self_attn.q_proj.q_groups',\n",
      " 'model.layers.4.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.4.self_attn.q_proj.q_scale',\n",
      " 'model.layers.4.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.4.self_attn.q_proj.q_weight',\n",
      " 'model.layers.4.self_attn.v_proj.q_groups',\n",
      " 'model.layers.4.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.4.self_attn.v_proj.q_scale',\n",
      " 'model.layers.4.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.4.self_attn.v_proj.q_weight',\n",
      " 'model.layers.5.input_layernorm.weight',\n",
      " 'model.layers.5.mlp.down_proj.q_groups',\n",
      " 'model.layers.5.mlp.down_proj.q_invperm',\n",
      " 'model.layers.5.mlp.down_proj.q_scale',\n",
      " 'model.layers.5.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.5.mlp.down_proj.q_weight',\n",
      " 'model.layers.5.mlp.gate_proj.q_groups',\n",
      " 'model.layers.5.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.5.mlp.gate_proj.q_scale',\n",
      " 'model.layers.5.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.5.mlp.gate_proj.q_weight',\n",
      " 'model.layers.5.mlp.up_proj.q_groups',\n",
      " 'model.layers.5.mlp.up_proj.q_invperm',\n",
      " 'model.layers.5.mlp.up_proj.q_scale',\n",
      " 'model.layers.5.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.5.mlp.up_proj.q_weight',\n",
      " 'model.layers.5.post_attention_layernorm.weight',\n",
      " 'model.layers.5.self_attn.k_proj.q_groups',\n",
      " 'model.layers.5.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.5.self_attn.k_proj.q_scale',\n",
      " 'model.layers.5.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.5.self_attn.k_proj.q_weight',\n",
      " 'model.layers.5.self_attn.o_proj.q_groups',\n",
      " 'model.layers.5.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.5.self_attn.o_proj.q_scale',\n",
      " 'model.layers.5.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.5.self_attn.o_proj.q_weight',\n",
      " 'model.layers.5.self_attn.q_proj.q_groups',\n",
      " 'model.layers.5.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.5.self_attn.q_proj.q_scale',\n",
      " 'model.layers.5.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.5.self_attn.q_proj.q_weight',\n",
      " 'model.layers.5.self_attn.v_proj.q_groups',\n",
      " 'model.layers.5.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.5.self_attn.v_proj.q_scale',\n",
      " 'model.layers.5.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.5.self_attn.v_proj.q_weight',\n",
      " 'model.layers.6.input_layernorm.weight',\n",
      " 'model.layers.6.mlp.down_proj.q_groups',\n",
      " 'model.layers.6.mlp.down_proj.q_invperm',\n",
      " 'model.layers.6.mlp.down_proj.q_scale',\n",
      " 'model.layers.6.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.6.mlp.down_proj.q_weight',\n",
      " 'model.layers.6.mlp.gate_proj.q_groups',\n",
      " 'model.layers.6.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.6.mlp.gate_proj.q_scale',\n",
      " 'model.layers.6.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.6.mlp.gate_proj.q_weight',\n",
      " 'model.layers.6.mlp.up_proj.q_groups',\n",
      " 'model.layers.6.mlp.up_proj.q_invperm',\n",
      " 'model.layers.6.mlp.up_proj.q_scale',\n",
      " 'model.layers.6.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.6.mlp.up_proj.q_weight',\n",
      " 'model.layers.6.post_attention_layernorm.weight',\n",
      " 'model.layers.6.self_attn.k_proj.q_groups',\n",
      " 'model.layers.6.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.6.self_attn.k_proj.q_scale',\n",
      " 'model.layers.6.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.6.self_attn.k_proj.q_weight',\n",
      " 'model.layers.6.self_attn.o_proj.q_groups',\n",
      " 'model.layers.6.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.6.self_attn.o_proj.q_scale',\n",
      " 'model.layers.6.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.6.self_attn.o_proj.q_weight',\n",
      " 'model.layers.6.self_attn.q_proj.q_groups',\n",
      " 'model.layers.6.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.6.self_attn.q_proj.q_scale',\n",
      " 'model.layers.6.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.6.self_attn.q_proj.q_weight',\n",
      " 'model.layers.6.self_attn.v_proj.q_groups',\n",
      " 'model.layers.6.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.6.self_attn.v_proj.q_scale',\n",
      " 'model.layers.6.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.6.self_attn.v_proj.q_weight',\n",
      " 'model.layers.7.input_layernorm.weight',\n",
      " 'model.layers.7.mlp.down_proj.q_groups',\n",
      " 'model.layers.7.mlp.down_proj.q_invperm',\n",
      " 'model.layers.7.mlp.down_proj.q_scale',\n",
      " 'model.layers.7.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.7.mlp.down_proj.q_weight',\n",
      " 'model.layers.7.mlp.gate_proj.q_groups',\n",
      " 'model.layers.7.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.7.mlp.gate_proj.q_scale',\n",
      " 'model.layers.7.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.7.mlp.gate_proj.q_weight',\n",
      " 'model.layers.7.mlp.up_proj.q_groups',\n",
      " 'model.layers.7.mlp.up_proj.q_invperm',\n",
      " 'model.layers.7.mlp.up_proj.q_scale',\n",
      " 'model.layers.7.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.7.mlp.up_proj.q_weight',\n",
      " 'model.layers.7.post_attention_layernorm.weight',\n",
      " 'model.layers.7.self_attn.k_proj.q_groups',\n",
      " 'model.layers.7.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.7.self_attn.k_proj.q_scale',\n",
      " 'model.layers.7.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.7.self_attn.k_proj.q_weight',\n",
      " 'model.layers.7.self_attn.o_proj.q_groups',\n",
      " 'model.layers.7.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.7.self_attn.o_proj.q_scale',\n",
      " 'model.layers.7.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.7.self_attn.o_proj.q_weight',\n",
      " 'model.layers.7.self_attn.q_proj.q_groups',\n",
      " 'model.layers.7.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.7.self_attn.q_proj.q_scale',\n",
      " 'model.layers.7.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.7.self_attn.q_proj.q_weight',\n",
      " 'model.layers.7.self_attn.v_proj.q_groups',\n",
      " 'model.layers.7.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.7.self_attn.v_proj.q_scale',\n",
      " 'model.layers.7.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.7.self_attn.v_proj.q_weight',\n",
      " 'model.layers.8.input_layernorm.weight',\n",
      " 'model.layers.8.mlp.down_proj.q_groups',\n",
      " 'model.layers.8.mlp.down_proj.q_invperm',\n",
      " 'model.layers.8.mlp.down_proj.q_scale',\n",
      " 'model.layers.8.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.8.mlp.down_proj.q_weight',\n",
      " 'model.layers.8.mlp.gate_proj.q_groups',\n",
      " 'model.layers.8.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.8.mlp.gate_proj.q_scale',\n",
      " 'model.layers.8.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.8.mlp.gate_proj.q_weight',\n",
      " 'model.layers.8.mlp.up_proj.q_groups',\n",
      " 'model.layers.8.mlp.up_proj.q_invperm',\n",
      " 'model.layers.8.mlp.up_proj.q_scale',\n",
      " 'model.layers.8.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.8.mlp.up_proj.q_weight',\n",
      " 'model.layers.8.post_attention_layernorm.weight',\n",
      " 'model.layers.8.self_attn.k_proj.q_groups',\n",
      " 'model.layers.8.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.8.self_attn.k_proj.q_scale',\n",
      " 'model.layers.8.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.8.self_attn.k_proj.q_weight',\n",
      " 'model.layers.8.self_attn.o_proj.q_groups',\n",
      " 'model.layers.8.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.8.self_attn.o_proj.q_scale',\n",
      " 'model.layers.8.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.8.self_attn.o_proj.q_weight',\n",
      " 'model.layers.8.self_attn.q_proj.q_groups',\n",
      " 'model.layers.8.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.8.self_attn.q_proj.q_scale',\n",
      " 'model.layers.8.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.8.self_attn.q_proj.q_weight',\n",
      " 'model.layers.8.self_attn.v_proj.q_groups',\n",
      " 'model.layers.8.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.8.self_attn.v_proj.q_scale',\n",
      " 'model.layers.8.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.8.self_attn.v_proj.q_weight',\n",
      " 'model.layers.9.input_layernorm.weight',\n",
      " 'model.layers.9.mlp.down_proj.q_groups',\n",
      " 'model.layers.9.mlp.down_proj.q_invperm',\n",
      " 'model.layers.9.mlp.down_proj.q_scale',\n",
      " 'model.layers.9.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.9.mlp.down_proj.q_weight',\n",
      " 'model.layers.9.mlp.gate_proj.q_groups',\n",
      " 'model.layers.9.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.9.mlp.gate_proj.q_scale',\n",
      " 'model.layers.9.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.9.mlp.gate_proj.q_weight',\n",
      " 'model.layers.9.mlp.up_proj.q_groups',\n",
      " 'model.layers.9.mlp.up_proj.q_invperm',\n",
      " 'model.layers.9.mlp.up_proj.q_scale',\n",
      " 'model.layers.9.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.9.mlp.up_proj.q_weight',\n",
      " 'model.layers.9.post_attention_layernorm.weight',\n",
      " 'model.layers.9.self_attn.k_proj.q_groups',\n",
      " 'model.layers.9.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.9.self_attn.k_proj.q_scale',\n",
      " 'model.layers.9.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.9.self_attn.k_proj.q_weight',\n",
      " 'model.layers.9.self_attn.o_proj.q_groups',\n",
      " 'model.layers.9.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.9.self_attn.o_proj.q_scale',\n",
      " 'model.layers.9.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.9.self_attn.o_proj.q_weight',\n",
      " 'model.layers.9.self_attn.q_proj.q_groups',\n",
      " 'model.layers.9.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.9.self_attn.q_proj.q_scale',\n",
      " 'model.layers.9.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.9.self_attn.q_proj.q_weight',\n",
      " 'model.layers.9.self_attn.v_proj.q_groups',\n",
      " 'model.layers.9.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.9.self_attn.v_proj.q_scale',\n",
      " 'model.layers.9.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.9.self_attn.v_proj.q_weight',\n",
      " 'model.norm.weight',\n",
      " 'model.layers.40.input_layernorm.weight',\n",
      " 'model.layers.40.mlp.down_proj.q_groups',\n",
      " 'model.layers.40.mlp.down_proj.q_invperm',\n",
      " 'model.layers.40.mlp.down_proj.q_scale',\n",
      " 'model.layers.40.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.40.mlp.down_proj.q_weight',\n",
      " 'model.layers.40.mlp.gate_proj.q_groups',\n",
      " 'model.layers.40.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.40.mlp.gate_proj.q_scale',\n",
      " 'model.layers.40.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.40.mlp.gate_proj.q_weight',\n",
      " 'model.layers.40.mlp.up_proj.q_groups',\n",
      " 'model.layers.40.mlp.up_proj.q_invperm',\n",
      " 'model.layers.40.mlp.up_proj.q_scale',\n",
      " 'model.layers.40.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.40.mlp.up_proj.q_weight',\n",
      " 'model.layers.40.post_attention_layernorm.weight',\n",
      " 'model.layers.40.self_attn.k_proj.q_groups',\n",
      " 'model.layers.40.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.40.self_attn.k_proj.q_scale',\n",
      " 'model.layers.40.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.40.self_attn.k_proj.q_weight',\n",
      " 'model.layers.40.self_attn.o_proj.q_groups',\n",
      " 'model.layers.40.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.40.self_attn.o_proj.q_scale',\n",
      " 'model.layers.40.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.40.self_attn.o_proj.q_weight',\n",
      " 'model.layers.40.self_attn.q_proj.q_groups',\n",
      " 'model.layers.40.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.40.self_attn.q_proj.q_scale',\n",
      " 'model.layers.40.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.40.self_attn.q_proj.q_weight',\n",
      " 'model.layers.40.self_attn.v_proj.q_groups',\n",
      " 'model.layers.40.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.40.self_attn.v_proj.q_scale',\n",
      " 'model.layers.40.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.40.self_attn.v_proj.q_weight',\n",
      " 'model.layers.41.input_layernorm.weight',\n",
      " 'model.layers.41.mlp.down_proj.q_groups',\n",
      " 'model.layers.41.mlp.down_proj.q_invperm',\n",
      " 'model.layers.41.mlp.down_proj.q_scale',\n",
      " 'model.layers.41.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.41.mlp.down_proj.q_weight',\n",
      " 'model.layers.41.mlp.gate_proj.q_groups',\n",
      " 'model.layers.41.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.41.mlp.gate_proj.q_scale',\n",
      " 'model.layers.41.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.41.mlp.gate_proj.q_weight',\n",
      " 'model.layers.41.mlp.up_proj.q_groups',\n",
      " 'model.layers.41.mlp.up_proj.q_invperm',\n",
      " 'model.layers.41.mlp.up_proj.q_scale',\n",
      " 'model.layers.41.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.41.mlp.up_proj.q_weight',\n",
      " 'model.layers.41.post_attention_layernorm.weight',\n",
      " 'model.layers.41.self_attn.k_proj.q_groups',\n",
      " 'model.layers.41.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.41.self_attn.k_proj.q_scale',\n",
      " 'model.layers.41.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.41.self_attn.k_proj.q_weight',\n",
      " 'model.layers.41.self_attn.o_proj.q_groups',\n",
      " 'model.layers.41.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.41.self_attn.o_proj.q_scale',\n",
      " 'model.layers.41.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.41.self_attn.o_proj.q_weight',\n",
      " 'model.layers.41.self_attn.q_proj.q_groups',\n",
      " 'model.layers.41.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.41.self_attn.q_proj.q_scale',\n",
      " 'model.layers.41.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.41.self_attn.q_proj.q_weight',\n",
      " 'model.layers.41.self_attn.v_proj.q_groups',\n",
      " 'model.layers.41.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.41.self_attn.v_proj.q_scale',\n",
      " 'model.layers.41.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.41.self_attn.v_proj.q_weight',\n",
      " 'model.layers.42.input_layernorm.weight',\n",
      " 'model.layers.42.mlp.down_proj.q_groups',\n",
      " 'model.layers.42.mlp.down_proj.q_invperm',\n",
      " 'model.layers.42.mlp.down_proj.q_scale',\n",
      " 'model.layers.42.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.42.mlp.down_proj.q_weight',\n",
      " 'model.layers.42.mlp.gate_proj.q_groups',\n",
      " 'model.layers.42.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.42.mlp.gate_proj.q_scale',\n",
      " 'model.layers.42.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.42.mlp.gate_proj.q_weight',\n",
      " 'model.layers.42.mlp.up_proj.q_groups',\n",
      " 'model.layers.42.mlp.up_proj.q_invperm',\n",
      " 'model.layers.42.mlp.up_proj.q_scale',\n",
      " 'model.layers.42.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.42.mlp.up_proj.q_weight',\n",
      " 'model.layers.42.post_attention_layernorm.weight',\n",
      " 'model.layers.42.self_attn.k_proj.q_groups',\n",
      " 'model.layers.42.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.42.self_attn.k_proj.q_scale',\n",
      " 'model.layers.42.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.42.self_attn.k_proj.q_weight',\n",
      " 'model.layers.42.self_attn.o_proj.q_groups',\n",
      " 'model.layers.42.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.42.self_attn.o_proj.q_scale',\n",
      " 'model.layers.42.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.42.self_attn.o_proj.q_weight',\n",
      " 'model.layers.42.self_attn.q_proj.q_groups',\n",
      " 'model.layers.42.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.42.self_attn.q_proj.q_scale',\n",
      " 'model.layers.42.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.42.self_attn.q_proj.q_weight',\n",
      " 'model.layers.42.self_attn.v_proj.q_groups',\n",
      " 'model.layers.42.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.42.self_attn.v_proj.q_scale',\n",
      " 'model.layers.42.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.42.self_attn.v_proj.q_weight',\n",
      " 'model.layers.43.input_layernorm.weight',\n",
      " 'model.layers.43.mlp.down_proj.q_groups',\n",
      " 'model.layers.43.mlp.down_proj.q_invperm',\n",
      " 'model.layers.43.mlp.down_proj.q_scale',\n",
      " 'model.layers.43.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.43.mlp.down_proj.q_weight',\n",
      " 'model.layers.43.mlp.gate_proj.q_groups',\n",
      " 'model.layers.43.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.43.mlp.gate_proj.q_scale',\n",
      " 'model.layers.43.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.43.mlp.gate_proj.q_weight',\n",
      " 'model.layers.43.mlp.up_proj.q_groups',\n",
      " 'model.layers.43.mlp.up_proj.q_invperm',\n",
      " 'model.layers.43.mlp.up_proj.q_scale',\n",
      " 'model.layers.43.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.43.mlp.up_proj.q_weight',\n",
      " 'model.layers.43.post_attention_layernorm.weight',\n",
      " 'model.layers.43.self_attn.k_proj.q_groups',\n",
      " 'model.layers.43.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.43.self_attn.k_proj.q_scale',\n",
      " 'model.layers.43.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.43.self_attn.k_proj.q_weight',\n",
      " 'model.layers.43.self_attn.o_proj.q_groups',\n",
      " 'model.layers.43.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.43.self_attn.o_proj.q_scale',\n",
      " 'model.layers.43.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.43.self_attn.o_proj.q_weight',\n",
      " 'model.layers.43.self_attn.q_proj.q_groups',\n",
      " 'model.layers.43.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.43.self_attn.q_proj.q_scale',\n",
      " 'model.layers.43.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.43.self_attn.q_proj.q_weight',\n",
      " 'model.layers.43.self_attn.v_proj.q_groups',\n",
      " 'model.layers.43.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.43.self_attn.v_proj.q_scale',\n",
      " 'model.layers.43.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.43.self_attn.v_proj.q_weight',\n",
      " 'model.layers.44.input_layernorm.weight',\n",
      " 'model.layers.44.mlp.down_proj.q_groups',\n",
      " 'model.layers.44.mlp.down_proj.q_invperm',\n",
      " 'model.layers.44.mlp.down_proj.q_scale',\n",
      " 'model.layers.44.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.44.mlp.down_proj.q_weight',\n",
      " 'model.layers.44.mlp.gate_proj.q_groups',\n",
      " 'model.layers.44.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.44.mlp.gate_proj.q_scale',\n",
      " 'model.layers.44.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.44.mlp.gate_proj.q_weight',\n",
      " 'model.layers.44.mlp.up_proj.q_groups',\n",
      " 'model.layers.44.mlp.up_proj.q_invperm',\n",
      " 'model.layers.44.mlp.up_proj.q_scale',\n",
      " 'model.layers.44.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.44.mlp.up_proj.q_weight',\n",
      " 'model.layers.44.post_attention_layernorm.weight',\n",
      " 'model.layers.44.self_attn.k_proj.q_groups',\n",
      " 'model.layers.44.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.44.self_attn.k_proj.q_scale',\n",
      " 'model.layers.44.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.44.self_attn.k_proj.q_weight',\n",
      " 'model.layers.44.self_attn.o_proj.q_groups',\n",
      " 'model.layers.44.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.44.self_attn.o_proj.q_scale',\n",
      " 'model.layers.44.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.44.self_attn.o_proj.q_weight',\n",
      " 'model.layers.44.self_attn.q_proj.q_groups',\n",
      " 'model.layers.44.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.44.self_attn.q_proj.q_scale',\n",
      " 'model.layers.44.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.44.self_attn.q_proj.q_weight',\n",
      " 'model.layers.44.self_attn.v_proj.q_groups',\n",
      " 'model.layers.44.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.44.self_attn.v_proj.q_scale',\n",
      " 'model.layers.44.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.44.self_attn.v_proj.q_weight',\n",
      " 'model.layers.45.input_layernorm.weight',\n",
      " 'model.layers.45.mlp.down_proj.q_groups',\n",
      " 'model.layers.45.mlp.down_proj.q_invperm',\n",
      " 'model.layers.45.mlp.down_proj.q_scale',\n",
      " 'model.layers.45.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.45.mlp.down_proj.q_weight',\n",
      " 'model.layers.45.mlp.gate_proj.q_groups',\n",
      " 'model.layers.45.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.45.mlp.gate_proj.q_scale',\n",
      " 'model.layers.45.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.45.mlp.gate_proj.q_weight',\n",
      " 'model.layers.45.mlp.up_proj.q_groups',\n",
      " 'model.layers.45.mlp.up_proj.q_invperm',\n",
      " 'model.layers.45.mlp.up_proj.q_scale',\n",
      " 'model.layers.45.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.45.mlp.up_proj.q_weight',\n",
      " 'model.layers.45.post_attention_layernorm.weight',\n",
      " 'model.layers.45.self_attn.k_proj.q_groups',\n",
      " 'model.layers.45.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.45.self_attn.k_proj.q_scale',\n",
      " 'model.layers.45.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.45.self_attn.k_proj.q_weight',\n",
      " 'model.layers.45.self_attn.o_proj.q_groups',\n",
      " 'model.layers.45.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.45.self_attn.o_proj.q_scale',\n",
      " 'model.layers.45.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.45.self_attn.o_proj.q_weight',\n",
      " 'model.layers.45.self_attn.q_proj.q_groups',\n",
      " 'model.layers.45.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.45.self_attn.q_proj.q_scale',\n",
      " 'model.layers.45.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.45.self_attn.q_proj.q_weight',\n",
      " 'model.layers.45.self_attn.v_proj.q_groups',\n",
      " 'model.layers.45.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.45.self_attn.v_proj.q_scale',\n",
      " 'model.layers.45.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.45.self_attn.v_proj.q_weight',\n",
      " 'model.layers.46.input_layernorm.weight',\n",
      " 'model.layers.46.mlp.down_proj.q_groups',\n",
      " 'model.layers.46.mlp.down_proj.q_invperm',\n",
      " 'model.layers.46.mlp.down_proj.q_scale',\n",
      " 'model.layers.46.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.46.mlp.down_proj.q_weight',\n",
      " 'model.layers.46.mlp.gate_proj.q_groups',\n",
      " 'model.layers.46.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.46.mlp.gate_proj.q_scale',\n",
      " 'model.layers.46.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.46.mlp.gate_proj.q_weight',\n",
      " 'model.layers.46.mlp.up_proj.q_groups',\n",
      " 'model.layers.46.mlp.up_proj.q_invperm',\n",
      " 'model.layers.46.mlp.up_proj.q_scale',\n",
      " 'model.layers.46.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.46.mlp.up_proj.q_weight',\n",
      " 'model.layers.46.post_attention_layernorm.weight',\n",
      " 'model.layers.46.self_attn.k_proj.q_groups',\n",
      " 'model.layers.46.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.46.self_attn.k_proj.q_scale',\n",
      " 'model.layers.46.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.46.self_attn.k_proj.q_weight',\n",
      " 'model.layers.46.self_attn.o_proj.q_groups',\n",
      " 'model.layers.46.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.46.self_attn.o_proj.q_scale',\n",
      " 'model.layers.46.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.46.self_attn.o_proj.q_weight',\n",
      " 'model.layers.46.self_attn.q_proj.q_groups',\n",
      " 'model.layers.46.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.46.self_attn.q_proj.q_scale',\n",
      " 'model.layers.46.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.46.self_attn.q_proj.q_weight',\n",
      " 'model.layers.46.self_attn.v_proj.q_groups',\n",
      " 'model.layers.46.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.46.self_attn.v_proj.q_scale',\n",
      " 'model.layers.46.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.46.self_attn.v_proj.q_weight',\n",
      " 'model.layers.47.input_layernorm.weight',\n",
      " 'model.layers.47.mlp.down_proj.q_groups',\n",
      " 'model.layers.47.mlp.down_proj.q_invperm',\n",
      " 'model.layers.47.mlp.down_proj.q_scale',\n",
      " 'model.layers.47.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.47.mlp.down_proj.q_weight',\n",
      " 'model.layers.47.mlp.gate_proj.q_groups',\n",
      " 'model.layers.47.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.47.mlp.gate_proj.q_scale',\n",
      " 'model.layers.47.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.47.mlp.gate_proj.q_weight',\n",
      " 'model.layers.47.mlp.up_proj.q_groups',\n",
      " 'model.layers.47.mlp.up_proj.q_invperm',\n",
      " 'model.layers.47.mlp.up_proj.q_scale',\n",
      " 'model.layers.47.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.47.mlp.up_proj.q_weight',\n",
      " 'model.layers.47.post_attention_layernorm.weight',\n",
      " 'model.layers.47.self_attn.k_proj.q_groups',\n",
      " 'model.layers.47.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.47.self_attn.k_proj.q_scale',\n",
      " 'model.layers.47.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.47.self_attn.k_proj.q_weight',\n",
      " 'model.layers.47.self_attn.o_proj.q_groups',\n",
      " 'model.layers.47.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.47.self_attn.o_proj.q_scale',\n",
      " 'model.layers.47.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.47.self_attn.o_proj.q_weight',\n",
      " 'model.layers.47.self_attn.q_proj.q_groups',\n",
      " 'model.layers.47.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.47.self_attn.q_proj.q_scale',\n",
      " 'model.layers.47.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.47.self_attn.q_proj.q_weight',\n",
      " 'model.layers.47.self_attn.v_proj.q_groups',\n",
      " 'model.layers.47.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.47.self_attn.v_proj.q_scale',\n",
      " 'model.layers.47.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.47.self_attn.v_proj.q_weight',\n",
      " 'model.layers.48.input_layernorm.weight',\n",
      " 'model.layers.48.mlp.down_proj.q_groups',\n",
      " 'model.layers.48.mlp.down_proj.q_invperm',\n",
      " 'model.layers.48.mlp.down_proj.q_scale',\n",
      " 'model.layers.48.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.48.mlp.down_proj.q_weight',\n",
      " 'model.layers.48.mlp.gate_proj.q_groups',\n",
      " 'model.layers.48.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.48.mlp.gate_proj.q_scale',\n",
      " 'model.layers.48.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.48.mlp.gate_proj.q_weight',\n",
      " 'model.layers.48.mlp.up_proj.q_groups',\n",
      " 'model.layers.48.mlp.up_proj.q_invperm',\n",
      " 'model.layers.48.mlp.up_proj.q_scale',\n",
      " 'model.layers.48.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.48.mlp.up_proj.q_weight',\n",
      " 'model.layers.48.post_attention_layernorm.weight',\n",
      " 'model.layers.48.self_attn.k_proj.q_groups',\n",
      " 'model.layers.48.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.48.self_attn.k_proj.q_scale',\n",
      " 'model.layers.48.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.48.self_attn.k_proj.q_weight',\n",
      " 'model.layers.48.self_attn.o_proj.q_groups',\n",
      " 'model.layers.48.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.48.self_attn.o_proj.q_scale',\n",
      " 'model.layers.48.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.48.self_attn.o_proj.q_weight',\n",
      " 'model.layers.48.self_attn.q_proj.q_groups',\n",
      " 'model.layers.48.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.48.self_attn.q_proj.q_scale',\n",
      " 'model.layers.48.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.48.self_attn.q_proj.q_weight',\n",
      " 'model.layers.48.self_attn.v_proj.q_groups',\n",
      " 'model.layers.48.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.48.self_attn.v_proj.q_scale',\n",
      " 'model.layers.48.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.48.self_attn.v_proj.q_weight',\n",
      " 'model.layers.49.input_layernorm.weight',\n",
      " 'model.layers.49.mlp.down_proj.q_groups',\n",
      " 'model.layers.49.mlp.down_proj.q_invperm',\n",
      " 'model.layers.49.mlp.down_proj.q_scale',\n",
      " 'model.layers.49.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.49.mlp.down_proj.q_weight',\n",
      " 'model.layers.49.mlp.gate_proj.q_groups',\n",
      " 'model.layers.49.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.49.mlp.gate_proj.q_scale',\n",
      " 'model.layers.49.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.49.mlp.gate_proj.q_weight',\n",
      " 'model.layers.49.mlp.up_proj.q_groups',\n",
      " 'model.layers.49.mlp.up_proj.q_invperm',\n",
      " 'model.layers.49.mlp.up_proj.q_scale',\n",
      " 'model.layers.49.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.49.mlp.up_proj.q_weight',\n",
      " 'model.layers.49.post_attention_layernorm.weight',\n",
      " 'model.layers.49.self_attn.k_proj.q_groups',\n",
      " 'model.layers.49.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.49.self_attn.k_proj.q_scale',\n",
      " 'model.layers.49.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.49.self_attn.k_proj.q_weight',\n",
      " 'model.layers.49.self_attn.o_proj.q_groups',\n",
      " 'model.layers.49.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.49.self_attn.o_proj.q_scale',\n",
      " 'model.layers.49.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.49.self_attn.o_proj.q_weight',\n",
      " 'model.layers.49.self_attn.q_proj.q_groups',\n",
      " 'model.layers.49.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.49.self_attn.q_proj.q_scale',\n",
      " 'model.layers.49.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.49.self_attn.q_proj.q_weight',\n",
      " 'model.layers.49.self_attn.v_proj.q_groups',\n",
      " 'model.layers.49.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.49.self_attn.v_proj.q_scale',\n",
      " 'model.layers.49.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.49.self_attn.v_proj.q_weight',\n",
      " 'model.layers.50.input_layernorm.weight',\n",
      " 'model.layers.50.mlp.down_proj.q_groups',\n",
      " 'model.layers.50.mlp.down_proj.q_invperm',\n",
      " 'model.layers.50.mlp.down_proj.q_scale',\n",
      " 'model.layers.50.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.50.mlp.down_proj.q_weight',\n",
      " 'model.layers.50.mlp.gate_proj.q_groups',\n",
      " 'model.layers.50.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.50.mlp.gate_proj.q_scale',\n",
      " 'model.layers.50.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.50.mlp.gate_proj.q_weight',\n",
      " 'model.layers.50.mlp.up_proj.q_groups',\n",
      " 'model.layers.50.mlp.up_proj.q_invperm',\n",
      " 'model.layers.50.mlp.up_proj.q_scale',\n",
      " 'model.layers.50.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.50.mlp.up_proj.q_weight',\n",
      " 'model.layers.50.post_attention_layernorm.weight',\n",
      " 'model.layers.50.self_attn.k_proj.q_groups',\n",
      " 'model.layers.50.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.50.self_attn.k_proj.q_scale',\n",
      " 'model.layers.50.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.50.self_attn.k_proj.q_weight',\n",
      " 'model.layers.50.self_attn.o_proj.q_groups',\n",
      " 'model.layers.50.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.50.self_attn.o_proj.q_scale',\n",
      " 'model.layers.50.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.50.self_attn.o_proj.q_weight',\n",
      " 'model.layers.50.self_attn.q_proj.q_groups',\n",
      " 'model.layers.50.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.50.self_attn.q_proj.q_scale',\n",
      " 'model.layers.50.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.50.self_attn.q_proj.q_weight',\n",
      " 'model.layers.50.self_attn.v_proj.q_groups',\n",
      " 'model.layers.50.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.50.self_attn.v_proj.q_scale',\n",
      " 'model.layers.50.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.50.self_attn.v_proj.q_weight',\n",
      " 'model.layers.51.input_layernorm.weight',\n",
      " 'model.layers.51.mlp.down_proj.q_groups',\n",
      " 'model.layers.51.mlp.down_proj.q_invperm',\n",
      " 'model.layers.51.mlp.down_proj.q_scale',\n",
      " 'model.layers.51.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.51.mlp.down_proj.q_weight',\n",
      " 'model.layers.51.mlp.gate_proj.q_groups',\n",
      " 'model.layers.51.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.51.mlp.gate_proj.q_scale',\n",
      " 'model.layers.51.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.51.mlp.gate_proj.q_weight',\n",
      " 'model.layers.51.mlp.up_proj.q_groups',\n",
      " 'model.layers.51.mlp.up_proj.q_invperm',\n",
      " 'model.layers.51.mlp.up_proj.q_scale',\n",
      " 'model.layers.51.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.51.mlp.up_proj.q_weight',\n",
      " 'model.layers.51.post_attention_layernorm.weight',\n",
      " 'model.layers.51.self_attn.k_proj.q_groups',\n",
      " 'model.layers.51.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.51.self_attn.k_proj.q_scale',\n",
      " 'model.layers.51.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.51.self_attn.k_proj.q_weight',\n",
      " 'model.layers.51.self_attn.o_proj.q_groups',\n",
      " 'model.layers.51.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.51.self_attn.o_proj.q_scale',\n",
      " 'model.layers.51.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.51.self_attn.o_proj.q_weight',\n",
      " 'model.layers.51.self_attn.q_proj.q_groups',\n",
      " 'model.layers.51.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.51.self_attn.q_proj.q_scale',\n",
      " 'model.layers.51.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.51.self_attn.q_proj.q_weight',\n",
      " 'model.layers.51.self_attn.v_proj.q_groups',\n",
      " 'model.layers.51.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.51.self_attn.v_proj.q_scale',\n",
      " 'model.layers.51.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.51.self_attn.v_proj.q_weight',\n",
      " 'model.layers.52.input_layernorm.weight',\n",
      " 'model.layers.52.mlp.down_proj.q_groups',\n",
      " 'model.layers.52.mlp.down_proj.q_invperm',\n",
      " 'model.layers.52.mlp.down_proj.q_scale',\n",
      " 'model.layers.52.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.52.mlp.down_proj.q_weight',\n",
      " 'model.layers.52.mlp.gate_proj.q_groups',\n",
      " 'model.layers.52.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.52.mlp.gate_proj.q_scale',\n",
      " 'model.layers.52.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.52.mlp.gate_proj.q_weight',\n",
      " 'model.layers.52.mlp.up_proj.q_groups',\n",
      " 'model.layers.52.mlp.up_proj.q_invperm',\n",
      " 'model.layers.52.mlp.up_proj.q_scale',\n",
      " 'model.layers.52.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.52.mlp.up_proj.q_weight',\n",
      " 'model.layers.52.post_attention_layernorm.weight',\n",
      " 'model.layers.52.self_attn.k_proj.q_groups',\n",
      " 'model.layers.52.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.52.self_attn.k_proj.q_scale',\n",
      " 'model.layers.52.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.52.self_attn.k_proj.q_weight',\n",
      " 'model.layers.52.self_attn.o_proj.q_groups',\n",
      " 'model.layers.52.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.52.self_attn.o_proj.q_scale',\n",
      " 'model.layers.52.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.52.self_attn.o_proj.q_weight',\n",
      " 'model.layers.52.self_attn.q_proj.q_groups',\n",
      " 'model.layers.52.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.52.self_attn.q_proj.q_scale',\n",
      " 'model.layers.52.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.52.self_attn.q_proj.q_weight',\n",
      " 'model.layers.52.self_attn.v_proj.q_groups',\n",
      " 'model.layers.52.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.52.self_attn.v_proj.q_scale',\n",
      " 'model.layers.52.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.52.self_attn.v_proj.q_weight',\n",
      " 'model.layers.53.input_layernorm.weight',\n",
      " 'model.layers.53.mlp.down_proj.q_groups',\n",
      " 'model.layers.53.mlp.down_proj.q_invperm',\n",
      " 'model.layers.53.mlp.down_proj.q_scale',\n",
      " 'model.layers.53.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.53.mlp.down_proj.q_weight',\n",
      " 'model.layers.53.mlp.gate_proj.q_groups',\n",
      " 'model.layers.53.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.53.mlp.gate_proj.q_scale',\n",
      " 'model.layers.53.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.53.mlp.gate_proj.q_weight',\n",
      " 'model.layers.53.mlp.up_proj.q_groups',\n",
      " 'model.layers.53.mlp.up_proj.q_invperm',\n",
      " 'model.layers.53.mlp.up_proj.q_scale',\n",
      " 'model.layers.53.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.53.mlp.up_proj.q_weight',\n",
      " 'model.layers.53.post_attention_layernorm.weight',\n",
      " 'model.layers.53.self_attn.k_proj.q_groups',\n",
      " 'model.layers.53.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.53.self_attn.k_proj.q_scale',\n",
      " 'model.layers.53.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.53.self_attn.k_proj.q_weight',\n",
      " 'model.layers.53.self_attn.o_proj.q_groups',\n",
      " 'model.layers.53.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.53.self_attn.o_proj.q_scale',\n",
      " 'model.layers.53.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.53.self_attn.o_proj.q_weight',\n",
      " 'model.layers.53.self_attn.q_proj.q_groups',\n",
      " 'model.layers.53.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.53.self_attn.q_proj.q_scale',\n",
      " 'model.layers.53.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.53.self_attn.q_proj.q_weight',\n",
      " 'model.layers.53.self_attn.v_proj.q_groups',\n",
      " 'model.layers.53.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.53.self_attn.v_proj.q_scale',\n",
      " 'model.layers.53.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.53.self_attn.v_proj.q_weight',\n",
      " 'model.layers.54.input_layernorm.weight',\n",
      " 'model.layers.54.mlp.down_proj.q_groups',\n",
      " 'model.layers.54.mlp.down_proj.q_invperm',\n",
      " 'model.layers.54.mlp.down_proj.q_scale',\n",
      " 'model.layers.54.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.54.mlp.down_proj.q_weight',\n",
      " 'model.layers.54.mlp.gate_proj.q_groups',\n",
      " 'model.layers.54.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.54.mlp.gate_proj.q_scale',\n",
      " 'model.layers.54.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.54.mlp.gate_proj.q_weight',\n",
      " 'model.layers.54.mlp.up_proj.q_groups',\n",
      " 'model.layers.54.mlp.up_proj.q_invperm',\n",
      " 'model.layers.54.mlp.up_proj.q_scale',\n",
      " 'model.layers.54.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.54.mlp.up_proj.q_weight',\n",
      " 'model.layers.54.post_attention_layernorm.weight',\n",
      " 'model.layers.54.self_attn.k_proj.q_groups',\n",
      " 'model.layers.54.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.54.self_attn.k_proj.q_scale',\n",
      " 'model.layers.54.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.54.self_attn.k_proj.q_weight',\n",
      " 'model.layers.54.self_attn.o_proj.q_groups',\n",
      " 'model.layers.54.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.54.self_attn.o_proj.q_scale',\n",
      " 'model.layers.54.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.54.self_attn.o_proj.q_weight',\n",
      " 'model.layers.54.self_attn.q_proj.q_groups',\n",
      " 'model.layers.54.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.54.self_attn.q_proj.q_scale',\n",
      " 'model.layers.54.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.54.self_attn.q_proj.q_weight',\n",
      " 'model.layers.54.self_attn.v_proj.q_groups',\n",
      " 'model.layers.54.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.54.self_attn.v_proj.q_scale',\n",
      " 'model.layers.54.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.54.self_attn.v_proj.q_weight',\n",
      " 'model.layers.55.input_layernorm.weight',\n",
      " 'model.layers.55.mlp.down_proj.q_groups',\n",
      " 'model.layers.55.mlp.down_proj.q_invperm',\n",
      " 'model.layers.55.mlp.down_proj.q_scale',\n",
      " 'model.layers.55.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.55.mlp.down_proj.q_weight',\n",
      " 'model.layers.55.mlp.gate_proj.q_groups',\n",
      " 'model.layers.55.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.55.mlp.gate_proj.q_scale',\n",
      " 'model.layers.55.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.55.mlp.gate_proj.q_weight',\n",
      " 'model.layers.55.mlp.up_proj.q_groups',\n",
      " 'model.layers.55.mlp.up_proj.q_invperm',\n",
      " 'model.layers.55.mlp.up_proj.q_scale',\n",
      " 'model.layers.55.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.55.mlp.up_proj.q_weight',\n",
      " 'model.layers.55.post_attention_layernorm.weight',\n",
      " 'model.layers.55.self_attn.k_proj.q_groups',\n",
      " 'model.layers.55.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.55.self_attn.k_proj.q_scale',\n",
      " 'model.layers.55.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.55.self_attn.k_proj.q_weight',\n",
      " 'model.layers.55.self_attn.o_proj.q_groups',\n",
      " 'model.layers.55.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.55.self_attn.o_proj.q_scale',\n",
      " 'model.layers.55.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.55.self_attn.o_proj.q_weight',\n",
      " 'model.layers.55.self_attn.q_proj.q_groups',\n",
      " 'model.layers.55.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.55.self_attn.q_proj.q_scale',\n",
      " 'model.layers.55.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.55.self_attn.q_proj.q_weight',\n",
      " 'model.layers.55.self_attn.v_proj.q_groups',\n",
      " 'model.layers.55.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.55.self_attn.v_proj.q_scale',\n",
      " 'model.layers.55.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.55.self_attn.v_proj.q_weight',\n",
      " 'model.layers.56.input_layernorm.weight',\n",
      " 'model.layers.56.mlp.down_proj.q_groups',\n",
      " 'model.layers.56.mlp.down_proj.q_invperm',\n",
      " 'model.layers.56.mlp.down_proj.q_scale',\n",
      " 'model.layers.56.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.56.mlp.down_proj.q_weight',\n",
      " 'model.layers.56.mlp.gate_proj.q_groups',\n",
      " 'model.layers.56.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.56.mlp.gate_proj.q_scale',\n",
      " 'model.layers.56.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.56.mlp.gate_proj.q_weight',\n",
      " 'model.layers.56.mlp.up_proj.q_groups',\n",
      " 'model.layers.56.mlp.up_proj.q_invperm',\n",
      " 'model.layers.56.mlp.up_proj.q_scale',\n",
      " 'model.layers.56.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.56.mlp.up_proj.q_weight',\n",
      " 'model.layers.56.post_attention_layernorm.weight',\n",
      " 'model.layers.56.self_attn.k_proj.q_groups',\n",
      " 'model.layers.56.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.56.self_attn.k_proj.q_scale',\n",
      " 'model.layers.56.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.56.self_attn.k_proj.q_weight',\n",
      " 'model.layers.56.self_attn.o_proj.q_groups',\n",
      " 'model.layers.56.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.56.self_attn.o_proj.q_scale',\n",
      " 'model.layers.56.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.56.self_attn.o_proj.q_weight',\n",
      " 'model.layers.56.self_attn.q_proj.q_groups',\n",
      " 'model.layers.56.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.56.self_attn.q_proj.q_scale',\n",
      " 'model.layers.56.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.56.self_attn.q_proj.q_weight',\n",
      " 'model.layers.56.self_attn.v_proj.q_groups',\n",
      " 'model.layers.56.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.56.self_attn.v_proj.q_scale',\n",
      " 'model.layers.56.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.56.self_attn.v_proj.q_weight',\n",
      " 'model.layers.57.input_layernorm.weight',\n",
      " 'model.layers.57.mlp.down_proj.q_groups',\n",
      " 'model.layers.57.mlp.down_proj.q_invperm',\n",
      " 'model.layers.57.mlp.down_proj.q_scale',\n",
      " 'model.layers.57.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.57.mlp.down_proj.q_weight',\n",
      " 'model.layers.57.mlp.gate_proj.q_groups',\n",
      " 'model.layers.57.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.57.mlp.gate_proj.q_scale',\n",
      " 'model.layers.57.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.57.mlp.gate_proj.q_weight',\n",
      " 'model.layers.57.mlp.up_proj.q_groups',\n",
      " 'model.layers.57.mlp.up_proj.q_invperm',\n",
      " 'model.layers.57.mlp.up_proj.q_scale',\n",
      " 'model.layers.57.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.57.mlp.up_proj.q_weight',\n",
      " 'model.layers.57.post_attention_layernorm.weight',\n",
      " 'model.layers.57.self_attn.k_proj.q_groups',\n",
      " 'model.layers.57.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.57.self_attn.k_proj.q_scale',\n",
      " 'model.layers.57.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.57.self_attn.k_proj.q_weight',\n",
      " 'model.layers.57.self_attn.o_proj.q_groups',\n",
      " 'model.layers.57.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.57.self_attn.o_proj.q_scale',\n",
      " 'model.layers.57.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.57.self_attn.o_proj.q_weight',\n",
      " 'model.layers.57.self_attn.q_proj.q_groups',\n",
      " 'model.layers.57.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.57.self_attn.q_proj.q_scale',\n",
      " 'model.layers.57.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.57.self_attn.q_proj.q_weight',\n",
      " 'model.layers.57.self_attn.v_proj.q_groups',\n",
      " 'model.layers.57.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.57.self_attn.v_proj.q_scale',\n",
      " 'model.layers.57.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.57.self_attn.v_proj.q_weight',\n",
      " 'model.layers.58.input_layernorm.weight',\n",
      " 'model.layers.58.mlp.down_proj.q_groups',\n",
      " 'model.layers.58.mlp.down_proj.q_invperm',\n",
      " 'model.layers.58.mlp.down_proj.q_scale',\n",
      " 'model.layers.58.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.58.mlp.down_proj.q_weight',\n",
      " 'model.layers.58.mlp.gate_proj.q_groups',\n",
      " 'model.layers.58.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.58.mlp.gate_proj.q_scale',\n",
      " 'model.layers.58.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.58.mlp.gate_proj.q_weight',\n",
      " 'model.layers.58.mlp.up_proj.q_groups',\n",
      " 'model.layers.58.mlp.up_proj.q_invperm',\n",
      " 'model.layers.58.mlp.up_proj.q_scale',\n",
      " 'model.layers.58.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.58.mlp.up_proj.q_weight',\n",
      " 'model.layers.58.post_attention_layernorm.weight',\n",
      " 'model.layers.58.self_attn.k_proj.q_groups',\n",
      " 'model.layers.58.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.58.self_attn.k_proj.q_scale',\n",
      " 'model.layers.58.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.58.self_attn.k_proj.q_weight',\n",
      " 'model.layers.58.self_attn.o_proj.q_groups',\n",
      " 'model.layers.58.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.58.self_attn.o_proj.q_scale',\n",
      " 'model.layers.58.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.58.self_attn.o_proj.q_weight',\n",
      " 'model.layers.58.self_attn.q_proj.q_groups',\n",
      " 'model.layers.58.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.58.self_attn.q_proj.q_scale',\n",
      " 'model.layers.58.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.58.self_attn.q_proj.q_weight',\n",
      " 'model.layers.58.self_attn.v_proj.q_groups',\n",
      " 'model.layers.58.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.58.self_attn.v_proj.q_scale',\n",
      " 'model.layers.58.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.58.self_attn.v_proj.q_weight',\n",
      " 'model.layers.59.input_layernorm.weight',\n",
      " 'model.layers.59.mlp.down_proj.q_groups',\n",
      " 'model.layers.59.mlp.down_proj.q_invperm',\n",
      " 'model.layers.59.mlp.down_proj.q_scale',\n",
      " 'model.layers.59.mlp.down_proj.q_scale_max',\n",
      " 'model.layers.59.mlp.down_proj.q_weight',\n",
      " 'model.layers.59.mlp.gate_proj.q_groups',\n",
      " 'model.layers.59.mlp.gate_proj.q_invperm',\n",
      " 'model.layers.59.mlp.gate_proj.q_scale',\n",
      " 'model.layers.59.mlp.gate_proj.q_scale_max',\n",
      " 'model.layers.59.mlp.gate_proj.q_weight',\n",
      " 'model.layers.59.mlp.up_proj.q_groups',\n",
      " 'model.layers.59.mlp.up_proj.q_invperm',\n",
      " 'model.layers.59.mlp.up_proj.q_scale',\n",
      " 'model.layers.59.mlp.up_proj.q_scale_max',\n",
      " 'model.layers.59.mlp.up_proj.q_weight',\n",
      " 'model.layers.59.post_attention_layernorm.weight',\n",
      " 'model.layers.59.self_attn.k_proj.q_groups',\n",
      " 'model.layers.59.self_attn.k_proj.q_invperm',\n",
      " 'model.layers.59.self_attn.k_proj.q_scale',\n",
      " 'model.layers.59.self_attn.k_proj.q_scale_max',\n",
      " 'model.layers.59.self_attn.k_proj.q_weight',\n",
      " 'model.layers.59.self_attn.o_proj.q_groups',\n",
      " 'model.layers.59.self_attn.o_proj.q_invperm',\n",
      " 'model.layers.59.self_attn.o_proj.q_scale',\n",
      " 'model.layers.59.self_attn.o_proj.q_scale_max',\n",
      " 'model.layers.59.self_attn.o_proj.q_weight',\n",
      " 'model.layers.59.self_attn.q_proj.q_groups',\n",
      " 'model.layers.59.self_attn.q_proj.q_invperm',\n",
      " 'model.layers.59.self_attn.q_proj.q_scale',\n",
      " 'model.layers.59.self_attn.q_proj.q_scale_max',\n",
      " 'model.layers.59.self_attn.q_proj.q_weight',\n",
      " 'model.layers.59.self_attn.v_proj.q_groups',\n",
      " 'model.layers.59.self_attn.v_proj.q_invperm',\n",
      " 'model.layers.59.self_attn.v_proj.q_scale',\n",
      " 'model.layers.59.self_attn.v_proj.q_scale_max',\n",
      " 'model.layers.59.self_attn.v_proj.q_weight']\n"
     ]
    }
   ],
   "source": [
    "pprint(list(tensors.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\n            Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: [{'model.layers.40.input_layernorm.weight', 'model.layers.10.input_layernorm.weight'}, {'model.layers.40.mlp.down_proj.q_groups', 'model.layers.10.mlp.down_proj.q_groups'}, {'model.layers.10.mlp.down_proj.q_invperm', 'model.layers.40.mlp.down_proj.q_invperm'}, {'model.layers.10.mlp.down_proj.q_scale', 'model.layers.40.mlp.down_proj.q_scale'}, {'model.layers.10.mlp.down_proj.q_scale_max', 'model.layers.40.mlp.down_proj.q_scale_max'}, {'model.layers.40.mlp.down_proj.q_weight', 'model.layers.10.mlp.down_proj.q_weight'}, {'model.layers.40.mlp.gate_proj.q_groups', 'model.layers.10.mlp.gate_proj.q_groups'}, {'model.layers.10.mlp.gate_proj.q_invperm', 'model.layers.40.mlp.gate_proj.q_invperm'}, {'model.layers.40.mlp.gate_proj.q_scale', 'model.layers.10.mlp.gate_proj.q_scale'}, {'model.layers.10.mlp.gate_proj.q_scale_max', 'model.layers.40.mlp.gate_proj.q_scale_max'}, {'model.layers.40.mlp.gate_proj.q_weight', 'model.layers.10.mlp.gate_proj.q_weight'}, {'model.layers.40.mlp.up_proj.q_groups', 'model.layers.10.mlp.up_proj.q_groups'}, {'model.layers.40.mlp.up_proj.q_invperm', 'model.layers.10.mlp.up_proj.q_invperm'}, {'model.layers.10.mlp.up_proj.q_scale', 'model.layers.40.mlp.up_proj.q_scale'}, {'model.layers.10.mlp.up_proj.q_scale_max', 'model.layers.40.mlp.up_proj.q_scale_max'}, {'model.layers.40.mlp.up_proj.q_weight', 'model.layers.10.mlp.up_proj.q_weight'}, {'model.layers.40.post_attention_layernorm.weight', 'model.layers.10.post_attention_layernorm.weight'}, {'model.layers.40.self_attn.k_proj.q_groups', 'model.layers.10.self_attn.k_proj.q_groups'}, {'model.layers.40.self_attn.k_proj.q_invperm', 'model.layers.10.self_attn.k_proj.q_invperm'}, {'model.layers.40.self_attn.k_proj.q_scale', 'model.layers.10.self_attn.k_proj.q_scale'}, {'model.layers.40.self_attn.k_proj.q_scale_max', 'model.layers.10.self_attn.k_proj.q_scale_max'}, {'model.layers.10.self_attn.k_proj.q_weight', 'model.layers.40.self_attn.k_proj.q_weight'}, {'model.layers.10.self_attn.o_proj.q_groups', 'model.layers.40.self_attn.o_proj.q_groups'}, {'model.layers.40.self_attn.o_proj.q_invperm', 'model.layers.10.self_attn.o_proj.q_invperm'}, {'model.layers.10.self_attn.o_proj.q_scale', 'model.layers.40.self_attn.o_proj.q_scale'}, {'model.layers.40.self_attn.o_proj.q_scale_max', 'model.layers.10.self_attn.o_proj.q_scale_max'}, {'model.layers.40.self_attn.o_proj.q_weight', 'model.layers.10.self_attn.o_proj.q_weight'}, {'model.layers.10.self_attn.q_proj.q_groups', 'model.layers.40.self_attn.q_proj.q_groups'}, {'model.layers.10.self_attn.q_proj.q_invperm', 'model.layers.40.self_attn.q_proj.q_invperm'}, {'model.layers.10.self_attn.q_proj.q_scale', 'model.layers.40.self_attn.q_proj.q_scale'}, {'model.layers.40.self_attn.q_proj.q_scale_max', 'model.layers.10.self_attn.q_proj.q_scale_max'}, {'model.layers.40.self_attn.q_proj.q_weight', 'model.layers.10.self_attn.q_proj.q_weight'}, {'model.layers.10.self_attn.v_proj.q_groups', 'model.layers.40.self_attn.v_proj.q_groups'}, {'model.layers.10.self_attn.v_proj.q_invperm', 'model.layers.40.self_attn.v_proj.q_invperm'}, {'model.layers.10.self_attn.v_proj.q_scale', 'model.layers.40.self_attn.v_proj.q_scale'}, {'model.layers.10.self_attn.v_proj.q_scale_max', 'model.layers.40.self_attn.v_proj.q_scale_max'}, {'model.layers.10.self_attn.v_proj.q_weight', 'model.layers.40.self_attn.v_proj.q_weight'}, {'model.layers.11.input_layernorm.weight', 'model.layers.41.input_layernorm.weight'}, {'model.layers.41.mlp.down_proj.q_groups', 'model.layers.11.mlp.down_proj.q_groups'}, {'model.layers.11.mlp.down_proj.q_invperm', 'model.layers.41.mlp.down_proj.q_invperm'}, {'model.layers.11.mlp.down_proj.q_scale', 'model.layers.41.mlp.down_proj.q_scale'}, {'model.layers.11.mlp.down_proj.q_scale_max', 'model.layers.41.mlp.down_proj.q_scale_max'}, {'model.layers.11.mlp.down_proj.q_weight', 'model.layers.41.mlp.down_proj.q_weight'}, {'model.layers.41.mlp.gate_proj.q_groups', 'model.layers.11.mlp.gate_proj.q_groups'}, {'model.layers.11.mlp.gate_proj.q_invperm', 'model.layers.41.mlp.gate_proj.q_invperm'}, {'model.layers.11.mlp.gate_proj.q_scale', 'model.layers.41.mlp.gate_proj.q_scale'}, {'model.layers.11.mlp.gate_proj.q_scale_max', 'model.layers.41.mlp.gate_proj.q_scale_max'}, {'model.layers.11.mlp.gate_proj.q_weight', 'model.layers.41.mlp.gate_proj.q_weight'}, {'model.layers.11.mlp.up_proj.q_groups', 'model.layers.41.mlp.up_proj.q_groups'}, {'model.layers.11.mlp.up_proj.q_invperm', 'model.layers.41.mlp.up_proj.q_invperm'}, {'model.layers.41.mlp.up_proj.q_scale', 'model.layers.11.mlp.up_proj.q_scale'}, {'model.layers.11.mlp.up_proj.q_scale_max', 'model.layers.41.mlp.up_proj.q_scale_max'}, {'model.layers.41.mlp.up_proj.q_weight', 'model.layers.11.mlp.up_proj.q_weight'}, {'model.layers.11.post_attention_layernorm.weight', 'model.layers.41.post_attention_layernorm.weight'}, {'model.layers.41.self_attn.k_proj.q_groups', 'model.layers.11.self_attn.k_proj.q_groups'}, {'model.layers.11.self_attn.k_proj.q_invperm', 'model.layers.41.self_attn.k_proj.q_invperm'}, {'model.layers.11.self_attn.k_proj.q_scale', 'model.layers.41.self_attn.k_proj.q_scale'}, {'model.layers.11.self_attn.k_proj.q_scale_max', 'model.layers.41.self_attn.k_proj.q_scale_max'}, {'model.layers.11.self_attn.k_proj.q_weight', 'model.layers.41.self_attn.k_proj.q_weight'}, {'model.layers.11.self_attn.o_proj.q_groups', 'model.layers.41.self_attn.o_proj.q_groups'}, {'model.layers.41.self_attn.o_proj.q_invperm', 'model.layers.11.self_attn.o_proj.q_invperm'}, {'model.layers.11.self_attn.o_proj.q_scale', 'model.layers.41.self_attn.o_proj.q_scale'}, {'model.layers.41.self_attn.o_proj.q_scale_max', 'model.layers.11.self_attn.o_proj.q_scale_max'}, {'model.layers.41.self_attn.o_proj.q_weight', 'model.layers.11.self_attn.o_proj.q_weight'}, {'model.layers.41.self_attn.q_proj.q_groups', 'model.layers.11.self_attn.q_proj.q_groups'}, {'model.layers.11.self_attn.q_proj.q_invperm', 'model.layers.41.self_attn.q_proj.q_invperm'}, {'model.layers.11.self_attn.q_proj.q_scale', 'model.layers.41.self_attn.q_proj.q_scale'}, {'model.layers.11.self_attn.q_proj.q_scale_max', 'model.layers.41.self_attn.q_proj.q_scale_max'}, {'model.layers.11.self_attn.q_proj.q_weight', 'model.layers.41.self_attn.q_proj.q_weight'}, {'model.layers.11.self_attn.v_proj.q_groups', 'model.layers.41.self_attn.v_proj.q_groups'}, {'model.layers.11.self_attn.v_proj.q_invperm', 'model.layers.41.self_attn.v_proj.q_invperm'}, {'model.layers.41.self_attn.v_proj.q_scale', 'model.layers.11.self_attn.v_proj.q_scale'}, {'model.layers.41.self_attn.v_proj.q_scale_max', 'model.layers.11.self_attn.v_proj.q_scale_max'}, {'model.layers.11.self_attn.v_proj.q_weight', 'model.layers.41.self_attn.v_proj.q_weight'}, {'model.layers.12.input_layernorm.weight', 'model.layers.42.input_layernorm.weight'}, {'model.layers.42.mlp.down_proj.q_groups', 'model.layers.12.mlp.down_proj.q_groups'}, {'model.layers.42.mlp.down_proj.q_invperm', 'model.layers.12.mlp.down_proj.q_invperm'}, {'model.layers.42.mlp.down_proj.q_scale', 'model.layers.12.mlp.down_proj.q_scale'}, {'model.layers.12.mlp.down_proj.q_scale_max', 'model.layers.42.mlp.down_proj.q_scale_max'}, {'model.layers.42.mlp.down_proj.q_weight', 'model.layers.12.mlp.down_proj.q_weight'}, {'model.layers.12.mlp.gate_proj.q_groups', 'model.layers.42.mlp.gate_proj.q_groups'}, {'model.layers.12.mlp.gate_proj.q_invperm', 'model.layers.42.mlp.gate_proj.q_invperm'}, {'model.layers.12.mlp.gate_proj.q_scale', 'model.layers.42.mlp.gate_proj.q_scale'}, {'model.layers.12.mlp.gate_proj.q_scale_max', 'model.layers.42.mlp.gate_proj.q_scale_max'}, {'model.layers.12.mlp.gate_proj.q_weight', 'model.layers.42.mlp.gate_proj.q_weight'}, {'model.layers.12.mlp.up_proj.q_groups', 'model.layers.42.mlp.up_proj.q_groups'}, {'model.layers.42.mlp.up_proj.q_invperm', 'model.layers.12.mlp.up_proj.q_invperm'}, {'model.layers.12.mlp.up_proj.q_scale', 'model.layers.42.mlp.up_proj.q_scale'}, {'model.layers.42.mlp.up_proj.q_scale_max', 'model.layers.12.mlp.up_proj.q_scale_max'}, {'model.layers.12.mlp.up_proj.q_weight', 'model.layers.42.mlp.up_proj.q_weight'}, {'model.layers.12.post_attention_layernorm.weight', 'model.layers.42.post_attention_layernorm.weight'}, {'model.layers.42.self_attn.k_proj.q_groups', 'model.layers.12.self_attn.k_proj.q_groups'}, {'model.layers.42.self_attn.k_proj.q_invperm', 'model.layers.12.self_attn.k_proj.q_invperm'}, {'model.layers.42.self_attn.k_proj.q_scale', 'model.layers.12.self_attn.k_proj.q_scale'}, {'model.layers.42.self_attn.k_proj.q_scale_max', 'model.layers.12.self_attn.k_proj.q_scale_max'}, {'model.layers.12.self_attn.k_proj.q_weight', 'model.layers.42.self_attn.k_proj.q_weight'}, {'model.layers.42.self_attn.o_proj.q_groups', 'model.layers.12.self_attn.o_proj.q_groups'}, {'model.layers.42.self_attn.o_proj.q_invperm', 'model.layers.12.self_attn.o_proj.q_invperm'}, {'model.layers.42.self_attn.o_proj.q_scale', 'model.layers.12.self_attn.o_proj.q_scale'}, {'model.layers.12.self_attn.o_proj.q_scale_max', 'model.layers.42.self_attn.o_proj.q_scale_max'}, {'model.layers.12.self_attn.o_proj.q_weight', 'model.layers.42.self_attn.o_proj.q_weight'}, {'model.layers.12.self_attn.q_proj.q_groups', 'model.layers.42.self_attn.q_proj.q_groups'}, {'model.layers.42.self_attn.q_proj.q_invperm', 'model.layers.12.self_attn.q_proj.q_invperm'}, {'model.layers.42.self_attn.q_proj.q_scale', 'model.layers.12.self_attn.q_proj.q_scale'}, {'model.layers.12.self_attn.q_proj.q_scale_max', 'model.layers.42.self_attn.q_proj.q_scale_max'}, {'model.layers.12.self_attn.q_proj.q_weight', 'model.layers.42.self_attn.q_proj.q_weight'}, {'model.layers.42.self_attn.v_proj.q_groups', 'model.layers.12.self_attn.v_proj.q_groups'}, {'model.layers.12.self_attn.v_proj.q_invperm', 'model.layers.42.self_attn.v_proj.q_invperm'}, {'model.layers.12.self_attn.v_proj.q_scale', 'model.layers.42.self_attn.v_proj.q_scale'}, {'model.layers.12.self_attn.v_proj.q_scale_max', 'model.layers.42.self_attn.v_proj.q_scale_max'}, {'model.layers.42.self_attn.v_proj.q_weight', 'model.layers.12.self_attn.v_proj.q_weight'}, {'model.layers.43.input_layernorm.weight', 'model.layers.13.input_layernorm.weight'}, {'model.layers.43.mlp.down_proj.q_groups', 'model.layers.13.mlp.down_proj.q_groups'}, {'model.layers.13.mlp.down_proj.q_invperm', 'model.layers.43.mlp.down_proj.q_invperm'}, {'model.layers.43.mlp.down_proj.q_scale', 'model.layers.13.mlp.down_proj.q_scale'}, {'model.layers.43.mlp.down_proj.q_scale_max', 'model.layers.13.mlp.down_proj.q_scale_max'}, {'model.layers.43.mlp.down_proj.q_weight', 'model.layers.13.mlp.down_proj.q_weight'}, {'model.layers.13.mlp.gate_proj.q_groups', 'model.layers.43.mlp.gate_proj.q_groups'}, {'model.layers.13.mlp.gate_proj.q_invperm', 'model.layers.43.mlp.gate_proj.q_invperm'}, {'model.layers.43.mlp.gate_proj.q_scale', 'model.layers.13.mlp.gate_proj.q_scale'}, {'model.layers.43.mlp.gate_proj.q_scale_max', 'model.layers.13.mlp.gate_proj.q_scale_max'}, {'model.layers.13.mlp.gate_proj.q_weight', 'model.layers.43.mlp.gate_proj.q_weight'}, {'model.layers.13.mlp.up_proj.q_groups', 'model.layers.43.mlp.up_proj.q_groups'}, {'model.layers.43.mlp.up_proj.q_invperm', 'model.layers.13.mlp.up_proj.q_invperm'}, {'model.layers.13.mlp.up_proj.q_scale', 'model.layers.43.mlp.up_proj.q_scale'}, {'model.layers.43.mlp.up_proj.q_scale_max', 'model.layers.13.mlp.up_proj.q_scale_max'}, {'model.layers.13.mlp.up_proj.q_weight', 'model.layers.43.mlp.up_proj.q_weight'}, {'model.layers.13.post_attention_layernorm.weight', 'model.layers.43.post_attention_layernorm.weight'}, {'model.layers.43.self_attn.k_proj.q_groups', 'model.layers.13.self_attn.k_proj.q_groups'}, {'model.layers.43.self_attn.k_proj.q_invperm', 'model.layers.13.self_attn.k_proj.q_invperm'}, {'model.layers.13.self_attn.k_proj.q_scale', 'model.layers.43.self_attn.k_proj.q_scale'}, {'model.layers.43.self_attn.k_proj.q_scale_max', 'model.layers.13.self_attn.k_proj.q_scale_max'}, {'model.layers.43.self_attn.k_proj.q_weight', 'model.layers.13.self_attn.k_proj.q_weight'}, {'model.layers.43.self_attn.o_proj.q_groups', 'model.layers.13.self_attn.o_proj.q_groups'}, {'model.layers.43.self_attn.o_proj.q_invperm', 'model.layers.13.self_attn.o_proj.q_invperm'}, {'model.layers.13.self_attn.o_proj.q_scale', 'model.layers.43.self_attn.o_proj.q_scale'}, {'model.layers.43.self_attn.o_proj.q_scale_max', 'model.layers.13.self_attn.o_proj.q_scale_max'}, {'model.layers.43.self_attn.o_proj.q_weight', 'model.layers.13.self_attn.o_proj.q_weight'}, {'model.layers.13.self_attn.q_proj.q_groups', 'model.layers.43.self_attn.q_proj.q_groups'}, {'model.layers.43.self_attn.q_proj.q_invperm', 'model.layers.13.self_attn.q_proj.q_invperm'}, {'model.layers.13.self_attn.q_proj.q_scale', 'model.layers.43.self_attn.q_proj.q_scale'}, {'model.layers.43.self_attn.q_proj.q_scale_max', 'model.layers.13.self_attn.q_proj.q_scale_max'}, {'model.layers.13.self_attn.q_proj.q_weight', 'model.layers.43.self_attn.q_proj.q_weight'}, {'model.layers.43.self_attn.v_proj.q_groups', 'model.layers.13.self_attn.v_proj.q_groups'}, {'model.layers.13.self_attn.v_proj.q_invperm', 'model.layers.43.self_attn.v_proj.q_invperm'}, {'model.layers.13.self_attn.v_proj.q_scale', 'model.layers.43.self_attn.v_proj.q_scale'}, {'model.layers.13.self_attn.v_proj.q_scale_max', 'model.layers.43.self_attn.v_proj.q_scale_max'}, {'model.layers.43.self_attn.v_proj.q_weight', 'model.layers.13.self_attn.v_proj.q_weight'}, {'model.layers.44.input_layernorm.weight', 'model.layers.14.input_layernorm.weight'}, {'model.layers.14.mlp.down_proj.q_groups', 'model.layers.44.mlp.down_proj.q_groups'}, {'model.layers.44.mlp.down_proj.q_invperm', 'model.layers.14.mlp.down_proj.q_invperm'}, {'model.layers.44.mlp.down_proj.q_scale', 'model.layers.14.mlp.down_proj.q_scale'}, {'model.layers.44.mlp.down_proj.q_scale_max', 'model.layers.14.mlp.down_proj.q_scale_max'}, {'model.layers.44.mlp.down_proj.q_weight', 'model.layers.14.mlp.down_proj.q_weight'}, {'model.layers.44.mlp.gate_proj.q_groups', 'model.layers.14.mlp.gate_proj.q_groups'}, {'model.layers.14.mlp.gate_proj.q_invperm', 'model.layers.44.mlp.gate_proj.q_invperm'}, {'model.layers.14.mlp.gate_proj.q_scale', 'model.layers.44.mlp.gate_proj.q_scale'}, {'model.layers.14.mlp.gate_proj.q_scale_max', 'model.layers.44.mlp.gate_proj.q_scale_max'}, {'model.layers.14.mlp.gate_proj.q_weight', 'model.layers.44.mlp.gate_proj.q_weight'}, {'model.layers.44.mlp.up_proj.q_groups', 'model.layers.14.mlp.up_proj.q_groups'}, {'model.layers.14.mlp.up_proj.q_invperm', 'model.layers.44.mlp.up_proj.q_invperm'}, {'model.layers.44.mlp.up_proj.q_scale', 'model.layers.14.mlp.up_proj.q_scale'}, {'model.layers.44.mlp.up_proj.q_scale_max', 'model.layers.14.mlp.up_proj.q_scale_max'}, {'model.layers.14.mlp.up_proj.q_weight', 'model.layers.44.mlp.up_proj.q_weight'}, {'model.layers.44.post_attention_layernorm.weight', 'model.layers.14.post_attention_layernorm.weight'}, {'model.layers.44.self_attn.k_proj.q_groups', 'model.layers.14.self_attn.k_proj.q_groups'}, {'model.layers.44.self_attn.k_proj.q_invperm', 'model.layers.14.self_attn.k_proj.q_invperm'}, {'model.layers.14.self_attn.k_proj.q_scale', 'model.layers.44.self_attn.k_proj.q_scale'}, {'model.layers.14.self_attn.k_proj.q_scale_max', 'model.layers.44.self_attn.k_proj.q_scale_max'}, {'model.layers.44.self_attn.k_proj.q_weight', 'model.layers.14.self_attn.k_proj.q_weight'}, {'model.layers.14.self_attn.o_proj.q_groups', 'model.layers.44.self_attn.o_proj.q_groups'}, {'model.layers.44.self_attn.o_proj.q_invperm', 'model.layers.14.self_attn.o_proj.q_invperm'}, {'model.layers.44.self_attn.o_proj.q_scale', 'model.layers.14.self_attn.o_proj.q_scale'}, {'model.layers.14.self_attn.o_proj.q_scale_max', 'model.layers.44.self_attn.o_proj.q_scale_max'}, {'model.layers.14.self_attn.o_proj.q_weight', 'model.layers.44.self_attn.o_proj.q_weight'}, {'model.layers.44.self_attn.q_proj.q_groups', 'model.layers.14.self_attn.q_proj.q_groups'}, {'model.layers.44.self_attn.q_proj.q_invperm', 'model.layers.14.self_attn.q_proj.q_invperm'}, {'model.layers.44.self_attn.q_proj.q_scale', 'model.layers.14.self_attn.q_proj.q_scale'}, {'model.layers.14.self_attn.q_proj.q_scale_max', 'model.layers.44.self_attn.q_proj.q_scale_max'}, {'model.layers.14.self_attn.q_proj.q_weight', 'model.layers.44.self_attn.q_proj.q_weight'}, {'model.layers.44.self_attn.v_proj.q_groups', 'model.layers.14.self_attn.v_proj.q_groups'}, {'model.layers.44.self_attn.v_proj.q_invperm', 'model.layers.14.self_attn.v_proj.q_invperm'}, {'model.layers.44.self_attn.v_proj.q_scale', 'model.layers.14.self_attn.v_proj.q_scale'}, {'model.layers.44.self_attn.v_proj.q_scale_max', 'model.layers.14.self_attn.v_proj.q_scale_max'}, {'model.layers.44.self_attn.v_proj.q_weight', 'model.layers.14.self_attn.v_proj.q_weight'}, {'model.layers.15.input_layernorm.weight', 'model.layers.45.input_layernorm.weight'}, {'model.layers.15.mlp.down_proj.q_groups', 'model.layers.45.mlp.down_proj.q_groups'}, {'model.layers.45.mlp.down_proj.q_invperm', 'model.layers.15.mlp.down_proj.q_invperm'}, {'model.layers.45.mlp.down_proj.q_scale', 'model.layers.15.mlp.down_proj.q_scale'}, {'model.layers.15.mlp.down_proj.q_scale_max', 'model.layers.45.mlp.down_proj.q_scale_max'}, {'model.layers.15.mlp.down_proj.q_weight', 'model.layers.45.mlp.down_proj.q_weight'}, {'model.layers.45.mlp.gate_proj.q_groups', 'model.layers.15.mlp.gate_proj.q_groups'}, {'model.layers.45.mlp.gate_proj.q_invperm', 'model.layers.15.mlp.gate_proj.q_invperm'}, {'model.layers.15.mlp.gate_proj.q_scale', 'model.layers.45.mlp.gate_proj.q_scale'}, {'model.layers.15.mlp.gate_proj.q_scale_max', 'model.layers.45.mlp.gate_proj.q_scale_max'}, {'model.layers.15.mlp.gate_proj.q_weight', 'model.layers.45.mlp.gate_proj.q_weight'}, {'model.layers.45.mlp.up_proj.q_groups', 'model.layers.15.mlp.up_proj.q_groups'}, {'model.layers.45.mlp.up_proj.q_invperm', 'model.layers.15.mlp.up_proj.q_invperm'}, {'model.layers.45.mlp.up_proj.q_scale', 'model.layers.15.mlp.up_proj.q_scale'}, {'model.layers.45.mlp.up_proj.q_scale_max', 'model.layers.15.mlp.up_proj.q_scale_max'}, {'model.layers.45.mlp.up_proj.q_weight', 'model.layers.15.mlp.up_proj.q_weight'}, {'model.layers.45.post_attention_layernorm.weight', 'model.layers.15.post_attention_layernorm.weight'}, {'model.layers.45.self_attn.k_proj.q_groups', 'model.layers.15.self_attn.k_proj.q_groups'}, {'model.layers.45.self_attn.k_proj.q_invperm', 'model.layers.15.self_attn.k_proj.q_invperm'}, {'model.layers.15.self_attn.k_proj.q_scale', 'model.layers.45.self_attn.k_proj.q_scale'}, {'model.layers.15.self_attn.k_proj.q_scale_max', 'model.layers.45.self_attn.k_proj.q_scale_max'}, {'model.layers.15.self_attn.k_proj.q_weight', 'model.layers.45.self_attn.k_proj.q_weight'}, {'model.layers.15.self_attn.o_proj.q_groups', 'model.layers.45.self_attn.o_proj.q_groups'}, {'model.layers.15.self_attn.o_proj.q_invperm', 'model.layers.45.self_attn.o_proj.q_invperm'}, {'model.layers.15.self_attn.o_proj.q_scale', 'model.layers.45.self_attn.o_proj.q_scale'}, {'model.layers.15.self_attn.o_proj.q_scale_max', 'model.layers.45.self_attn.o_proj.q_scale_max'}, {'model.layers.45.self_attn.o_proj.q_weight', 'model.layers.15.self_attn.o_proj.q_weight'}, {'model.layers.15.self_attn.q_proj.q_groups', 'model.layers.45.self_attn.q_proj.q_groups'}, {'model.layers.45.self_attn.q_proj.q_invperm', 'model.layers.15.self_attn.q_proj.q_invperm'}, {'model.layers.45.self_attn.q_proj.q_scale', 'model.layers.15.self_attn.q_proj.q_scale'}, {'model.layers.45.self_attn.q_proj.q_scale_max', 'model.layers.15.self_attn.q_proj.q_scale_max'}, {'model.layers.45.self_attn.q_proj.q_weight', 'model.layers.15.self_attn.q_proj.q_weight'}, {'model.layers.45.self_attn.v_proj.q_groups', 'model.layers.15.self_attn.v_proj.q_groups'}, {'model.layers.45.self_attn.v_proj.q_invperm', 'model.layers.15.self_attn.v_proj.q_invperm'}, {'model.layers.15.self_attn.v_proj.q_scale', 'model.layers.45.self_attn.v_proj.q_scale'}, {'model.layers.15.self_attn.v_proj.q_scale_max', 'model.layers.45.self_attn.v_proj.q_scale_max'}, {'model.layers.45.self_attn.v_proj.q_weight', 'model.layers.15.self_attn.v_proj.q_weight'}, {'model.layers.16.input_layernorm.weight', 'model.layers.46.input_layernorm.weight'}, {'model.layers.16.mlp.down_proj.q_groups', 'model.layers.46.mlp.down_proj.q_groups'}, {'model.layers.16.mlp.down_proj.q_invperm', 'model.layers.46.mlp.down_proj.q_invperm'}, {'model.layers.16.mlp.down_proj.q_scale', 'model.layers.46.mlp.down_proj.q_scale'}, {'model.layers.46.mlp.down_proj.q_scale_max', 'model.layers.16.mlp.down_proj.q_scale_max'}, {'model.layers.16.mlp.down_proj.q_weight', 'model.layers.46.mlp.down_proj.q_weight'}, {'model.layers.46.mlp.gate_proj.q_groups', 'model.layers.16.mlp.gate_proj.q_groups'}, {'model.layers.46.mlp.gate_proj.q_invperm', 'model.layers.16.mlp.gate_proj.q_invperm'}, {'model.layers.16.mlp.gate_proj.q_scale', 'model.layers.46.mlp.gate_proj.q_scale'}, {'model.layers.46.mlp.gate_proj.q_scale_max', 'model.layers.16.mlp.gate_proj.q_scale_max'}, {'model.layers.46.mlp.gate_proj.q_weight', 'model.layers.16.mlp.gate_proj.q_weight'}, {'model.layers.46.mlp.up_proj.q_groups', 'model.layers.16.mlp.up_proj.q_groups'}, {'model.layers.16.mlp.up_proj.q_invperm', 'model.layers.46.mlp.up_proj.q_invperm'}, {'model.layers.16.mlp.up_proj.q_scale', 'model.layers.46.mlp.up_proj.q_scale'}, {'model.layers.16.mlp.up_proj.q_scale_max', 'model.layers.46.mlp.up_proj.q_scale_max'}, {'model.layers.46.mlp.up_proj.q_weight', 'model.layers.16.mlp.up_proj.q_weight'}, {'model.layers.16.post_attention_layernorm.weight', 'model.layers.46.post_attention_layernorm.weight'}, {'model.layers.46.self_attn.k_proj.q_groups', 'model.layers.16.self_attn.k_proj.q_groups'}, {'model.layers.16.self_attn.k_proj.q_invperm', 'model.layers.46.self_attn.k_proj.q_invperm'}, {'model.layers.16.self_attn.k_proj.q_scale', 'model.layers.46.self_attn.k_proj.q_scale'}, {'model.layers.16.self_attn.k_proj.q_scale_max', 'model.layers.46.self_attn.k_proj.q_scale_max'}, {'model.layers.46.self_attn.k_proj.q_weight', 'model.layers.16.self_attn.k_proj.q_weight'}, {'model.layers.46.self_attn.o_proj.q_groups', 'model.layers.16.self_attn.o_proj.q_groups'}, {'model.layers.46.self_attn.o_proj.q_invperm', 'model.layers.16.self_attn.o_proj.q_invperm'}, {'model.layers.46.self_attn.o_proj.q_scale', 'model.layers.16.self_attn.o_proj.q_scale'}, {'model.layers.46.self_attn.o_proj.q_scale_max', 'model.layers.16.self_attn.o_proj.q_scale_max'}, {'model.layers.16.self_attn.o_proj.q_weight', 'model.layers.46.self_attn.o_proj.q_weight'}, {'model.layers.46.self_attn.q_proj.q_groups', 'model.layers.16.self_attn.q_proj.q_groups'}, {'model.layers.46.self_attn.q_proj.q_invperm', 'model.layers.16.self_attn.q_proj.q_invperm'}, {'model.layers.46.self_attn.q_proj.q_scale', 'model.layers.16.self_attn.q_proj.q_scale'}, {'model.layers.46.self_attn.q_proj.q_scale_max', 'model.layers.16.self_attn.q_proj.q_scale_max'}, {'model.layers.46.self_attn.q_proj.q_weight', 'model.layers.16.self_attn.q_proj.q_weight'}, {'model.layers.46.self_attn.v_proj.q_groups', 'model.layers.16.self_attn.v_proj.q_groups'}, {'model.layers.16.self_attn.v_proj.q_invperm', 'model.layers.46.self_attn.v_proj.q_invperm'}, {'model.layers.16.self_attn.v_proj.q_scale', 'model.layers.46.self_attn.v_proj.q_scale'}, {'model.layers.46.self_attn.v_proj.q_scale_max', 'model.layers.16.self_attn.v_proj.q_scale_max'}, {'model.layers.46.self_attn.v_proj.q_weight', 'model.layers.16.self_attn.v_proj.q_weight'}, {'model.layers.17.input_layernorm.weight', 'model.layers.47.input_layernorm.weight'}, {'model.layers.47.mlp.down_proj.q_groups', 'model.layers.17.mlp.down_proj.q_groups'}, {'model.layers.47.mlp.down_proj.q_invperm', 'model.layers.17.mlp.down_proj.q_invperm'}, {'model.layers.47.mlp.down_proj.q_scale', 'model.layers.17.mlp.down_proj.q_scale'}, {'model.layers.47.mlp.down_proj.q_scale_max', 'model.layers.17.mlp.down_proj.q_scale_max'}, {'model.layers.47.mlp.down_proj.q_weight', 'model.layers.17.mlp.down_proj.q_weight'}, {'model.layers.17.mlp.gate_proj.q_groups', 'model.layers.47.mlp.gate_proj.q_groups'}, {'model.layers.47.mlp.gate_proj.q_invperm', 'model.layers.17.mlp.gate_proj.q_invperm'}, {'model.layers.47.mlp.gate_proj.q_scale', 'model.layers.17.mlp.gate_proj.q_scale'}, {'model.layers.17.mlp.gate_proj.q_scale_max', 'model.layers.47.mlp.gate_proj.q_scale_max'}, {'model.layers.47.mlp.gate_proj.q_weight', 'model.layers.17.mlp.gate_proj.q_weight'}, {'model.layers.47.mlp.up_proj.q_groups', 'model.layers.17.mlp.up_proj.q_groups'}, {'model.layers.17.mlp.up_proj.q_invperm', 'model.layers.47.mlp.up_proj.q_invperm'}, {'model.layers.17.mlp.up_proj.q_scale', 'model.layers.47.mlp.up_proj.q_scale'}, {'model.layers.17.mlp.up_proj.q_scale_max', 'model.layers.47.mlp.up_proj.q_scale_max'}, {'model.layers.47.mlp.up_proj.q_weight', 'model.layers.17.mlp.up_proj.q_weight'}, {'model.layers.17.post_attention_layernorm.weight', 'model.layers.47.post_attention_layernorm.weight'}, {'model.layers.17.self_attn.k_proj.q_groups', 'model.layers.47.self_attn.k_proj.q_groups'}, {'model.layers.17.self_attn.k_proj.q_invperm', 'model.layers.47.self_attn.k_proj.q_invperm'}, {'model.layers.47.self_attn.k_proj.q_scale', 'model.layers.17.self_attn.k_proj.q_scale'}, {'model.layers.47.self_attn.k_proj.q_scale_max', 'model.layers.17.self_attn.k_proj.q_scale_max'}, {'model.layers.47.self_attn.k_proj.q_weight', 'model.layers.17.self_attn.k_proj.q_weight'}, {'model.layers.47.self_attn.o_proj.q_groups', 'model.layers.17.self_attn.o_proj.q_groups'}, {'model.layers.47.self_attn.o_proj.q_invperm', 'model.layers.17.self_attn.o_proj.q_invperm'}, {'model.layers.47.self_attn.o_proj.q_scale', 'model.layers.17.self_attn.o_proj.q_scale'}, {'model.layers.47.self_attn.o_proj.q_scale_max', 'model.layers.17.self_attn.o_proj.q_scale_max'}, {'model.layers.47.self_attn.o_proj.q_weight', 'model.layers.17.self_attn.o_proj.q_weight'}, {'model.layers.47.self_attn.q_proj.q_groups', 'model.layers.17.self_attn.q_proj.q_groups'}, {'model.layers.17.self_attn.q_proj.q_invperm', 'model.layers.47.self_attn.q_proj.q_invperm'}, {'model.layers.17.self_attn.q_proj.q_scale', 'model.layers.47.self_attn.q_proj.q_scale'}, {'model.layers.47.self_attn.q_proj.q_scale_max', 'model.layers.17.self_attn.q_proj.q_scale_max'}, {'model.layers.17.self_attn.q_proj.q_weight', 'model.layers.47.self_attn.q_proj.q_weight'}, {'model.layers.47.self_attn.v_proj.q_groups', 'model.layers.17.self_attn.v_proj.q_groups'}, {'model.layers.17.self_attn.v_proj.q_invperm', 'model.layers.47.self_attn.v_proj.q_invperm'}, {'model.layers.47.self_attn.v_proj.q_scale', 'model.layers.17.self_attn.v_proj.q_scale'}, {'model.layers.17.self_attn.v_proj.q_scale_max', 'model.layers.47.self_attn.v_proj.q_scale_max'}, {'model.layers.47.self_attn.v_proj.q_weight', 'model.layers.17.self_attn.v_proj.q_weight'}, {'model.layers.48.input_layernorm.weight', 'model.layers.18.input_layernorm.weight'}, {'model.layers.48.mlp.down_proj.q_groups', 'model.layers.18.mlp.down_proj.q_groups'}, {'model.layers.48.mlp.down_proj.q_invperm', 'model.layers.18.mlp.down_proj.q_invperm'}, {'model.layers.48.mlp.down_proj.q_scale', 'model.layers.18.mlp.down_proj.q_scale'}, {'model.layers.48.mlp.down_proj.q_scale_max', 'model.layers.18.mlp.down_proj.q_scale_max'}, {'model.layers.18.mlp.down_proj.q_weight', 'model.layers.48.mlp.down_proj.q_weight'}, {'model.layers.18.mlp.gate_proj.q_groups', 'model.layers.48.mlp.gate_proj.q_groups'}, {'model.layers.48.mlp.gate_proj.q_invperm', 'model.layers.18.mlp.gate_proj.q_invperm'}, {'model.layers.48.mlp.gate_proj.q_scale', 'model.layers.18.mlp.gate_proj.q_scale'}, {'model.layers.18.mlp.gate_proj.q_scale_max', 'model.layers.48.mlp.gate_proj.q_scale_max'}, {'model.layers.48.mlp.gate_proj.q_weight', 'model.layers.18.mlp.gate_proj.q_weight'}, {'model.layers.18.mlp.up_proj.q_groups', 'model.layers.48.mlp.up_proj.q_groups'}, {'model.layers.48.mlp.up_proj.q_invperm', 'model.layers.18.mlp.up_proj.q_invperm'}, {'model.layers.18.mlp.up_proj.q_scale', 'model.layers.48.mlp.up_proj.q_scale'}, {'model.layers.48.mlp.up_proj.q_scale_max', 'model.layers.18.mlp.up_proj.q_scale_max'}, {'model.layers.48.mlp.up_proj.q_weight', 'model.layers.18.mlp.up_proj.q_weight'}, {'model.layers.18.post_attention_layernorm.weight', 'model.layers.48.post_attention_layernorm.weight'}, {'model.layers.18.self_attn.k_proj.q_groups', 'model.layers.48.self_attn.k_proj.q_groups'}, {'model.layers.18.self_attn.k_proj.q_invperm', 'model.layers.48.self_attn.k_proj.q_invperm'}, {'model.layers.48.self_attn.k_proj.q_scale', 'model.layers.18.self_attn.k_proj.q_scale'}, {'model.layers.48.self_attn.k_proj.q_scale_max', 'model.layers.18.self_attn.k_proj.q_scale_max'}, {'model.layers.18.self_attn.k_proj.q_weight', 'model.layers.48.self_attn.k_proj.q_weight'}, {'model.layers.18.self_attn.o_proj.q_groups', 'model.layers.48.self_attn.o_proj.q_groups'}, {'model.layers.48.self_attn.o_proj.q_invperm', 'model.layers.18.self_attn.o_proj.q_invperm'}, {'model.layers.48.self_attn.o_proj.q_scale', 'model.layers.18.self_attn.o_proj.q_scale'}, {'model.layers.48.self_attn.o_proj.q_scale_max', 'model.layers.18.self_attn.o_proj.q_scale_max'}, {'model.layers.18.self_attn.o_proj.q_weight', 'model.layers.48.self_attn.o_proj.q_weight'}, {'model.layers.18.self_attn.q_proj.q_groups', 'model.layers.48.self_attn.q_proj.q_groups'}, {'model.layers.18.self_attn.q_proj.q_invperm', 'model.layers.48.self_attn.q_proj.q_invperm'}, {'model.layers.48.self_attn.q_proj.q_scale', 'model.layers.18.self_attn.q_proj.q_scale'}, {'model.layers.18.self_attn.q_proj.q_scale_max', 'model.layers.48.self_attn.q_proj.q_scale_max'}, {'model.layers.48.self_attn.q_proj.q_weight', 'model.layers.18.self_attn.q_proj.q_weight'}, {'model.layers.48.self_attn.v_proj.q_groups', 'model.layers.18.self_attn.v_proj.q_groups'}, {'model.layers.48.self_attn.v_proj.q_invperm', 'model.layers.18.self_attn.v_proj.q_invperm'}, {'model.layers.48.self_attn.v_proj.q_scale', 'model.layers.18.self_attn.v_proj.q_scale'}, {'model.layers.48.self_attn.v_proj.q_scale_max', 'model.layers.18.self_attn.v_proj.q_scale_max'}, {'model.layers.18.self_attn.v_proj.q_weight', 'model.layers.48.self_attn.v_proj.q_weight'}, {'model.layers.49.input_layernorm.weight', 'model.layers.19.input_layernorm.weight'}, {'model.layers.19.mlp.down_proj.q_groups', 'model.layers.49.mlp.down_proj.q_groups'}, {'model.layers.19.mlp.down_proj.q_invperm', 'model.layers.49.mlp.down_proj.q_invperm'}, {'model.layers.49.mlp.down_proj.q_scale', 'model.layers.19.mlp.down_proj.q_scale'}, {'model.layers.49.mlp.down_proj.q_scale_max', 'model.layers.19.mlp.down_proj.q_scale_max'}, {'model.layers.19.mlp.down_proj.q_weight', 'model.layers.49.mlp.down_proj.q_weight'}, {'model.layers.19.mlp.gate_proj.q_groups', 'model.layers.49.mlp.gate_proj.q_groups'}, {'model.layers.19.mlp.gate_proj.q_invperm', 'model.layers.49.mlp.gate_proj.q_invperm'}, {'model.layers.19.mlp.gate_proj.q_scale', 'model.layers.49.mlp.gate_proj.q_scale'}, {'model.layers.49.mlp.gate_proj.q_scale_max', 'model.layers.19.mlp.gate_proj.q_scale_max'}, {'model.layers.49.mlp.gate_proj.q_weight', 'model.layers.19.mlp.gate_proj.q_weight'}, {'model.layers.49.mlp.up_proj.q_groups', 'model.layers.19.mlp.up_proj.q_groups'}, {'model.layers.19.mlp.up_proj.q_invperm', 'model.layers.49.mlp.up_proj.q_invperm'}, {'model.layers.19.mlp.up_proj.q_scale', 'model.layers.49.mlp.up_proj.q_scale'}, {'model.layers.49.mlp.up_proj.q_scale_max', 'model.layers.19.mlp.up_proj.q_scale_max'}, {'model.layers.19.mlp.up_proj.q_weight', 'model.layers.49.mlp.up_proj.q_weight'}, {'model.layers.49.post_attention_layernorm.weight', 'model.layers.19.post_attention_layernorm.weight'}, {'model.layers.19.self_attn.k_proj.q_groups', 'model.layers.49.self_attn.k_proj.q_groups'}, {'model.layers.49.self_attn.k_proj.q_invperm', 'model.layers.19.self_attn.k_proj.q_invperm'}, {'model.layers.49.self_attn.k_proj.q_scale', 'model.layers.19.self_attn.k_proj.q_scale'}, {'model.layers.19.self_attn.k_proj.q_scale_max', 'model.layers.49.self_attn.k_proj.q_scale_max'}, {'model.layers.49.self_attn.k_proj.q_weight', 'model.layers.19.self_attn.k_proj.q_weight'}, {'model.layers.49.self_attn.o_proj.q_groups', 'model.layers.19.self_attn.o_proj.q_groups'}, {'model.layers.49.self_attn.o_proj.q_invperm', 'model.layers.19.self_attn.o_proj.q_invperm'}, {'model.layers.19.self_attn.o_proj.q_scale', 'model.layers.49.self_attn.o_proj.q_scale'}, {'model.layers.19.self_attn.o_proj.q_scale_max', 'model.layers.49.self_attn.o_proj.q_scale_max'}, {'model.layers.19.self_attn.o_proj.q_weight', 'model.layers.49.self_attn.o_proj.q_weight'}, {'model.layers.49.self_attn.q_proj.q_groups', 'model.layers.19.self_attn.q_proj.q_groups'}, {'model.layers.49.self_attn.q_proj.q_invperm', 'model.layers.19.self_attn.q_proj.q_invperm'}, {'model.layers.49.self_attn.q_proj.q_scale', 'model.layers.19.self_attn.q_proj.q_scale'}, {'model.layers.19.self_attn.q_proj.q_scale_max', 'model.layers.49.self_attn.q_proj.q_scale_max'}, {'model.layers.49.self_attn.q_proj.q_weight', 'model.layers.19.self_attn.q_proj.q_weight'}, {'model.layers.49.self_attn.v_proj.q_groups', 'model.layers.19.self_attn.v_proj.q_groups'}, {'model.layers.49.self_attn.v_proj.q_invperm', 'model.layers.19.self_attn.v_proj.q_invperm'}, {'model.layers.49.self_attn.v_proj.q_scale', 'model.layers.19.self_attn.v_proj.q_scale'}, {'model.layers.49.self_attn.v_proj.q_scale_max', 'model.layers.19.self_attn.v_proj.q_scale_max'}, {'model.layers.19.self_attn.v_proj.q_weight', 'model.layers.49.self_attn.v_proj.q_weight'}, {'model.layers.50.input_layernorm.weight', 'model.layers.20.input_layernorm.weight'}, {'model.layers.50.mlp.down_proj.q_groups', 'model.layers.20.mlp.down_proj.q_groups'}, {'model.layers.50.mlp.down_proj.q_invperm', 'model.layers.20.mlp.down_proj.q_invperm'}, {'model.layers.20.mlp.down_proj.q_scale', 'model.layers.50.mlp.down_proj.q_scale'}, {'model.layers.50.mlp.down_proj.q_scale_max', 'model.layers.20.mlp.down_proj.q_scale_max'}, {'model.layers.50.mlp.down_proj.q_weight', 'model.layers.20.mlp.down_proj.q_weight'}, {'model.layers.50.mlp.gate_proj.q_groups', 'model.layers.20.mlp.gate_proj.q_groups'}, {'model.layers.50.mlp.gate_proj.q_invperm', 'model.layers.20.mlp.gate_proj.q_invperm'}, {'model.layers.50.mlp.gate_proj.q_scale', 'model.layers.20.mlp.gate_proj.q_scale'}, {'model.layers.20.mlp.gate_proj.q_scale_max', 'model.layers.50.mlp.gate_proj.q_scale_max'}, {'model.layers.50.mlp.gate_proj.q_weight', 'model.layers.20.mlp.gate_proj.q_weight'}, {'model.layers.50.mlp.up_proj.q_groups', 'model.layers.20.mlp.up_proj.q_groups'}, {'model.layers.20.mlp.up_proj.q_invperm', 'model.layers.50.mlp.up_proj.q_invperm'}, {'model.layers.50.mlp.up_proj.q_scale', 'model.layers.20.mlp.up_proj.q_scale'}, {'model.layers.20.mlp.up_proj.q_scale_max', 'model.layers.50.mlp.up_proj.q_scale_max'}, {'model.layers.20.mlp.up_proj.q_weight', 'model.layers.50.mlp.up_proj.q_weight'}, {'model.layers.20.post_attention_layernorm.weight', 'model.layers.50.post_attention_layernorm.weight'}, {'model.layers.50.self_attn.k_proj.q_groups', 'model.layers.20.self_attn.k_proj.q_groups'}, {'model.layers.50.self_attn.k_proj.q_invperm', 'model.layers.20.self_attn.k_proj.q_invperm'}, {'model.layers.20.self_attn.k_proj.q_scale', 'model.layers.50.self_attn.k_proj.q_scale'}, {'model.layers.50.self_attn.k_proj.q_scale_max', 'model.layers.20.self_attn.k_proj.q_scale_max'}, {'model.layers.20.self_attn.k_proj.q_weight', 'model.layers.50.self_attn.k_proj.q_weight'}, {'model.layers.50.self_attn.o_proj.q_groups', 'model.layers.20.self_attn.o_proj.q_groups'}, {'model.layers.50.self_attn.o_proj.q_invperm', 'model.layers.20.self_attn.o_proj.q_invperm'}, {'model.layers.50.self_attn.o_proj.q_scale', 'model.layers.20.self_attn.o_proj.q_scale'}, {'model.layers.20.self_attn.o_proj.q_scale_max', 'model.layers.50.self_attn.o_proj.q_scale_max'}, {'model.layers.20.self_attn.o_proj.q_weight', 'model.layers.50.self_attn.o_proj.q_weight'}, {'model.layers.50.self_attn.q_proj.q_groups', 'model.layers.20.self_attn.q_proj.q_groups'}, {'model.layers.20.self_attn.q_proj.q_invperm', 'model.layers.50.self_attn.q_proj.q_invperm'}, {'model.layers.20.self_attn.q_proj.q_scale', 'model.layers.50.self_attn.q_proj.q_scale'}, {'model.layers.50.self_attn.q_proj.q_scale_max', 'model.layers.20.self_attn.q_proj.q_scale_max'}, {'model.layers.20.self_attn.q_proj.q_weight', 'model.layers.50.self_attn.q_proj.q_weight'}, {'model.layers.50.self_attn.v_proj.q_groups', 'model.layers.20.self_attn.v_proj.q_groups'}, {'model.layers.20.self_attn.v_proj.q_invperm', 'model.layers.50.self_attn.v_proj.q_invperm'}, {'model.layers.50.self_attn.v_proj.q_scale', 'model.layers.20.self_attn.v_proj.q_scale'}, {'model.layers.50.self_attn.v_proj.q_scale_max', 'model.layers.20.self_attn.v_proj.q_scale_max'}, {'model.layers.50.self_attn.v_proj.q_weight', 'model.layers.20.self_attn.v_proj.q_weight'}, {'model.layers.51.input_layernorm.weight', 'model.layers.21.input_layernorm.weight'}, {'model.layers.51.mlp.down_proj.q_groups', 'model.layers.21.mlp.down_proj.q_groups'}, {'model.layers.21.mlp.down_proj.q_invperm', 'model.layers.51.mlp.down_proj.q_invperm'}, {'model.layers.51.mlp.down_proj.q_scale', 'model.layers.21.mlp.down_proj.q_scale'}, {'model.layers.21.mlp.down_proj.q_scale_max', 'model.layers.51.mlp.down_proj.q_scale_max'}, {'model.layers.51.mlp.down_proj.q_weight', 'model.layers.21.mlp.down_proj.q_weight'}, {'model.layers.51.mlp.gate_proj.q_groups', 'model.layers.21.mlp.gate_proj.q_groups'}, {'model.layers.21.mlp.gate_proj.q_invperm', 'model.layers.51.mlp.gate_proj.q_invperm'}, {'model.layers.21.mlp.gate_proj.q_scale', 'model.layers.51.mlp.gate_proj.q_scale'}, {'model.layers.51.mlp.gate_proj.q_scale_max', 'model.layers.21.mlp.gate_proj.q_scale_max'}, {'model.layers.51.mlp.gate_proj.q_weight', 'model.layers.21.mlp.gate_proj.q_weight'}, {'model.layers.51.mlp.up_proj.q_groups', 'model.layers.21.mlp.up_proj.q_groups'}, {'model.layers.51.mlp.up_proj.q_invperm', 'model.layers.21.mlp.up_proj.q_invperm'}, {'model.layers.51.mlp.up_proj.q_scale', 'model.layers.21.mlp.up_proj.q_scale'}, {'model.layers.51.mlp.up_proj.q_scale_max', 'model.layers.21.mlp.up_proj.q_scale_max'}, {'model.layers.21.mlp.up_proj.q_weight', 'model.layers.51.mlp.up_proj.q_weight'}, {'model.layers.21.post_attention_layernorm.weight', 'model.layers.51.post_attention_layernorm.weight'}, {'model.layers.21.self_attn.k_proj.q_groups', 'model.layers.51.self_attn.k_proj.q_groups'}, {'model.layers.51.self_attn.k_proj.q_invperm', 'model.layers.21.self_attn.k_proj.q_invperm'}, {'model.layers.21.self_attn.k_proj.q_scale', 'model.layers.51.self_attn.k_proj.q_scale'}, {'model.layers.51.self_attn.k_proj.q_scale_max', 'model.layers.21.self_attn.k_proj.q_scale_max'}, {'model.layers.51.self_attn.k_proj.q_weight', 'model.layers.21.self_attn.k_proj.q_weight'}, {'model.layers.51.self_attn.o_proj.q_groups', 'model.layers.21.self_attn.o_proj.q_groups'}, {'model.layers.21.self_attn.o_proj.q_invperm', 'model.layers.51.self_attn.o_proj.q_invperm'}, {'model.layers.21.self_attn.o_proj.q_scale', 'model.layers.51.self_attn.o_proj.q_scale'}, {'model.layers.51.self_attn.o_proj.q_scale_max', 'model.layers.21.self_attn.o_proj.q_scale_max'}, {'model.layers.21.self_attn.o_proj.q_weight', 'model.layers.51.self_attn.o_proj.q_weight'}, {'model.layers.21.self_attn.q_proj.q_groups', 'model.layers.51.self_attn.q_proj.q_groups'}, {'model.layers.21.self_attn.q_proj.q_invperm', 'model.layers.51.self_attn.q_proj.q_invperm'}, {'model.layers.51.self_attn.q_proj.q_scale', 'model.layers.21.self_attn.q_proj.q_scale'}, {'model.layers.21.self_attn.q_proj.q_scale_max', 'model.layers.51.self_attn.q_proj.q_scale_max'}, {'model.layers.21.self_attn.q_proj.q_weight', 'model.layers.51.self_attn.q_proj.q_weight'}, {'model.layers.21.self_attn.v_proj.q_groups', 'model.layers.51.self_attn.v_proj.q_groups'}, {'model.layers.21.self_attn.v_proj.q_invperm', 'model.layers.51.self_attn.v_proj.q_invperm'}, {'model.layers.21.self_attn.v_proj.q_scale', 'model.layers.51.self_attn.v_proj.q_scale'}, {'model.layers.21.self_attn.v_proj.q_scale_max', 'model.layers.51.self_attn.v_proj.q_scale_max'}, {'model.layers.51.self_attn.v_proj.q_weight', 'model.layers.21.self_attn.v_proj.q_weight'}, {'model.layers.22.input_layernorm.weight', 'model.layers.52.input_layernorm.weight'}, {'model.layers.52.mlp.down_proj.q_groups', 'model.layers.22.mlp.down_proj.q_groups'}, {'model.layers.22.mlp.down_proj.q_invperm', 'model.layers.52.mlp.down_proj.q_invperm'}, {'model.layers.22.mlp.down_proj.q_scale', 'model.layers.52.mlp.down_proj.q_scale'}, {'model.layers.52.mlp.down_proj.q_scale_max', 'model.layers.22.mlp.down_proj.q_scale_max'}, {'model.layers.52.mlp.down_proj.q_weight', 'model.layers.22.mlp.down_proj.q_weight'}, {'model.layers.22.mlp.gate_proj.q_groups', 'model.layers.52.mlp.gate_proj.q_groups'}, {'model.layers.52.mlp.gate_proj.q_invperm', 'model.layers.22.mlp.gate_proj.q_invperm'}, {'model.layers.52.mlp.gate_proj.q_scale', 'model.layers.22.mlp.gate_proj.q_scale'}, {'model.layers.22.mlp.gate_proj.q_scale_max', 'model.layers.52.mlp.gate_proj.q_scale_max'}, {'model.layers.52.mlp.gate_proj.q_weight', 'model.layers.22.mlp.gate_proj.q_weight'}, {'model.layers.22.mlp.up_proj.q_groups', 'model.layers.52.mlp.up_proj.q_groups'}, {'model.layers.22.mlp.up_proj.q_invperm', 'model.layers.52.mlp.up_proj.q_invperm'}, {'model.layers.22.mlp.up_proj.q_scale', 'model.layers.52.mlp.up_proj.q_scale'}, {'model.layers.22.mlp.up_proj.q_scale_max', 'model.layers.52.mlp.up_proj.q_scale_max'}, {'model.layers.22.mlp.up_proj.q_weight', 'model.layers.52.mlp.up_proj.q_weight'}, {'model.layers.22.post_attention_layernorm.weight', 'model.layers.52.post_attention_layernorm.weight'}, {'model.layers.52.self_attn.k_proj.q_groups', 'model.layers.22.self_attn.k_proj.q_groups'}, {'model.layers.22.self_attn.k_proj.q_invperm', 'model.layers.52.self_attn.k_proj.q_invperm'}, {'model.layers.52.self_attn.k_proj.q_scale', 'model.layers.22.self_attn.k_proj.q_scale'}, {'model.layers.52.self_attn.k_proj.q_scale_max', 'model.layers.22.self_attn.k_proj.q_scale_max'}, {'model.layers.22.self_attn.k_proj.q_weight', 'model.layers.52.self_attn.k_proj.q_weight'}, {'model.layers.52.self_attn.o_proj.q_groups', 'model.layers.22.self_attn.o_proj.q_groups'}, {'model.layers.52.self_attn.o_proj.q_invperm', 'model.layers.22.self_attn.o_proj.q_invperm'}, {'model.layers.22.self_attn.o_proj.q_scale', 'model.layers.52.self_attn.o_proj.q_scale'}, {'model.layers.52.self_attn.o_proj.q_scale_max', 'model.layers.22.self_attn.o_proj.q_scale_max'}, {'model.layers.22.self_attn.o_proj.q_weight', 'model.layers.52.self_attn.o_proj.q_weight'}, {'model.layers.52.self_attn.q_proj.q_groups', 'model.layers.22.self_attn.q_proj.q_groups'}, {'model.layers.22.self_attn.q_proj.q_invperm', 'model.layers.52.self_attn.q_proj.q_invperm'}, {'model.layers.22.self_attn.q_proj.q_scale', 'model.layers.52.self_attn.q_proj.q_scale'}, {'model.layers.52.self_attn.q_proj.q_scale_max', 'model.layers.22.self_attn.q_proj.q_scale_max'}, {'model.layers.22.self_attn.q_proj.q_weight', 'model.layers.52.self_attn.q_proj.q_weight'}, {'model.layers.52.self_attn.v_proj.q_groups', 'model.layers.22.self_attn.v_proj.q_groups'}, {'model.layers.52.self_attn.v_proj.q_invperm', 'model.layers.22.self_attn.v_proj.q_invperm'}, {'model.layers.22.self_attn.v_proj.q_scale', 'model.layers.52.self_attn.v_proj.q_scale'}, {'model.layers.22.self_attn.v_proj.q_scale_max', 'model.layers.52.self_attn.v_proj.q_scale_max'}, {'model.layers.52.self_attn.v_proj.q_weight', 'model.layers.22.self_attn.v_proj.q_weight'}, {'model.layers.53.input_layernorm.weight', 'model.layers.23.input_layernorm.weight'}, {'model.layers.53.mlp.down_proj.q_groups', 'model.layers.23.mlp.down_proj.q_groups'}, {'model.layers.53.mlp.down_proj.q_invperm', 'model.layers.23.mlp.down_proj.q_invperm'}, {'model.layers.53.mlp.down_proj.q_scale', 'model.layers.23.mlp.down_proj.q_scale'}, {'model.layers.53.mlp.down_proj.q_scale_max', 'model.layers.23.mlp.down_proj.q_scale_max'}, {'model.layers.23.mlp.down_proj.q_weight', 'model.layers.53.mlp.down_proj.q_weight'}, {'model.layers.23.mlp.gate_proj.q_groups', 'model.layers.53.mlp.gate_proj.q_groups'}, {'model.layers.53.mlp.gate_proj.q_invperm', 'model.layers.23.mlp.gate_proj.q_invperm'}, {'model.layers.53.mlp.gate_proj.q_scale', 'model.layers.23.mlp.gate_proj.q_scale'}, {'model.layers.53.mlp.gate_proj.q_scale_max', 'model.layers.23.mlp.gate_proj.q_scale_max'}, {'model.layers.23.mlp.gate_proj.q_weight', 'model.layers.53.mlp.gate_proj.q_weight'}, {'model.layers.53.mlp.up_proj.q_groups', 'model.layers.23.mlp.up_proj.q_groups'}, {'model.layers.53.mlp.up_proj.q_invperm', 'model.layers.23.mlp.up_proj.q_invperm'}, {'model.layers.53.mlp.up_proj.q_scale', 'model.layers.23.mlp.up_proj.q_scale'}, {'model.layers.53.mlp.up_proj.q_scale_max', 'model.layers.23.mlp.up_proj.q_scale_max'}, {'model.layers.23.mlp.up_proj.q_weight', 'model.layers.53.mlp.up_proj.q_weight'}, {'model.layers.53.post_attention_layernorm.weight', 'model.layers.23.post_attention_layernorm.weight'}, {'model.layers.23.self_attn.k_proj.q_groups', 'model.layers.53.self_attn.k_proj.q_groups'}, {'model.layers.53.self_attn.k_proj.q_invperm', 'model.layers.23.self_attn.k_proj.q_invperm'}, {'model.layers.23.self_attn.k_proj.q_scale', 'model.layers.53.self_attn.k_proj.q_scale'}, {'model.layers.23.self_attn.k_proj.q_scale_max', 'model.layers.53.self_attn.k_proj.q_scale_max'}, {'model.layers.53.self_attn.k_proj.q_weight', 'model.layers.23.self_attn.k_proj.q_weight'}, {'model.layers.53.self_attn.o_proj.q_groups', 'model.layers.23.self_attn.o_proj.q_groups'}, {'model.layers.53.self_attn.o_proj.q_invperm', 'model.layers.23.self_attn.o_proj.q_invperm'}, {'model.layers.23.self_attn.o_proj.q_scale', 'model.layers.53.self_attn.o_proj.q_scale'}, {'model.layers.53.self_attn.o_proj.q_scale_max', 'model.layers.23.self_attn.o_proj.q_scale_max'}, {'model.layers.23.self_attn.o_proj.q_weight', 'model.layers.53.self_attn.o_proj.q_weight'}, {'model.layers.23.self_attn.q_proj.q_groups', 'model.layers.53.self_attn.q_proj.q_groups'}, {'model.layers.23.self_attn.q_proj.q_invperm', 'model.layers.53.self_attn.q_proj.q_invperm'}, {'model.layers.53.self_attn.q_proj.q_scale', 'model.layers.23.self_attn.q_proj.q_scale'}, {'model.layers.23.self_attn.q_proj.q_scale_max', 'model.layers.53.self_attn.q_proj.q_scale_max'}, {'model.layers.23.self_attn.q_proj.q_weight', 'model.layers.53.self_attn.q_proj.q_weight'}, {'model.layers.53.self_attn.v_proj.q_groups', 'model.layers.23.self_attn.v_proj.q_groups'}, {'model.layers.53.self_attn.v_proj.q_invperm', 'model.layers.23.self_attn.v_proj.q_invperm'}, {'model.layers.23.self_attn.v_proj.q_scale', 'model.layers.53.self_attn.v_proj.q_scale'}, {'model.layers.23.self_attn.v_proj.q_scale_max', 'model.layers.53.self_attn.v_proj.q_scale_max'}, {'model.layers.23.self_attn.v_proj.q_weight', 'model.layers.53.self_attn.v_proj.q_weight'}, {'model.layers.24.input_layernorm.weight', 'model.layers.54.input_layernorm.weight'}, {'model.layers.24.mlp.down_proj.q_groups', 'model.layers.54.mlp.down_proj.q_groups'}, {'model.layers.24.mlp.down_proj.q_invperm', 'model.layers.54.mlp.down_proj.q_invperm'}, {'model.layers.24.mlp.down_proj.q_scale', 'model.layers.54.mlp.down_proj.q_scale'}, {'model.layers.24.mlp.down_proj.q_scale_max', 'model.layers.54.mlp.down_proj.q_scale_max'}, {'model.layers.54.mlp.down_proj.q_weight', 'model.layers.24.mlp.down_proj.q_weight'}, {'model.layers.54.mlp.gate_proj.q_groups', 'model.layers.24.mlp.gate_proj.q_groups'}, {'model.layers.24.mlp.gate_proj.q_invperm', 'model.layers.54.mlp.gate_proj.q_invperm'}, {'model.layers.24.mlp.gate_proj.q_scale', 'model.layers.54.mlp.gate_proj.q_scale'}, {'model.layers.54.mlp.gate_proj.q_scale_max', 'model.layers.24.mlp.gate_proj.q_scale_max'}, {'model.layers.24.mlp.gate_proj.q_weight', 'model.layers.54.mlp.gate_proj.q_weight'}, {'model.layers.54.mlp.up_proj.q_groups', 'model.layers.24.mlp.up_proj.q_groups'}, {'model.layers.54.mlp.up_proj.q_invperm', 'model.layers.24.mlp.up_proj.q_invperm'}, {'model.layers.24.mlp.up_proj.q_scale', 'model.layers.54.mlp.up_proj.q_scale'}, {'model.layers.54.mlp.up_proj.q_scale_max', 'model.layers.24.mlp.up_proj.q_scale_max'}, {'model.layers.24.mlp.up_proj.q_weight', 'model.layers.54.mlp.up_proj.q_weight'}, {'model.layers.54.post_attention_layernorm.weight', 'model.layers.24.post_attention_layernorm.weight'}, {'model.layers.24.self_attn.k_proj.q_groups', 'model.layers.54.self_attn.k_proj.q_groups'}, {'model.layers.24.self_attn.k_proj.q_invperm', 'model.layers.54.self_attn.k_proj.q_invperm'}, {'model.layers.54.self_attn.k_proj.q_scale', 'model.layers.24.self_attn.k_proj.q_scale'}, {'model.layers.54.self_attn.k_proj.q_scale_max', 'model.layers.24.self_attn.k_proj.q_scale_max'}, {'model.layers.24.self_attn.k_proj.q_weight', 'model.layers.54.self_attn.k_proj.q_weight'}, {'model.layers.24.self_attn.o_proj.q_groups', 'model.layers.54.self_attn.o_proj.q_groups'}, {'model.layers.24.self_attn.o_proj.q_invperm', 'model.layers.54.self_attn.o_proj.q_invperm'}, {'model.layers.54.self_attn.o_proj.q_scale', 'model.layers.24.self_attn.o_proj.q_scale'}, {'model.layers.54.self_attn.o_proj.q_scale_max', 'model.layers.24.self_attn.o_proj.q_scale_max'}, {'model.layers.54.self_attn.o_proj.q_weight', 'model.layers.24.self_attn.o_proj.q_weight'}, {'model.layers.24.self_attn.q_proj.q_groups', 'model.layers.54.self_attn.q_proj.q_groups'}, {'model.layers.24.self_attn.q_proj.q_invperm', 'model.layers.54.self_attn.q_proj.q_invperm'}, {'model.layers.24.self_attn.q_proj.q_scale', 'model.layers.54.self_attn.q_proj.q_scale'}, {'model.layers.54.self_attn.q_proj.q_scale_max', 'model.layers.24.self_attn.q_proj.q_scale_max'}, {'model.layers.54.self_attn.q_proj.q_weight', 'model.layers.24.self_attn.q_proj.q_weight'}, {'model.layers.24.self_attn.v_proj.q_groups', 'model.layers.54.self_attn.v_proj.q_groups'}, {'model.layers.24.self_attn.v_proj.q_invperm', 'model.layers.54.self_attn.v_proj.q_invperm'}, {'model.layers.54.self_attn.v_proj.q_scale', 'model.layers.24.self_attn.v_proj.q_scale'}, {'model.layers.54.self_attn.v_proj.q_scale_max', 'model.layers.24.self_attn.v_proj.q_scale_max'}, {'model.layers.54.self_attn.v_proj.q_weight', 'model.layers.24.self_attn.v_proj.q_weight'}, {'model.layers.55.input_layernorm.weight', 'model.layers.25.input_layernorm.weight'}, {'model.layers.25.mlp.down_proj.q_groups', 'model.layers.55.mlp.down_proj.q_groups'}, {'model.layers.55.mlp.down_proj.q_invperm', 'model.layers.25.mlp.down_proj.q_invperm'}, {'model.layers.55.mlp.down_proj.q_scale', 'model.layers.25.mlp.down_proj.q_scale'}, {'model.layers.25.mlp.down_proj.q_scale_max', 'model.layers.55.mlp.down_proj.q_scale_max'}, {'model.layers.25.mlp.down_proj.q_weight', 'model.layers.55.mlp.down_proj.q_weight'}, {'model.layers.25.mlp.gate_proj.q_groups', 'model.layers.55.mlp.gate_proj.q_groups'}, {'model.layers.55.mlp.gate_proj.q_invperm', 'model.layers.25.mlp.gate_proj.q_invperm'}, {'model.layers.25.mlp.gate_proj.q_scale', 'model.layers.55.mlp.gate_proj.q_scale'}, {'model.layers.25.mlp.gate_proj.q_scale_max', 'model.layers.55.mlp.gate_proj.q_scale_max'}, {'model.layers.25.mlp.gate_proj.q_weight', 'model.layers.55.mlp.gate_proj.q_weight'}, {'model.layers.25.mlp.up_proj.q_groups', 'model.layers.55.mlp.up_proj.q_groups'}, {'model.layers.55.mlp.up_proj.q_invperm', 'model.layers.25.mlp.up_proj.q_invperm'}, {'model.layers.25.mlp.up_proj.q_scale', 'model.layers.55.mlp.up_proj.q_scale'}, {'model.layers.55.mlp.up_proj.q_scale_max', 'model.layers.25.mlp.up_proj.q_scale_max'}, {'model.layers.25.mlp.up_proj.q_weight', 'model.layers.55.mlp.up_proj.q_weight'}, {'model.layers.25.post_attention_layernorm.weight', 'model.layers.55.post_attention_layernorm.weight'}, {'model.layers.55.self_attn.k_proj.q_groups', 'model.layers.25.self_attn.k_proj.q_groups'}, {'model.layers.55.self_attn.k_proj.q_invperm', 'model.layers.25.self_attn.k_proj.q_invperm'}, {'model.layers.55.self_attn.k_proj.q_scale', 'model.layers.25.self_attn.k_proj.q_scale'}, {'model.layers.55.self_attn.k_proj.q_scale_max', 'model.layers.25.self_attn.k_proj.q_scale_max'}, {'model.layers.25.self_attn.k_proj.q_weight', 'model.layers.55.self_attn.k_proj.q_weight'}, {'model.layers.55.self_attn.o_proj.q_groups', 'model.layers.25.self_attn.o_proj.q_groups'}, {'model.layers.55.self_attn.o_proj.q_invperm', 'model.layers.25.self_attn.o_proj.q_invperm'}, {'model.layers.25.self_attn.o_proj.q_scale', 'model.layers.55.self_attn.o_proj.q_scale'}, {'model.layers.55.self_attn.o_proj.q_scale_max', 'model.layers.25.self_attn.o_proj.q_scale_max'}, {'model.layers.55.self_attn.o_proj.q_weight', 'model.layers.25.self_attn.o_proj.q_weight'}, {'model.layers.55.self_attn.q_proj.q_groups', 'model.layers.25.self_attn.q_proj.q_groups'}, {'model.layers.25.self_attn.q_proj.q_invperm', 'model.layers.55.self_attn.q_proj.q_invperm'}, {'model.layers.55.self_attn.q_proj.q_scale', 'model.layers.25.self_attn.q_proj.q_scale'}, {'model.layers.55.self_attn.q_proj.q_scale_max', 'model.layers.25.self_attn.q_proj.q_scale_max'}, {'model.layers.55.self_attn.q_proj.q_weight', 'model.layers.25.self_attn.q_proj.q_weight'}, {'model.layers.55.self_attn.v_proj.q_groups', 'model.layers.25.self_attn.v_proj.q_groups'}, {'model.layers.25.self_attn.v_proj.q_invperm', 'model.layers.55.self_attn.v_proj.q_invperm'}, {'model.layers.25.self_attn.v_proj.q_scale', 'model.layers.55.self_attn.v_proj.q_scale'}, {'model.layers.55.self_attn.v_proj.q_scale_max', 'model.layers.25.self_attn.v_proj.q_scale_max'}, {'model.layers.55.self_attn.v_proj.q_weight', 'model.layers.25.self_attn.v_proj.q_weight'}, {'model.layers.56.input_layernorm.weight', 'model.layers.26.input_layernorm.weight'}, {'model.layers.26.mlp.down_proj.q_groups', 'model.layers.56.mlp.down_proj.q_groups'}, {'model.layers.26.mlp.down_proj.q_invperm', 'model.layers.56.mlp.down_proj.q_invperm'}, {'model.layers.56.mlp.down_proj.q_scale', 'model.layers.26.mlp.down_proj.q_scale'}, {'model.layers.56.mlp.down_proj.q_scale_max', 'model.layers.26.mlp.down_proj.q_scale_max'}, {'model.layers.56.mlp.down_proj.q_weight', 'model.layers.26.mlp.down_proj.q_weight'}, {'model.layers.26.mlp.gate_proj.q_groups', 'model.layers.56.mlp.gate_proj.q_groups'}, {'model.layers.26.mlp.gate_proj.q_invperm', 'model.layers.56.mlp.gate_proj.q_invperm'}, {'model.layers.56.mlp.gate_proj.q_scale', 'model.layers.26.mlp.gate_proj.q_scale'}, {'model.layers.26.mlp.gate_proj.q_scale_max', 'model.layers.56.mlp.gate_proj.q_scale_max'}, {'model.layers.26.mlp.gate_proj.q_weight', 'model.layers.56.mlp.gate_proj.q_weight'}, {'model.layers.56.mlp.up_proj.q_groups', 'model.layers.26.mlp.up_proj.q_groups'}, {'model.layers.56.mlp.up_proj.q_invperm', 'model.layers.26.mlp.up_proj.q_invperm'}, {'model.layers.26.mlp.up_proj.q_scale', 'model.layers.56.mlp.up_proj.q_scale'}, {'model.layers.56.mlp.up_proj.q_scale_max', 'model.layers.26.mlp.up_proj.q_scale_max'}, {'model.layers.26.mlp.up_proj.q_weight', 'model.layers.56.mlp.up_proj.q_weight'}, {'model.layers.26.post_attention_layernorm.weight', 'model.layers.56.post_attention_layernorm.weight'}, {'model.layers.26.self_attn.k_proj.q_groups', 'model.layers.56.self_attn.k_proj.q_groups'}, {'model.layers.26.self_attn.k_proj.q_invperm', 'model.layers.56.self_attn.k_proj.q_invperm'}, {'model.layers.56.self_attn.k_proj.q_scale', 'model.layers.26.self_attn.k_proj.q_scale'}, {'model.layers.26.self_attn.k_proj.q_scale_max', 'model.layers.56.self_attn.k_proj.q_scale_max'}, {'model.layers.56.self_attn.k_proj.q_weight', 'model.layers.26.self_attn.k_proj.q_weight'}, {'model.layers.56.self_attn.o_proj.q_groups', 'model.layers.26.self_attn.o_proj.q_groups'}, {'model.layers.56.self_attn.o_proj.q_invperm', 'model.layers.26.self_attn.o_proj.q_invperm'}, {'model.layers.56.self_attn.o_proj.q_scale', 'model.layers.26.self_attn.o_proj.q_scale'}, {'model.layers.26.self_attn.o_proj.q_scale_max', 'model.layers.56.self_attn.o_proj.q_scale_max'}, {'model.layers.56.self_attn.o_proj.q_weight', 'model.layers.26.self_attn.o_proj.q_weight'}, {'model.layers.56.self_attn.q_proj.q_groups', 'model.layers.26.self_attn.q_proj.q_groups'}, {'model.layers.26.self_attn.q_proj.q_invperm', 'model.layers.56.self_attn.q_proj.q_invperm'}, {'model.layers.26.self_attn.q_proj.q_scale', 'model.layers.56.self_attn.q_proj.q_scale'}, {'model.layers.26.self_attn.q_proj.q_scale_max', 'model.layers.56.self_attn.q_proj.q_scale_max'}, {'model.layers.56.self_attn.q_proj.q_weight', 'model.layers.26.self_attn.q_proj.q_weight'}, {'model.layers.26.self_attn.v_proj.q_groups', 'model.layers.56.self_attn.v_proj.q_groups'}, {'model.layers.56.self_attn.v_proj.q_invperm', 'model.layers.26.self_attn.v_proj.q_invperm'}, {'model.layers.26.self_attn.v_proj.q_scale', 'model.layers.56.self_attn.v_proj.q_scale'}, {'model.layers.56.self_attn.v_proj.q_scale_max', 'model.layers.26.self_attn.v_proj.q_scale_max'}, {'model.layers.56.self_attn.v_proj.q_weight', 'model.layers.26.self_attn.v_proj.q_weight'}, {'model.layers.57.input_layernorm.weight', 'model.layers.27.input_layernorm.weight'}, {'model.layers.27.mlp.down_proj.q_groups', 'model.layers.57.mlp.down_proj.q_groups'}, {'model.layers.57.mlp.down_proj.q_invperm', 'model.layers.27.mlp.down_proj.q_invperm'}, {'model.layers.27.mlp.down_proj.q_scale', 'model.layers.57.mlp.down_proj.q_scale'}, {'model.layers.27.mlp.down_proj.q_scale_max', 'model.layers.57.mlp.down_proj.q_scale_max'}, {'model.layers.57.mlp.down_proj.q_weight', 'model.layers.27.mlp.down_proj.q_weight'}, {'model.layers.27.mlp.gate_proj.q_groups', 'model.layers.57.mlp.gate_proj.q_groups'}, {'model.layers.27.mlp.gate_proj.q_invperm', 'model.layers.57.mlp.gate_proj.q_invperm'}, {'model.layers.27.mlp.gate_proj.q_scale', 'model.layers.57.mlp.gate_proj.q_scale'}, {'model.layers.57.mlp.gate_proj.q_scale_max', 'model.layers.27.mlp.gate_proj.q_scale_max'}, {'model.layers.57.mlp.gate_proj.q_weight', 'model.layers.27.mlp.gate_proj.q_weight'}, {'model.layers.27.mlp.up_proj.q_groups', 'model.layers.57.mlp.up_proj.q_groups'}, {'model.layers.57.mlp.up_proj.q_invperm', 'model.layers.27.mlp.up_proj.q_invperm'}, {'model.layers.57.mlp.up_proj.q_scale', 'model.layers.27.mlp.up_proj.q_scale'}, {'model.layers.27.mlp.up_proj.q_scale_max', 'model.layers.57.mlp.up_proj.q_scale_max'}, {'model.layers.57.mlp.up_proj.q_weight', 'model.layers.27.mlp.up_proj.q_weight'}, {'model.layers.27.post_attention_layernorm.weight', 'model.layers.57.post_attention_layernorm.weight'}, {'model.layers.27.self_attn.k_proj.q_groups', 'model.layers.57.self_attn.k_proj.q_groups'}, {'model.layers.57.self_attn.k_proj.q_invperm', 'model.layers.27.self_attn.k_proj.q_invperm'}, {'model.layers.57.self_attn.k_proj.q_scale', 'model.layers.27.self_attn.k_proj.q_scale'}, {'model.layers.27.self_attn.k_proj.q_scale_max', 'model.layers.57.self_attn.k_proj.q_scale_max'}, {'model.layers.57.self_attn.k_proj.q_weight', 'model.layers.27.self_attn.k_proj.q_weight'}, {'model.layers.27.self_attn.o_proj.q_groups', 'model.layers.57.self_attn.o_proj.q_groups'}, {'model.layers.27.self_attn.o_proj.q_invperm', 'model.layers.57.self_attn.o_proj.q_invperm'}, {'model.layers.57.self_attn.o_proj.q_scale', 'model.layers.27.self_attn.o_proj.q_scale'}, {'model.layers.27.self_attn.o_proj.q_scale_max', 'model.layers.57.self_attn.o_proj.q_scale_max'}, {'model.layers.57.self_attn.o_proj.q_weight', 'model.layers.27.self_attn.o_proj.q_weight'}, {'model.layers.27.self_attn.q_proj.q_groups', 'model.layers.57.self_attn.q_proj.q_groups'}, {'model.layers.27.self_attn.q_proj.q_invperm', 'model.layers.57.self_attn.q_proj.q_invperm'}, {'model.layers.57.self_attn.q_proj.q_scale', 'model.layers.27.self_attn.q_proj.q_scale'}, {'model.layers.27.self_attn.q_proj.q_scale_max', 'model.layers.57.self_attn.q_proj.q_scale_max'}, {'model.layers.27.self_attn.q_proj.q_weight', 'model.layers.57.self_attn.q_proj.q_weight'}, {'model.layers.27.self_attn.v_proj.q_groups', 'model.layers.57.self_attn.v_proj.q_groups'}, {'model.layers.27.self_attn.v_proj.q_invperm', 'model.layers.57.self_attn.v_proj.q_invperm'}, {'model.layers.57.self_attn.v_proj.q_scale', 'model.layers.27.self_attn.v_proj.q_scale'}, {'model.layers.27.self_attn.v_proj.q_scale_max', 'model.layers.57.self_attn.v_proj.q_scale_max'}, {'model.layers.57.self_attn.v_proj.q_weight', 'model.layers.27.self_attn.v_proj.q_weight'}, {'model.layers.28.input_layernorm.weight', 'model.layers.58.input_layernorm.weight'}, {'model.layers.58.mlp.down_proj.q_groups', 'model.layers.28.mlp.down_proj.q_groups'}, {'model.layers.58.mlp.down_proj.q_invperm', 'model.layers.28.mlp.down_proj.q_invperm'}, {'model.layers.58.mlp.down_proj.q_scale', 'model.layers.28.mlp.down_proj.q_scale'}, {'model.layers.28.mlp.down_proj.q_scale_max', 'model.layers.58.mlp.down_proj.q_scale_max'}, {'model.layers.58.mlp.down_proj.q_weight', 'model.layers.28.mlp.down_proj.q_weight'}, {'model.layers.58.mlp.gate_proj.q_groups', 'model.layers.28.mlp.gate_proj.q_groups'}, {'model.layers.58.mlp.gate_proj.q_invperm', 'model.layers.28.mlp.gate_proj.q_invperm'}, {'model.layers.58.mlp.gate_proj.q_scale', 'model.layers.28.mlp.gate_proj.q_scale'}, {'model.layers.58.mlp.gate_proj.q_scale_max', 'model.layers.28.mlp.gate_proj.q_scale_max'}, {'model.layers.28.mlp.gate_proj.q_weight', 'model.layers.58.mlp.gate_proj.q_weight'}, {'model.layers.28.mlp.up_proj.q_groups', 'model.layers.58.mlp.up_proj.q_groups'}, {'model.layers.28.mlp.up_proj.q_invperm', 'model.layers.58.mlp.up_proj.q_invperm'}, {'model.layers.28.mlp.up_proj.q_scale', 'model.layers.58.mlp.up_proj.q_scale'}, {'model.layers.28.mlp.up_proj.q_scale_max', 'model.layers.58.mlp.up_proj.q_scale_max'}, {'model.layers.28.mlp.up_proj.q_weight', 'model.layers.58.mlp.up_proj.q_weight'}, {'model.layers.58.post_attention_layernorm.weight', 'model.layers.28.post_attention_layernorm.weight'}, {'model.layers.28.self_attn.k_proj.q_groups', 'model.layers.58.self_attn.k_proj.q_groups'}, {'model.layers.58.self_attn.k_proj.q_invperm', 'model.layers.28.self_attn.k_proj.q_invperm'}, {'model.layers.28.self_attn.k_proj.q_scale', 'model.layers.58.self_attn.k_proj.q_scale'}, {'model.layers.28.self_attn.k_proj.q_scale_max', 'model.layers.58.self_attn.k_proj.q_scale_max'}, {'model.layers.28.self_attn.k_proj.q_weight', 'model.layers.58.self_attn.k_proj.q_weight'}, {'model.layers.58.self_attn.o_proj.q_groups', 'model.layers.28.self_attn.o_proj.q_groups'}, {'model.layers.28.self_attn.o_proj.q_invperm', 'model.layers.58.self_attn.o_proj.q_invperm'}, {'model.layers.58.self_attn.o_proj.q_scale', 'model.layers.28.self_attn.o_proj.q_scale'}, {'model.layers.28.self_attn.o_proj.q_scale_max', 'model.layers.58.self_attn.o_proj.q_scale_max'}, {'model.layers.58.self_attn.o_proj.q_weight', 'model.layers.28.self_attn.o_proj.q_weight'}, {'model.layers.28.self_attn.q_proj.q_groups', 'model.layers.58.self_attn.q_proj.q_groups'}, {'model.layers.28.self_attn.q_proj.q_invperm', 'model.layers.58.self_attn.q_proj.q_invperm'}, {'model.layers.28.self_attn.q_proj.q_scale', 'model.layers.58.self_attn.q_proj.q_scale'}, {'model.layers.58.self_attn.q_proj.q_scale_max', 'model.layers.28.self_attn.q_proj.q_scale_max'}, {'model.layers.58.self_attn.q_proj.q_weight', 'model.layers.28.self_attn.q_proj.q_weight'}, {'model.layers.28.self_attn.v_proj.q_groups', 'model.layers.58.self_attn.v_proj.q_groups'}, {'model.layers.28.self_attn.v_proj.q_invperm', 'model.layers.58.self_attn.v_proj.q_invperm'}, {'model.layers.28.self_attn.v_proj.q_scale', 'model.layers.58.self_attn.v_proj.q_scale'}, {'model.layers.28.self_attn.v_proj.q_scale_max', 'model.layers.58.self_attn.v_proj.q_scale_max'}, {'model.layers.58.self_attn.v_proj.q_weight', 'model.layers.28.self_attn.v_proj.q_weight'}, {'model.layers.59.input_layernorm.weight', 'model.layers.29.input_layernorm.weight'}, {'model.layers.29.mlp.down_proj.q_groups', 'model.layers.59.mlp.down_proj.q_groups'}, {'model.layers.59.mlp.down_proj.q_invperm', 'model.layers.29.mlp.down_proj.q_invperm'}, {'model.layers.29.mlp.down_proj.q_scale', 'model.layers.59.mlp.down_proj.q_scale'}, {'model.layers.59.mlp.down_proj.q_scale_max', 'model.layers.29.mlp.down_proj.q_scale_max'}, {'model.layers.29.mlp.down_proj.q_weight', 'model.layers.59.mlp.down_proj.q_weight'}, {'model.layers.29.mlp.gate_proj.q_groups', 'model.layers.59.mlp.gate_proj.q_groups'}, {'model.layers.59.mlp.gate_proj.q_invperm', 'model.layers.29.mlp.gate_proj.q_invperm'}, {'model.layers.59.mlp.gate_proj.q_scale', 'model.layers.29.mlp.gate_proj.q_scale'}, {'model.layers.59.mlp.gate_proj.q_scale_max', 'model.layers.29.mlp.gate_proj.q_scale_max'}, {'model.layers.59.mlp.gate_proj.q_weight', 'model.layers.29.mlp.gate_proj.q_weight'}, {'model.layers.59.mlp.up_proj.q_groups', 'model.layers.29.mlp.up_proj.q_groups'}, {'model.layers.59.mlp.up_proj.q_invperm', 'model.layers.29.mlp.up_proj.q_invperm'}, {'model.layers.29.mlp.up_proj.q_scale', 'model.layers.59.mlp.up_proj.q_scale'}, {'model.layers.59.mlp.up_proj.q_scale_max', 'model.layers.29.mlp.up_proj.q_scale_max'}, {'model.layers.29.mlp.up_proj.q_weight', 'model.layers.59.mlp.up_proj.q_weight'}, {'model.layers.59.post_attention_layernorm.weight', 'model.layers.29.post_attention_layernorm.weight'}, {'model.layers.29.self_attn.k_proj.q_groups', 'model.layers.59.self_attn.k_proj.q_groups'}, {'model.layers.29.self_attn.k_proj.q_invperm', 'model.layers.59.self_attn.k_proj.q_invperm'}, {'model.layers.29.self_attn.k_proj.q_scale', 'model.layers.59.self_attn.k_proj.q_scale'}, {'model.layers.29.self_attn.k_proj.q_scale_max', 'model.layers.59.self_attn.k_proj.q_scale_max'}, {'model.layers.29.self_attn.k_proj.q_weight', 'model.layers.59.self_attn.k_proj.q_weight'}, {'model.layers.59.self_attn.o_proj.q_groups', 'model.layers.29.self_attn.o_proj.q_groups'}, {'model.layers.29.self_attn.o_proj.q_invperm', 'model.layers.59.self_attn.o_proj.q_invperm'}, {'model.layers.59.self_attn.o_proj.q_scale', 'model.layers.29.self_attn.o_proj.q_scale'}, {'model.layers.59.self_attn.o_proj.q_scale_max', 'model.layers.29.self_attn.o_proj.q_scale_max'}, {'model.layers.59.self_attn.o_proj.q_weight', 'model.layers.29.self_attn.o_proj.q_weight'}, {'model.layers.29.self_attn.q_proj.q_groups', 'model.layers.59.self_attn.q_proj.q_groups'}, {'model.layers.29.self_attn.q_proj.q_invperm', 'model.layers.59.self_attn.q_proj.q_invperm'}, {'model.layers.29.self_attn.q_proj.q_scale', 'model.layers.59.self_attn.q_proj.q_scale'}, {'model.layers.29.self_attn.q_proj.q_scale_max', 'model.layers.59.self_attn.q_proj.q_scale_max'}, {'model.layers.59.self_attn.q_proj.q_weight', 'model.layers.29.self_attn.q_proj.q_weight'}, {'model.layers.29.self_attn.v_proj.q_groups', 'model.layers.59.self_attn.v_proj.q_groups'}, {'model.layers.59.self_attn.v_proj.q_invperm', 'model.layers.29.self_attn.v_proj.q_invperm'}, {'model.layers.29.self_attn.v_proj.q_scale', 'model.layers.59.self_attn.v_proj.q_scale'}, {'model.layers.29.self_attn.v_proj.q_scale_max', 'model.layers.59.self_attn.v_proj.q_scale_max'}, {'model.layers.59.self_attn.v_proj.q_weight', 'model.layers.29.self_attn.v_proj.q_weight'}].\n            A potential way to correctly save your model is to use `save_model`.\n            More information at https://huggingface.co/docs/safetensors/torch_shared_tensors\n            ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msave_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput.safetensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/exllama/lib/python3.10/site-packages/safetensors/torch.py:281\u001b[0m, in \u001b[0;36msave_file\u001b[0;34m(tensors, filename, metadata)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_file\u001b[39m(\n\u001b[1;32m    251\u001b[0m     tensors: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[1;32m    252\u001b[0m     filename: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    253\u001b[0m     metadata: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    254\u001b[0m ):\n\u001b[1;32m    255\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m    Saves a dictionary of tensors into raw bytes in safetensors format.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m     serialize_file(\u001b[43m_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m, filename, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n",
      "File \u001b[0;32m~/miniforge3/envs/exllama/lib/python3.10/site-packages/safetensors/torch.py:477\u001b[0m, in \u001b[0;36m_flatten\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    474\u001b[0m         failing\u001b[38;5;241m.\u001b[39mappend(names)\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failing:\n\u001b[0;32m--> 477\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;124m        Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfailing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;124m        A potential way to correctly save your model is to use `save_model`.\u001b[39m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;124m        More information at https://huggingface.co/docs/safetensors/torch_shared_tensors\u001b[39m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    483\u001b[0m     )\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    486\u001b[0m     k: {\n\u001b[1;32m    487\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(v\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    492\u001b[0m }\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \n            Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: [{'model.layers.40.input_layernorm.weight', 'model.layers.10.input_layernorm.weight'}, {'model.layers.40.mlp.down_proj.q_groups', 'model.layers.10.mlp.down_proj.q_groups'}, {'model.layers.10.mlp.down_proj.q_invperm', 'model.layers.40.mlp.down_proj.q_invperm'}, {'model.layers.10.mlp.down_proj.q_scale', 'model.layers.40.mlp.down_proj.q_scale'}, {'model.layers.10.mlp.down_proj.q_scale_max', 'model.layers.40.mlp.down_proj.q_scale_max'}, {'model.layers.40.mlp.down_proj.q_weight', 'model.layers.10.mlp.down_proj.q_weight'}, {'model.layers.40.mlp.gate_proj.q_groups', 'model.layers.10.mlp.gate_proj.q_groups'}, {'model.layers.10.mlp.gate_proj.q_invperm', 'model.layers.40.mlp.gate_proj.q_invperm'}, {'model.layers.40.mlp.gate_proj.q_scale', 'model.layers.10.mlp.gate_proj.q_scale'}, {'model.layers.10.mlp.gate_proj.q_scale_max', 'model.layers.40.mlp.gate_proj.q_scale_max'}, {'model.layers.40.mlp.gate_proj.q_weight', 'model.layers.10.mlp.gate_proj.q_weight'}, {'model.layers.40.mlp.up_proj.q_groups', 'model.layers.10.mlp.up_proj.q_groups'}, {'model.layers.40.mlp.up_proj.q_invperm', 'model.layers.10.mlp.up_proj.q_invperm'}, {'model.layers.10.mlp.up_proj.q_scale', 'model.layers.40.mlp.up_proj.q_scale'}, {'model.layers.10.mlp.up_proj.q_scale_max', 'model.layers.40.mlp.up_proj.q_scale_max'}, {'model.layers.40.mlp.up_proj.q_weight', 'model.layers.10.mlp.up_proj.q_weight'}, {'model.layers.40.post_attention_layernorm.weight', 'model.layers.10.post_attention_layernorm.weight'}, {'model.layers.40.self_attn.k_proj.q_groups', 'model.layers.10.self_attn.k_proj.q_groups'}, {'model.layers.40.self_attn.k_proj.q_invperm', 'model.layers.10.self_attn.k_proj.q_invperm'}, {'model.layers.40.self_attn.k_proj.q_scale', 'model.layers.10.self_attn.k_proj.q_scale'}, {'model.layers.40.self_attn.k_proj.q_scale_max', 'model.layers.10.self_attn.k_proj.q_scale_max'}, {'model.layers.10.self_attn.k_proj.q_weight', 'model.layers.40.self_attn.k_proj.q_weight'}, {'model.layers.10.self_attn.o_proj.q_groups', 'model.layers.40.self_attn.o_proj.q_groups'}, {'model.layers.40.self_attn.o_proj.q_invperm', 'model.layers.10.self_attn.o_proj.q_invperm'}, {'model.layers.10.self_attn.o_proj.q_scale', 'model.layers.40.self_attn.o_proj.q_scale'}, {'model.layers.40.self_attn.o_proj.q_scale_max', 'model.layers.10.self_attn.o_proj.q_scale_max'}, {'model.layers.40.self_attn.o_proj.q_weight', 'model.layers.10.self_attn.o_proj.q_weight'}, {'model.layers.10.self_attn.q_proj.q_groups', 'model.layers.40.self_attn.q_proj.q_groups'}, {'model.layers.10.self_attn.q_proj.q_invperm', 'model.layers.40.self_attn.q_proj.q_invperm'}, {'model.layers.10.self_attn.q_proj.q_scale', 'model.layers.40.self_attn.q_proj.q_scale'}, {'model.layers.40.self_attn.q_proj.q_scale_max', 'model.layers.10.self_attn.q_proj.q_scale_max'}, {'model.layers.40.self_attn.q_proj.q_weight', 'model.layers.10.self_attn.q_proj.q_weight'}, {'model.layers.10.self_attn.v_proj.q_groups', 'model.layers.40.self_attn.v_proj.q_groups'}, {'model.layers.10.self_attn.v_proj.q_invperm', 'model.layers.40.self_attn.v_proj.q_invperm'}, {'model.layers.10.self_attn.v_proj.q_scale', 'model.layers.40.self_attn.v_proj.q_scale'}, {'model.layers.10.self_attn.v_proj.q_scale_max', 'model.layers.40.self_attn.v_proj.q_scale_max'}, {'model.layers.10.self_attn.v_proj.q_weight', 'model.layers.40.self_attn.v_proj.q_weight'}, {'model.layers.11.input_layernorm.weight', 'model.layers.41.input_layernorm.weight'}, {'model.layers.41.mlp.down_proj.q_groups', 'model.layers.11.mlp.down_proj.q_groups'}, {'model.layers.11.mlp.down_proj.q_invperm', 'model.layers.41.mlp.down_proj.q_invperm'}, {'model.layers.11.mlp.down_proj.q_scale', 'model.layers.41.mlp.down_proj.q_scale'}, {'model.layers.11.mlp.down_proj.q_scale_max', 'model.layers.41.mlp.down_proj.q_scale_max'}, {'model.layers.11.mlp.down_proj.q_weight', 'model.layers.41.mlp.down_proj.q_weight'}, {'model.layers.41.mlp.gate_proj.q_groups', 'model.layers.11.mlp.gate_proj.q_groups'}, {'model.layers.11.mlp.gate_proj.q_invperm', 'model.layers.41.mlp.gate_proj.q_invperm'}, {'model.layers.11.mlp.gate_proj.q_scale', 'model.layers.41.mlp.gate_proj.q_scale'}, {'model.layers.11.mlp.gate_proj.q_scale_max', 'model.layers.41.mlp.gate_proj.q_scale_max'}, {'model.layers.11.mlp.gate_proj.q_weight', 'model.layers.41.mlp.gate_proj.q_weight'}, {'model.layers.11.mlp.up_proj.q_groups', 'model.layers.41.mlp.up_proj.q_groups'}, {'model.layers.11.mlp.up_proj.q_invperm', 'model.layers.41.mlp.up_proj.q_invperm'}, {'model.layers.41.mlp.up_proj.q_scale', 'model.layers.11.mlp.up_proj.q_scale'}, {'model.layers.11.mlp.up_proj.q_scale_max', 'model.layers.41.mlp.up_proj.q_scale_max'}, {'model.layers.41.mlp.up_proj.q_weight', 'model.layers.11.mlp.up_proj.q_weight'}, {'model.layers.11.post_attention_layernorm.weight', 'model.layers.41.post_attention_layernorm.weight'}, {'model.layers.41.self_attn.k_proj.q_groups', 'model.layers.11.self_attn.k_proj.q_groups'}, {'model.layers.11.self_attn.k_proj.q_invperm', 'model.layers.41.self_attn.k_proj.q_invperm'}, {'model.layers.11.self_attn.k_proj.q_scale', 'model.layers.41.self_attn.k_proj.q_scale'}, {'model.layers.11.self_attn.k_proj.q_scale_max', 'model.layers.41.self_attn.k_proj.q_scale_max'}, {'model.layers.11.self_attn.k_proj.q_weight', 'model.layers.41.self_attn.k_proj.q_weight'}, {'model.layers.11.self_attn.o_proj.q_groups', 'model.layers.41.self_attn.o_proj.q_groups'}, {'model.layers.41.self_attn.o_proj.q_invperm', 'model.layers.11.self_attn.o_proj.q_invperm'}, {'model.layers.11.self_attn.o_proj.q_scale', 'model.layers.41.self_attn.o_proj.q_scale'}, {'model.layers.41.self_attn.o_proj.q_scale_max', 'model.layers.11.self_attn.o_proj.q_scale_max'}, {'model.layers.41.self_attn.o_proj.q_weight', 'model.layers.11.self_attn.o_proj.q_weight'}, {'model.layers.41.self_attn.q_proj.q_groups', 'model.layers.11.self_attn.q_proj.q_groups'}, {'model.layers.11.self_attn.q_proj.q_invperm', 'model.layers.41.self_attn.q_proj.q_invperm'}, {'model.layers.11.self_attn.q_proj.q_scale', 'model.layers.41.self_attn.q_proj.q_scale'}, {'model.layers.11.self_attn.q_proj.q_scale_max', 'model.layers.41.self_attn.q_proj.q_scale_max'}, {'model.layers.11.self_attn.q_proj.q_weight', 'model.layers.41.self_attn.q_proj.q_weight'}, {'model.layers.11.self_attn.v_proj.q_groups', 'model.layers.41.self_attn.v_proj.q_groups'}, {'model.layers.11.self_attn.v_proj.q_invperm', 'model.layers.41.self_attn.v_proj.q_invperm'}, {'model.layers.41.self_attn.v_proj.q_scale', 'model.layers.11.self_attn.v_proj.q_scale'}, {'model.layers.41.self_attn.v_proj.q_scale_max', 'model.layers.11.self_attn.v_proj.q_scale_max'}, {'model.layers.11.self_attn.v_proj.q_weight', 'model.layers.41.self_attn.v_proj.q_weight'}, {'model.layers.12.input_layernorm.weight', 'model.layers.42.input_layernorm.weight'}, {'model.layers.42.mlp.down_proj.q_groups', 'model.layers.12.mlp.down_proj.q_groups'}, {'model.layers.42.mlp.down_proj.q_invperm', 'model.layers.12.mlp.down_proj.q_invperm'}, {'model.layers.42.mlp.down_proj.q_scale', 'model.layers.12.mlp.down_proj.q_scale'}, {'model.layers.12.mlp.down_proj.q_scale_max', 'model.layers.42.mlp.down_proj.q_scale_max'}, {'model.layers.42.mlp.down_proj.q_weight', 'model.layers.12.mlp.down_proj.q_weight'}, {'model.layers.12.mlp.gate_proj.q_groups', 'model.layers.42.mlp.gate_proj.q_groups'}, {'model.layers.12.mlp.gate_proj.q_invperm', 'model.layers.42.mlp.gate_proj.q_invperm'}, {'model.layers.12.mlp.gate_proj.q_scale', 'model.layers.42.mlp.gate_proj.q_scale'}, {'model.layers.12.mlp.gate_proj.q_scale_max', 'model.layers.42.mlp.gate_proj.q_scale_max'}, {'model.layers.12.mlp.gate_proj.q_weight', 'model.layers.42.mlp.gate_proj.q_weight'}, {'model.layers.12.mlp.up_proj.q_groups', 'model.layers.42.mlp.up_proj.q_groups'}, {'model.layers.42.mlp.up_proj.q_invperm', 'model.layers.12.mlp.up_proj.q_invperm'}, {'model.layers.12.mlp.up_proj.q_scale', 'model.layers.42.mlp.up_proj.q_scale'}, {'model.layers.42.mlp.up_proj.q_scale_max', 'model.layers.12.mlp.up_proj.q_scale_max'}, {'model.layers.12.mlp.up_proj.q_weight', 'model.layers.42.mlp.up_proj.q_weight'}, {'model.layers.12.post_attention_layernorm.weight', 'model.layers.42.post_attention_layernorm.weight'}, {'model.layers.42.self_attn.k_proj.q_groups', 'model.layers.12.self_attn.k_proj.q_groups'}, {'model.layers.42.self_attn.k_proj.q_invperm', 'model.layers.12.self_attn.k_proj.q_invperm'}, {'model.layers.42.self_attn.k_proj.q_scale', 'model.layers.12.self_attn.k_proj.q_scale'}, {'model.layers.42.self_attn.k_proj.q_scale_max', 'model.layers.12.self_attn.k_proj.q_scale_max'}, {'model.layers.12.self_attn.k_proj.q_weight', 'model.layers.42.self_attn.k_proj.q_weight'}, {'model.layers.42.self_attn.o_proj.q_groups', 'model.layers.12.self_attn.o_proj.q_groups'}, {'model.layers.42.self_attn.o_proj.q_invperm', 'model.layers.12.self_attn.o_proj.q_invperm'}, {'model.layers.42.self_attn.o_proj.q_scale', 'model.layers.12.self_attn.o_proj.q_scale'}, {'model.layers.12.self_attn.o_proj.q_scale_max', 'model.layers.42.self_attn.o_proj.q_scale_max'}, {'model.layers.12.self_attn.o_proj.q_weight', 'model.layers.42.self_attn.o_proj.q_weight'}, {'model.layers.12.self_attn.q_proj.q_groups', 'model.layers.42.self_attn.q_proj.q_groups'}, {'model.layers.42.self_attn.q_proj.q_invperm', 'model.layers.12.self_attn.q_proj.q_invperm'}, {'model.layers.42.self_attn.q_proj.q_scale', 'model.layers.12.self_attn.q_proj.q_scale'}, {'model.layers.12.self_attn.q_proj.q_scale_max', 'model.layers.42.self_attn.q_proj.q_scale_max'}, {'model.layers.12.self_attn.q_proj.q_weight', 'model.layers.42.self_attn.q_proj.q_weight'}, {'model.layers.42.self_attn.v_proj.q_groups', 'model.layers.12.self_attn.v_proj.q_groups'}, {'model.layers.12.self_attn.v_proj.q_invperm', 'model.layers.42.self_attn.v_proj.q_invperm'}, {'model.layers.12.self_attn.v_proj.q_scale', 'model.layers.42.self_attn.v_proj.q_scale'}, {'model.layers.12.self_attn.v_proj.q_scale_max', 'model.layers.42.self_attn.v_proj.q_scale_max'}, {'model.layers.42.self_attn.v_proj.q_weight', 'model.layers.12.self_attn.v_proj.q_weight'}, {'model.layers.43.input_layernorm.weight', 'model.layers.13.input_layernorm.weight'}, {'model.layers.43.mlp.down_proj.q_groups', 'model.layers.13.mlp.down_proj.q_groups'}, {'model.layers.13.mlp.down_proj.q_invperm', 'model.layers.43.mlp.down_proj.q_invperm'}, {'model.layers.43.mlp.down_proj.q_scale', 'model.layers.13.mlp.down_proj.q_scale'}, {'model.layers.43.mlp.down_proj.q_scale_max', 'model.layers.13.mlp.down_proj.q_scale_max'}, {'model.layers.43.mlp.down_proj.q_weight', 'model.layers.13.mlp.down_proj.q_weight'}, {'model.layers.13.mlp.gate_proj.q_groups', 'model.layers.43.mlp.gate_proj.q_groups'}, {'model.layers.13.mlp.gate_proj.q_invperm', 'model.layers.43.mlp.gate_proj.q_invperm'}, {'model.layers.43.mlp.gate_proj.q_scale', 'model.layers.13.mlp.gate_proj.q_scale'}, {'model.layers.43.mlp.gate_proj.q_scale_max', 'model.layers.13.mlp.gate_proj.q_scale_max'}, {'model.layers.13.mlp.gate_proj.q_weight', 'model.layers.43.mlp.gate_proj.q_weight'}, {'model.layers.13.mlp.up_proj.q_groups', 'model.layers.43.mlp.up_proj.q_groups'}, {'model.layers.43.mlp.up_proj.q_invperm', 'model.layers.13.mlp.up_proj.q_invperm'}, {'model.layers.13.mlp.up_proj.q_scale', 'model.layers.43.mlp.up_proj.q_scale'}, {'model.layers.43.mlp.up_proj.q_scale_max', 'model.layers.13.mlp.up_proj.q_scale_max'}, {'model.layers.13.mlp.up_proj.q_weight', 'model.layers.43.mlp.up_proj.q_weight'}, {'model.layers.13.post_attention_layernorm.weight', 'model.layers.43.post_attention_layernorm.weight'}, {'model.layers.43.self_attn.k_proj.q_groups', 'model.layers.13.self_attn.k_proj.q_groups'}, {'model.layers.43.self_attn.k_proj.q_invperm', 'model.layers.13.self_attn.k_proj.q_invperm'}, {'model.layers.13.self_attn.k_proj.q_scale', 'model.layers.43.self_attn.k_proj.q_scale'}, {'model.layers.43.self_attn.k_proj.q_scale_max', 'model.layers.13.self_attn.k_proj.q_scale_max'}, {'model.layers.43.self_attn.k_proj.q_weight', 'model.layers.13.self_attn.k_proj.q_weight'}, {'model.layers.43.self_attn.o_proj.q_groups', 'model.layers.13.self_attn.o_proj.q_groups'}, {'model.layers.43.self_attn.o_proj.q_invperm', 'model.layers.13.self_attn.o_proj.q_invperm'}, {'model.layers.13.self_attn.o_proj.q_scale', 'model.layers.43.self_attn.o_proj.q_scale'}, {'model.layers.43.self_attn.o_proj.q_scale_max', 'model.layers.13.self_attn.o_proj.q_scale_max'}, {'model.layers.43.self_attn.o_proj.q_weight', 'model.layers.13.self_attn.o_proj.q_weight'}, {'model.layers.13.self_attn.q_proj.q_groups', 'model.layers.43.self_attn.q_proj.q_groups'}, {'model.layers.43.self_attn.q_proj.q_invperm', 'model.layers.13.self_attn.q_proj.q_invperm'}, {'model.layers.13.self_attn.q_proj.q_scale', 'model.layers.43.self_attn.q_proj.q_scale'}, {'model.layers.43.self_attn.q_proj.q_scale_max', 'model.layers.13.self_attn.q_proj.q_scale_max'}, {'model.layers.13.self_attn.q_proj.q_weight', 'model.layers.43.self_attn.q_proj.q_weight'}, {'model.layers.43.self_attn.v_proj.q_groups', 'model.layers.13.self_attn.v_proj.q_groups'}, {'model.layers.13.self_attn.v_proj.q_invperm', 'model.layers.43.self_attn.v_proj.q_invperm'}, {'model.layers.13.self_attn.v_proj.q_scale', 'model.layers.43.self_attn.v_proj.q_scale'}, {'model.layers.13.self_attn.v_proj.q_scale_max', 'model.layers.43.self_attn.v_proj.q_scale_max'}, {'model.layers.43.self_attn.v_proj.q_weight', 'model.layers.13.self_attn.v_proj.q_weight'}, {'model.layers.44.input_layernorm.weight', 'model.layers.14.input_layernorm.weight'}, {'model.layers.14.mlp.down_proj.q_groups', 'model.layers.44.mlp.down_proj.q_groups'}, {'model.layers.44.mlp.down_proj.q_invperm', 'model.layers.14.mlp.down_proj.q_invperm'}, {'model.layers.44.mlp.down_proj.q_scale', 'model.layers.14.mlp.down_proj.q_scale'}, {'model.layers.44.mlp.down_proj.q_scale_max', 'model.layers.14.mlp.down_proj.q_scale_max'}, {'model.layers.44.mlp.down_proj.q_weight', 'model.layers.14.mlp.down_proj.q_weight'}, {'model.layers.44.mlp.gate_proj.q_groups', 'model.layers.14.mlp.gate_proj.q_groups'}, {'model.layers.14.mlp.gate_proj.q_invperm', 'model.layers.44.mlp.gate_proj.q_invperm'}, {'model.layers.14.mlp.gate_proj.q_scale', 'model.layers.44.mlp.gate_proj.q_scale'}, {'model.layers.14.mlp.gate_proj.q_scale_max', 'model.layers.44.mlp.gate_proj.q_scale_max'}, {'model.layers.14.mlp.gate_proj.q_weight', 'model.layers.44.mlp.gate_proj.q_weight'}, {'model.layers.44.mlp.up_proj.q_groups', 'model.layers.14.mlp.up_proj.q_groups'}, {'model.layers.14.mlp.up_proj.q_invperm', 'model.layers.44.mlp.up_proj.q_invperm'}, {'model.layers.44.mlp.up_proj.q_scale', 'model.layers.14.mlp.up_proj.q_scale'}, {'model.layers.44.mlp.up_proj.q_scale_max', 'model.layers.14.mlp.up_proj.q_scale_max'}, {'model.layers.14.mlp.up_proj.q_weight', 'model.layers.44.mlp.up_proj.q_weight'}, {'model.layers.44.post_attention_layernorm.weight', 'model.layers.14.post_attention_layernorm.weight'}, {'model.layers.44.self_attn.k_proj.q_groups', 'model.layers.14.self_attn.k_proj.q_groups'}, {'model.layers.44.self_attn.k_proj.q_invperm', 'model.layers.14.self_attn.k_proj.q_invperm'}, {'model.layers.14.self_attn.k_proj.q_scale', 'model.layers.44.self_attn.k_proj.q_scale'}, {'model.layers.14.self_attn.k_proj.q_scale_max', 'model.layers.44.self_attn.k_proj.q_scale_max'}, {'model.layers.44.self_attn.k_proj.q_weight', 'model.layers.14.self_attn.k_proj.q_weight'}, {'model.layers.14.self_attn.o_proj.q_groups', 'model.layers.44.self_attn.o_proj.q_groups'}, {'model.layers.44.self_attn.o_proj.q_invperm', 'model.layers.14.self_attn.o_proj.q_invperm'}, {'model.layers.44.self_attn.o_proj.q_scale', 'model.layers.14.self_attn.o_proj.q_scale'}, {'model.layers.14.self_attn.o_proj.q_scale_max', 'model.layers.44.self_attn.o_proj.q_scale_max'}, {'model.layers.14.self_attn.o_proj.q_weight', 'model.layers.44.self_attn.o_proj.q_weight'}, {'model.layers.44.self_attn.q_proj.q_groups', 'model.layers.14.self_attn.q_proj.q_groups'}, {'model.layers.44.self_attn.q_proj.q_invperm', 'model.layers.14.self_attn.q_proj.q_invperm'}, {'model.layers.44.self_attn.q_proj.q_scale', 'model.layers.14.self_attn.q_proj.q_scale'}, {'model.layers.14.self_attn.q_proj.q_scale_max', 'model.layers.44.self_attn.q_proj.q_scale_max'}, {'model.layers.14.self_attn.q_proj.q_weight', 'model.layers.44.self_attn.q_proj.q_weight'}, {'model.layers.44.self_attn.v_proj.q_groups', 'model.layers.14.self_attn.v_proj.q_groups'}, {'model.layers.44.self_attn.v_proj.q_invperm', 'model.layers.14.self_attn.v_proj.q_invperm'}, {'model.layers.44.self_attn.v_proj.q_scale', 'model.layers.14.self_attn.v_proj.q_scale'}, {'model.layers.44.self_attn.v_proj.q_scale_max', 'model.layers.14.self_attn.v_proj.q_scale_max'}, {'model.layers.44.self_attn.v_proj.q_weight', 'model.layers.14.self_attn.v_proj.q_weight'}, {'model.layers.15.input_layernorm.weight', 'model.layers.45.input_layernorm.weight'}, {'model.layers.15.mlp.down_proj.q_groups', 'model.layers.45.mlp.down_proj.q_groups'}, {'model.layers.45.mlp.down_proj.q_invperm', 'model.layers.15.mlp.down_proj.q_invperm'}, {'model.layers.45.mlp.down_proj.q_scale', 'model.layers.15.mlp.down_proj.q_scale'}, {'model.layers.15.mlp.down_proj.q_scale_max', 'model.layers.45.mlp.down_proj.q_scale_max'}, {'model.layers.15.mlp.down_proj.q_weight', 'model.layers.45.mlp.down_proj.q_weight'}, {'model.layers.45.mlp.gate_proj.q_groups', 'model.layers.15.mlp.gate_proj.q_groups'}, {'model.layers.45.mlp.gate_proj.q_invperm', 'model.layers.15.mlp.gate_proj.q_invperm'}, {'model.layers.15.mlp.gate_proj.q_scale', 'model.layers.45.mlp.gate_proj.q_scale'}, {'model.layers.15.mlp.gate_proj.q_scale_max', 'model.layers.45.mlp.gate_proj.q_scale_max'}, {'model.layers.15.mlp.gate_proj.q_weight', 'model.layers.45.mlp.gate_proj.q_weight'}, {'model.layers.45.mlp.up_proj.q_groups', 'model.layers.15.mlp.up_proj.q_groups'}, {'model.layers.45.mlp.up_proj.q_invperm', 'model.layers.15.mlp.up_proj.q_invperm'}, {'model.layers.45.mlp.up_proj.q_scale', 'model.layers.15.mlp.up_proj.q_scale'}, {'model.layers.45.mlp.up_proj.q_scale_max', 'model.layers.15.mlp.up_proj.q_scale_max'}, {'model.layers.45.mlp.up_proj.q_weight', 'model.layers.15.mlp.up_proj.q_weight'}, {'model.layers.45.post_attention_layernorm.weight', 'model.layers.15.post_attention_layernorm.weight'}, {'model.layers.45.self_attn.k_proj.q_groups', 'model.layers.15.self_attn.k_proj.q_groups'}, {'model.layers.45.self_attn.k_proj.q_invperm', 'model.layers.15.self_attn.k_proj.q_invperm'}, {'model.layers.15.self_attn.k_proj.q_scale', 'model.layers.45.self_attn.k_proj.q_scale'}, {'model.layers.15.self_attn.k_proj.q_scale_max', 'model.layers.45.self_attn.k_proj.q_scale_max'}, {'model.layers.15.self_attn.k_proj.q_weight', 'model.layers.45.self_attn.k_proj.q_weight'}, {'model.layers.15.self_attn.o_proj.q_groups', 'model.layers.45.self_attn.o_proj.q_groups'}, {'model.layers.15.self_attn.o_proj.q_invperm', 'model.layers.45.self_attn.o_proj.q_invperm'}, {'model.layers.15.self_attn.o_proj.q_scale', 'model.layers.45.self_attn.o_proj.q_scale'}, {'model.layers.15.self_attn.o_proj.q_scale_max', 'model.layers.45.self_attn.o_proj.q_scale_max'}, {'model.layers.45.self_attn.o_proj.q_weight', 'model.layers.15.self_attn.o_proj.q_weight'}, {'model.layers.15.self_attn.q_proj.q_groups', 'model.layers.45.self_attn.q_proj.q_groups'}, {'model.layers.45.self_attn.q_proj.q_invperm', 'model.layers.15.self_attn.q_proj.q_invperm'}, {'model.layers.45.self_attn.q_proj.q_scale', 'model.layers.15.self_attn.q_proj.q_scale'}, {'model.layers.45.self_attn.q_proj.q_scale_max', 'model.layers.15.self_attn.q_proj.q_scale_max'}, {'model.layers.45.self_attn.q_proj.q_weight', 'model.layers.15.self_attn.q_proj.q_weight'}, {'model.layers.45.self_attn.v_proj.q_groups', 'model.layers.15.self_attn.v_proj.q_groups'}, {'model.layers.45.self_attn.v_proj.q_invperm', 'model.layers.15.self_attn.v_proj.q_invperm'}, {'model.layers.15.self_attn.v_proj.q_scale', 'model.layers.45.self_attn.v_proj.q_scale'}, {'model.layers.15.self_attn.v_proj.q_scale_max', 'model.layers.45.self_attn.v_proj.q_scale_max'}, {'model.layers.45.self_attn.v_proj.q_weight', 'model.layers.15.self_attn.v_proj.q_weight'}, {'model.layers.16.input_layernorm.weight', 'model.layers.46.input_layernorm.weight'}, {'model.layers.16.mlp.down_proj.q_groups', 'model.layers.46.mlp.down_proj.q_groups'}, {'model.layers.16.mlp.down_proj.q_invperm', 'model.layers.46.mlp.down_proj.q_invperm'}, {'model.layers.16.mlp.down_proj.q_scale', 'model.layers.46.mlp.down_proj.q_scale'}, {'model.layers.46.mlp.down_proj.q_scale_max', 'model.layers.16.mlp.down_proj.q_scale_max'}, {'model.layers.16.mlp.down_proj.q_weight', 'model.layers.46.mlp.down_proj.q_weight'}, {'model.layers.46.mlp.gate_proj.q_groups', 'model.layers.16.mlp.gate_proj.q_groups'}, {'model.layers.46.mlp.gate_proj.q_invperm', 'model.layers.16.mlp.gate_proj.q_invperm'}, {'model.layers.16.mlp.gate_proj.q_scale', 'model.layers.46.mlp.gate_proj.q_scale'}, {'model.layers.46.mlp.gate_proj.q_scale_max', 'model.layers.16.mlp.gate_proj.q_scale_max'}, {'model.layers.46.mlp.gate_proj.q_weight', 'model.layers.16.mlp.gate_proj.q_weight'}, {'model.layers.46.mlp.up_proj.q_groups', 'model.layers.16.mlp.up_proj.q_groups'}, {'model.layers.16.mlp.up_proj.q_invperm', 'model.layers.46.mlp.up_proj.q_invperm'}, {'model.layers.16.mlp.up_proj.q_scale', 'model.layers.46.mlp.up_proj.q_scale'}, {'model.layers.16.mlp.up_proj.q_scale_max', 'model.layers.46.mlp.up_proj.q_scale_max'}, {'model.layers.46.mlp.up_proj.q_weight', 'model.layers.16.mlp.up_proj.q_weight'}, {'model.layers.16.post_attention_layernorm.weight', 'model.layers.46.post_attention_layernorm.weight'}, {'model.layers.46.self_attn.k_proj.q_groups', 'model.layers.16.self_attn.k_proj.q_groups'}, {'model.layers.16.self_attn.k_proj.q_invperm', 'model.layers.46.self_attn.k_proj.q_invperm'}, {'model.layers.16.self_attn.k_proj.q_scale', 'model.layers.46.self_attn.k_proj.q_scale'}, {'model.layers.16.self_attn.k_proj.q_scale_max', 'model.layers.46.self_attn.k_proj.q_scale_max'}, {'model.layers.46.self_attn.k_proj.q_weight', 'model.layers.16.self_attn.k_proj.q_weight'}, {'model.layers.46.self_attn.o_proj.q_groups', 'model.layers.16.self_attn.o_proj.q_groups'}, {'model.layers.46.self_attn.o_proj.q_invperm', 'model.layers.16.self_attn.o_proj.q_invperm'}, {'model.layers.46.self_attn.o_proj.q_scale', 'model.layers.16.self_attn.o_proj.q_scale'}, {'model.layers.46.self_attn.o_proj.q_scale_max', 'model.layers.16.self_attn.o_proj.q_scale_max'}, {'model.layers.16.self_attn.o_proj.q_weight', 'model.layers.46.self_attn.o_proj.q_weight'}, {'model.layers.46.self_attn.q_proj.q_groups', 'model.layers.16.self_attn.q_proj.q_groups'}, {'model.layers.46.self_attn.q_proj.q_invperm', 'model.layers.16.self_attn.q_proj.q_invperm'}, {'model.layers.46.self_attn.q_proj.q_scale', 'model.layers.16.self_attn.q_proj.q_scale'}, {'model.layers.46.self_attn.q_proj.q_scale_max', 'model.layers.16.self_attn.q_proj.q_scale_max'}, {'model.layers.46.self_attn.q_proj.q_weight', 'model.layers.16.self_attn.q_proj.q_weight'}, {'model.layers.46.self_attn.v_proj.q_groups', 'model.layers.16.self_attn.v_proj.q_groups'}, {'model.layers.16.self_attn.v_proj.q_invperm', 'model.layers.46.self_attn.v_proj.q_invperm'}, {'model.layers.16.self_attn.v_proj.q_scale', 'model.layers.46.self_attn.v_proj.q_scale'}, {'model.layers.46.self_attn.v_proj.q_scale_max', 'model.layers.16.self_attn.v_proj.q_scale_max'}, {'model.layers.46.self_attn.v_proj.q_weight', 'model.layers.16.self_attn.v_proj.q_weight'}, {'model.layers.17.input_layernorm.weight', 'model.layers.47.input_layernorm.weight'}, {'model.layers.47.mlp.down_proj.q_groups', 'model.layers.17.mlp.down_proj.q_groups'}, {'model.layers.47.mlp.down_proj.q_invperm', 'model.layers.17.mlp.down_proj.q_invperm'}, {'model.layers.47.mlp.down_proj.q_scale', 'model.layers.17.mlp.down_proj.q_scale'}, {'model.layers.47.mlp.down_proj.q_scale_max', 'model.layers.17.mlp.down_proj.q_scale_max'}, {'model.layers.47.mlp.down_proj.q_weight', 'model.layers.17.mlp.down_proj.q_weight'}, {'model.layers.17.mlp.gate_proj.q_groups', 'model.layers.47.mlp.gate_proj.q_groups'}, {'model.layers.47.mlp.gate_proj.q_invperm', 'model.layers.17.mlp.gate_proj.q_invperm'}, {'model.layers.47.mlp.gate_proj.q_scale', 'model.layers.17.mlp.gate_proj.q_scale'}, {'model.layers.17.mlp.gate_proj.q_scale_max', 'model.layers.47.mlp.gate_proj.q_scale_max'}, {'model.layers.47.mlp.gate_proj.q_weight', 'model.layers.17.mlp.gate_proj.q_weight'}, {'model.layers.47.mlp.up_proj.q_groups', 'model.layers.17.mlp.up_proj.q_groups'}, {'model.layers.17.mlp.up_proj.q_invperm', 'model.layers.47.mlp.up_proj.q_invperm'}, {'model.layers.17.mlp.up_proj.q_scale', 'model.layers.47.mlp.up_proj.q_scale'}, {'model.layers.17.mlp.up_proj.q_scale_max', 'model.layers.47.mlp.up_proj.q_scale_max'}, {'model.layers.47.mlp.up_proj.q_weight', 'model.layers.17.mlp.up_proj.q_weight'}, {'model.layers.17.post_attention_layernorm.weight', 'model.layers.47.post_attention_layernorm.weight'}, {'model.layers.17.self_attn.k_proj.q_groups', 'model.layers.47.self_attn.k_proj.q_groups'}, {'model.layers.17.self_attn.k_proj.q_invperm', 'model.layers.47.self_attn.k_proj.q_invperm'}, {'model.layers.47.self_attn.k_proj.q_scale', 'model.layers.17.self_attn.k_proj.q_scale'}, {'model.layers.47.self_attn.k_proj.q_scale_max', 'model.layers.17.self_attn.k_proj.q_scale_max'}, {'model.layers.47.self_attn.k_proj.q_weight', 'model.layers.17.self_attn.k_proj.q_weight'}, {'model.layers.47.self_attn.o_proj.q_groups', 'model.layers.17.self_attn.o_proj.q_groups'}, {'model.layers.47.self_attn.o_proj.q_invperm', 'model.layers.17.self_attn.o_proj.q_invperm'}, {'model.layers.47.self_attn.o_proj.q_scale', 'model.layers.17.self_attn.o_proj.q_scale'}, {'model.layers.47.self_attn.o_proj.q_scale_max', 'model.layers.17.self_attn.o_proj.q_scale_max'}, {'model.layers.47.self_attn.o_proj.q_weight', 'model.layers.17.self_attn.o_proj.q_weight'}, {'model.layers.47.self_attn.q_proj.q_groups', 'model.layers.17.self_attn.q_proj.q_groups'}, {'model.layers.17.self_attn.q_proj.q_invperm', 'model.layers.47.self_attn.q_proj.q_invperm'}, {'model.layers.17.self_attn.q_proj.q_scale', 'model.layers.47.self_attn.q_proj.q_scale'}, {'model.layers.47.self_attn.q_proj.q_scale_max', 'model.layers.17.self_attn.q_proj.q_scale_max'}, {'model.layers.17.self_attn.q_proj.q_weight', 'model.layers.47.self_attn.q_proj.q_weight'}, {'model.layers.47.self_attn.v_proj.q_groups', 'model.layers.17.self_attn.v_proj.q_groups'}, {'model.layers.17.self_attn.v_proj.q_invperm', 'model.layers.47.self_attn.v_proj.q_invperm'}, {'model.layers.47.self_attn.v_proj.q_scale', 'model.layers.17.self_attn.v_proj.q_scale'}, {'model.layers.17.self_attn.v_proj.q_scale_max', 'model.layers.47.self_attn.v_proj.q_scale_max'}, {'model.layers.47.self_attn.v_proj.q_weight', 'model.layers.17.self_attn.v_proj.q_weight'}, {'model.layers.48.input_layernorm.weight', 'model.layers.18.input_layernorm.weight'}, {'model.layers.48.mlp.down_proj.q_groups', 'model.layers.18.mlp.down_proj.q_groups'}, {'model.layers.48.mlp.down_proj.q_invperm', 'model.layers.18.mlp.down_proj.q_invperm'}, {'model.layers.48.mlp.down_proj.q_scale', 'model.layers.18.mlp.down_proj.q_scale'}, {'model.layers.48.mlp.down_proj.q_scale_max', 'model.layers.18.mlp.down_proj.q_scale_max'}, {'model.layers.18.mlp.down_proj.q_weight', 'model.layers.48.mlp.down_proj.q_weight'}, {'model.layers.18.mlp.gate_proj.q_groups', 'model.layers.48.mlp.gate_proj.q_groups'}, {'model.layers.48.mlp.gate_proj.q_invperm', 'model.layers.18.mlp.gate_proj.q_invperm'}, {'model.layers.48.mlp.gate_proj.q_scale', 'model.layers.18.mlp.gate_proj.q_scale'}, {'model.layers.18.mlp.gate_proj.q_scale_max', 'model.layers.48.mlp.gate_proj.q_scale_max'}, {'model.layers.48.mlp.gate_proj.q_weight', 'model.layers.18.mlp.gate_proj.q_weight'}, {'model.layers.18.mlp.up_proj.q_groups', 'model.layers.48.mlp.up_proj.q_groups'}, {'model.layers.48.mlp.up_proj.q_invperm', 'model.layers.18.mlp.up_proj.q_invperm'}, {'model.layers.18.mlp.up_proj.q_scale', 'model.layers.48.mlp.up_proj.q_scale'}, {'model.layers.48.mlp.up_proj.q_scale_max', 'model.layers.18.mlp.up_proj.q_scale_max'}, {'model.layers.48.mlp.up_proj.q_weight', 'model.layers.18.mlp.up_proj.q_weight'}, {'model.layers.18.post_attention_layernorm.weight', 'model.layers.48.post_attention_layernorm.weight'}, {'model.layers.18.self_attn.k_proj.q_groups', 'model.layers.48.self_attn.k_proj.q_groups'}, {'model.layers.18.self_attn.k_proj.q_invperm', 'model.layers.48.self_attn.k_proj.q_invperm'}, {'model.layers.48.self_attn.k_proj.q_scale', 'model.layers.18.self_attn.k_proj.q_scale'}, {'model.layers.48.self_attn.k_proj.q_scale_max', 'model.layers.18.self_attn.k_proj.q_scale_max'}, {'model.layers.18.self_attn.k_proj.q_weight', 'model.layers.48.self_attn.k_proj.q_weight'}, {'model.layers.18.self_attn.o_proj.q_groups', 'model.layers.48.self_attn.o_proj.q_groups'}, {'model.layers.48.self_attn.o_proj.q_invperm', 'model.layers.18.self_attn.o_proj.q_invperm'}, {'model.layers.48.self_attn.o_proj.q_scale', 'model.layers.18.self_attn.o_proj.q_scale'}, {'model.layers.48.self_attn.o_proj.q_scale_max', 'model.layers.18.self_attn.o_proj.q_scale_max'}, {'model.layers.18.self_attn.o_proj.q_weight', 'model.layers.48.self_attn.o_proj.q_weight'}, {'model.layers.18.self_attn.q_proj.q_groups', 'model.layers.48.self_attn.q_proj.q_groups'}, {'model.layers.18.self_attn.q_proj.q_invperm', 'model.layers.48.self_attn.q_proj.q_invperm'}, {'model.layers.48.self_attn.q_proj.q_scale', 'model.layers.18.self_attn.q_proj.q_scale'}, {'model.layers.18.self_attn.q_proj.q_scale_max', 'model.layers.48.self_attn.q_proj.q_scale_max'}, {'model.layers.48.self_attn.q_proj.q_weight', 'model.layers.18.self_attn.q_proj.q_weight'}, {'model.layers.48.self_attn.v_proj.q_groups', 'model.layers.18.self_attn.v_proj.q_groups'}, {'model.layers.48.self_attn.v_proj.q_invperm', 'model.layers.18.self_attn.v_proj.q_invperm'}, {'model.layers.48.self_attn.v_proj.q_scale', 'model.layers.18.self_attn.v_proj.q_scale'}, {'model.layers.48.self_attn.v_proj.q_scale_max', 'model.layers.18.self_attn.v_proj.q_scale_max'}, {'model.layers.18.self_attn.v_proj.q_weight', 'model.layers.48.self_attn.v_proj.q_weight'}, {'model.layers.49.input_layernorm.weight', 'model.layers.19.input_layernorm.weight'}, {'model.layers.19.mlp.down_proj.q_groups', 'model.layers.49.mlp.down_proj.q_groups'}, {'model.layers.19.mlp.down_proj.q_invperm', 'model.layers.49.mlp.down_proj.q_invperm'}, {'model.layers.49.mlp.down_proj.q_scale', 'model.layers.19.mlp.down_proj.q_scale'}, {'model.layers.49.mlp.down_proj.q_scale_max', 'model.layers.19.mlp.down_proj.q_scale_max'}, {'model.layers.19.mlp.down_proj.q_weight', 'model.layers.49.mlp.down_proj.q_weight'}, {'model.layers.19.mlp.gate_proj.q_groups', 'model.layers.49.mlp.gate_proj.q_groups'}, {'model.layers.19.mlp.gate_proj.q_invperm', 'model.layers.49.mlp.gate_proj.q_invperm'}, {'model.layers.19.mlp.gate_proj.q_scale', 'model.layers.49.mlp.gate_proj.q_scale'}, {'model.layers.49.mlp.gate_proj.q_scale_max', 'model.layers.19.mlp.gate_proj.q_scale_max'}, {'model.layers.49.mlp.gate_proj.q_weight', 'model.layers.19.mlp.gate_proj.q_weight'}, {'model.layers.49.mlp.up_proj.q_groups', 'model.layers.19.mlp.up_proj.q_groups'}, {'model.layers.19.mlp.up_proj.q_invperm', 'model.layers.49.mlp.up_proj.q_invperm'}, {'model.layers.19.mlp.up_proj.q_scale', 'model.layers.49.mlp.up_proj.q_scale'}, {'model.layers.49.mlp.up_proj.q_scale_max', 'model.layers.19.mlp.up_proj.q_scale_max'}, {'model.layers.19.mlp.up_proj.q_weight', 'model.layers.49.mlp.up_proj.q_weight'}, {'model.layers.49.post_attention_layernorm.weight', 'model.layers.19.post_attention_layernorm.weight'}, {'model.layers.19.self_attn.k_proj.q_groups', 'model.layers.49.self_attn.k_proj.q_groups'}, {'model.layers.49.self_attn.k_proj.q_invperm', 'model.layers.19.self_attn.k_proj.q_invperm'}, {'model.layers.49.self_attn.k_proj.q_scale', 'model.layers.19.self_attn.k_proj.q_scale'}, {'model.layers.19.self_attn.k_proj.q_scale_max', 'model.layers.49.self_attn.k_proj.q_scale_max'}, {'model.layers.49.self_attn.k_proj.q_weight', 'model.layers.19.self_attn.k_proj.q_weight'}, {'model.layers.49.self_attn.o_proj.q_groups', 'model.layers.19.self_attn.o_proj.q_groups'}, {'model.layers.49.self_attn.o_proj.q_invperm', 'model.layers.19.self_attn.o_proj.q_invperm'}, {'model.layers.19.self_attn.o_proj.q_scale', 'model.layers.49.self_attn.o_proj.q_scale'}, {'model.layers.19.self_attn.o_proj.q_scale_max', 'model.layers.49.self_attn.o_proj.q_scale_max'}, {'model.layers.19.self_attn.o_proj.q_weight', 'model.layers.49.self_attn.o_proj.q_weight'}, {'model.layers.49.self_attn.q_proj.q_groups', 'model.layers.19.self_attn.q_proj.q_groups'}, {'model.layers.49.self_attn.q_proj.q_invperm', 'model.layers.19.self_attn.q_proj.q_invperm'}, {'model.layers.49.self_attn.q_proj.q_scale', 'model.layers.19.self_attn.q_proj.q_scale'}, {'model.layers.19.self_attn.q_proj.q_scale_max', 'model.layers.49.self_attn.q_proj.q_scale_max'}, {'model.layers.49.self_attn.q_proj.q_weight', 'model.layers.19.self_attn.q_proj.q_weight'}, {'model.layers.49.self_attn.v_proj.q_groups', 'model.layers.19.self_attn.v_proj.q_groups'}, {'model.layers.49.self_attn.v_proj.q_invperm', 'model.layers.19.self_attn.v_proj.q_invperm'}, {'model.layers.49.self_attn.v_proj.q_scale', 'model.layers.19.self_attn.v_proj.q_scale'}, {'model.layers.49.self_attn.v_proj.q_scale_max', 'model.layers.19.self_attn.v_proj.q_scale_max'}, {'model.layers.19.self_attn.v_proj.q_weight', 'model.layers.49.self_attn.v_proj.q_weight'}, {'model.layers.50.input_layernorm.weight', 'model.layers.20.input_layernorm.weight'}, {'model.layers.50.mlp.down_proj.q_groups', 'model.layers.20.mlp.down_proj.q_groups'}, {'model.layers.50.mlp.down_proj.q_invperm', 'model.layers.20.mlp.down_proj.q_invperm'}, {'model.layers.20.mlp.down_proj.q_scale', 'model.layers.50.mlp.down_proj.q_scale'}, {'model.layers.50.mlp.down_proj.q_scale_max', 'model.layers.20.mlp.down_proj.q_scale_max'}, {'model.layers.50.mlp.down_proj.q_weight', 'model.layers.20.mlp.down_proj.q_weight'}, {'model.layers.50.mlp.gate_proj.q_groups', 'model.layers.20.mlp.gate_proj.q_groups'}, {'model.layers.50.mlp.gate_proj.q_invperm', 'model.layers.20.mlp.gate_proj.q_invperm'}, {'model.layers.50.mlp.gate_proj.q_scale', 'model.layers.20.mlp.gate_proj.q_scale'}, {'model.layers.20.mlp.gate_proj.q_scale_max', 'model.layers.50.mlp.gate_proj.q_scale_max'}, {'model.layers.50.mlp.gate_proj.q_weight', 'model.layers.20.mlp.gate_proj.q_weight'}, {'model.layers.50.mlp.up_proj.q_groups', 'model.layers.20.mlp.up_proj.q_groups'}, {'model.layers.20.mlp.up_proj.q_invperm', 'model.layers.50.mlp.up_proj.q_invperm'}, {'model.layers.50.mlp.up_proj.q_scale', 'model.layers.20.mlp.up_proj.q_scale'}, {'model.layers.20.mlp.up_proj.q_scale_max', 'model.layers.50.mlp.up_proj.q_scale_max'}, {'model.layers.20.mlp.up_proj.q_weight', 'model.layers.50.mlp.up_proj.q_weight'}, {'model.layers.20.post_attention_layernorm.weight', 'model.layers.50.post_attention_layernorm.weight'}, {'model.layers.50.self_attn.k_proj.q_groups', 'model.layers.20.self_attn.k_proj.q_groups'}, {'model.layers.50.self_attn.k_proj.q_invperm', 'model.layers.20.self_attn.k_proj.q_invperm'}, {'model.layers.20.self_attn.k_proj.q_scale', 'model.layers.50.self_attn.k_proj.q_scale'}, {'model.layers.50.self_attn.k_proj.q_scale_max', 'model.layers.20.self_attn.k_proj.q_scale_max'}, {'model.layers.20.self_attn.k_proj.q_weight', 'model.layers.50.self_attn.k_proj.q_weight'}, {'model.layers.50.self_attn.o_proj.q_groups', 'model.layers.20.self_attn.o_proj.q_groups'}, {'model.layers.50.self_attn.o_proj.q_invperm', 'model.layers.20.self_attn.o_proj.q_invperm'}, {'model.layers.50.self_attn.o_proj.q_scale', 'model.layers.20.self_attn.o_proj.q_scale'}, {'model.layers.20.self_attn.o_proj.q_scale_max', 'model.layers.50.self_attn.o_proj.q_scale_max'}, {'model.layers.20.self_attn.o_proj.q_weight', 'model.layers.50.self_attn.o_proj.q_weight'}, {'model.layers.50.self_attn.q_proj.q_groups', 'model.layers.20.self_attn.q_proj.q_groups'}, {'model.layers.20.self_attn.q_proj.q_invperm', 'model.layers.50.self_attn.q_proj.q_invperm'}, {'model.layers.20.self_attn.q_proj.q_scale', 'model.layers.50.self_attn.q_proj.q_scale'}, {'model.layers.50.self_attn.q_proj.q_scale_max', 'model.layers.20.self_attn.q_proj.q_scale_max'}, {'model.layers.20.self_attn.q_proj.q_weight', 'model.layers.50.self_attn.q_proj.q_weight'}, {'model.layers.50.self_attn.v_proj.q_groups', 'model.layers.20.self_attn.v_proj.q_groups'}, {'model.layers.20.self_attn.v_proj.q_invperm', 'model.layers.50.self_attn.v_proj.q_invperm'}, {'model.layers.50.self_attn.v_proj.q_scale', 'model.layers.20.self_attn.v_proj.q_scale'}, {'model.layers.50.self_attn.v_proj.q_scale_max', 'model.layers.20.self_attn.v_proj.q_scale_max'}, {'model.layers.50.self_attn.v_proj.q_weight', 'model.layers.20.self_attn.v_proj.q_weight'}, {'model.layers.51.input_layernorm.weight', 'model.layers.21.input_layernorm.weight'}, {'model.layers.51.mlp.down_proj.q_groups', 'model.layers.21.mlp.down_proj.q_groups'}, {'model.layers.21.mlp.down_proj.q_invperm', 'model.layers.51.mlp.down_proj.q_invperm'}, {'model.layers.51.mlp.down_proj.q_scale', 'model.layers.21.mlp.down_proj.q_scale'}, {'model.layers.21.mlp.down_proj.q_scale_max', 'model.layers.51.mlp.down_proj.q_scale_max'}, {'model.layers.51.mlp.down_proj.q_weight', 'model.layers.21.mlp.down_proj.q_weight'}, {'model.layers.51.mlp.gate_proj.q_groups', 'model.layers.21.mlp.gate_proj.q_groups'}, {'model.layers.21.mlp.gate_proj.q_invperm', 'model.layers.51.mlp.gate_proj.q_invperm'}, {'model.layers.21.mlp.gate_proj.q_scale', 'model.layers.51.mlp.gate_proj.q_scale'}, {'model.layers.51.mlp.gate_proj.q_scale_max', 'model.layers.21.mlp.gate_proj.q_scale_max'}, {'model.layers.51.mlp.gate_proj.q_weight', 'model.layers.21.mlp.gate_proj.q_weight'}, {'model.layers.51.mlp.up_proj.q_groups', 'model.layers.21.mlp.up_proj.q_groups'}, {'model.layers.51.mlp.up_proj.q_invperm', 'model.layers.21.mlp.up_proj.q_invperm'}, {'model.layers.51.mlp.up_proj.q_scale', 'model.layers.21.mlp.up_proj.q_scale'}, {'model.layers.51.mlp.up_proj.q_scale_max', 'model.layers.21.mlp.up_proj.q_scale_max'}, {'model.layers.21.mlp.up_proj.q_weight', 'model.layers.51.mlp.up_proj.q_weight'}, {'model.layers.21.post_attention_layernorm.weight', 'model.layers.51.post_attention_layernorm.weight'}, {'model.layers.21.self_attn.k_proj.q_groups', 'model.layers.51.self_attn.k_proj.q_groups'}, {'model.layers.51.self_attn.k_proj.q_invperm', 'model.layers.21.self_attn.k_proj.q_invperm'}, {'model.layers.21.self_attn.k_proj.q_scale', 'model.layers.51.self_attn.k_proj.q_scale'}, {'model.layers.51.self_attn.k_proj.q_scale_max', 'model.layers.21.self_attn.k_proj.q_scale_max'}, {'model.layers.51.self_attn.k_proj.q_weight', 'model.layers.21.self_attn.k_proj.q_weight'}, {'model.layers.51.self_attn.o_proj.q_groups', 'model.layers.21.self_attn.o_proj.q_groups'}, {'model.layers.21.self_attn.o_proj.q_invperm', 'model.layers.51.self_attn.o_proj.q_invperm'}, {'model.layers.21.self_attn.o_proj.q_scale', 'model.layers.51.self_attn.o_proj.q_scale'}, {'model.layers.51.self_attn.o_proj.q_scale_max', 'model.layers.21.self_attn.o_proj.q_scale_max'}, {'model.layers.21.self_attn.o_proj.q_weight', 'model.layers.51.self_attn.o_proj.q_weight'}, {'model.layers.21.self_attn.q_proj.q_groups', 'model.layers.51.self_attn.q_proj.q_groups'}, {'model.layers.21.self_attn.q_proj.q_invperm', 'model.layers.51.self_attn.q_proj.q_invperm'}, {'model.layers.51.self_attn.q_proj.q_scale', 'model.layers.21.self_attn.q_proj.q_scale'}, {'model.layers.21.self_attn.q_proj.q_scale_max', 'model.layers.51.self_attn.q_proj.q_scale_max'}, {'model.layers.21.self_attn.q_proj.q_weight', 'model.layers.51.self_attn.q_proj.q_weight'}, {'model.layers.21.self_attn.v_proj.q_groups', 'model.layers.51.self_attn.v_proj.q_groups'}, {'model.layers.21.self_attn.v_proj.q_invperm', 'model.layers.51.self_attn.v_proj.q_invperm'}, {'model.layers.21.self_attn.v_proj.q_scale', 'model.layers.51.self_attn.v_proj.q_scale'}, {'model.layers.21.self_attn.v_proj.q_scale_max', 'model.layers.51.self_attn.v_proj.q_scale_max'}, {'model.layers.51.self_attn.v_proj.q_weight', 'model.layers.21.self_attn.v_proj.q_weight'}, {'model.layers.22.input_layernorm.weight', 'model.layers.52.input_layernorm.weight'}, {'model.layers.52.mlp.down_proj.q_groups', 'model.layers.22.mlp.down_proj.q_groups'}, {'model.layers.22.mlp.down_proj.q_invperm', 'model.layers.52.mlp.down_proj.q_invperm'}, {'model.layers.22.mlp.down_proj.q_scale', 'model.layers.52.mlp.down_proj.q_scale'}, {'model.layers.52.mlp.down_proj.q_scale_max', 'model.layers.22.mlp.down_proj.q_scale_max'}, {'model.layers.52.mlp.down_proj.q_weight', 'model.layers.22.mlp.down_proj.q_weight'}, {'model.layers.22.mlp.gate_proj.q_groups', 'model.layers.52.mlp.gate_proj.q_groups'}, {'model.layers.52.mlp.gate_proj.q_invperm', 'model.layers.22.mlp.gate_proj.q_invperm'}, {'model.layers.52.mlp.gate_proj.q_scale', 'model.layers.22.mlp.gate_proj.q_scale'}, {'model.layers.22.mlp.gate_proj.q_scale_max', 'model.layers.52.mlp.gate_proj.q_scale_max'}, {'model.layers.52.mlp.gate_proj.q_weight', 'model.layers.22.mlp.gate_proj.q_weight'}, {'model.layers.22.mlp.up_proj.q_groups', 'model.layers.52.mlp.up_proj.q_groups'}, {'model.layers.22.mlp.up_proj.q_invperm', 'model.layers.52.mlp.up_proj.q_invperm'}, {'model.layers.22.mlp.up_proj.q_scale', 'model.layers.52.mlp.up_proj.q_scale'}, {'model.layers.22.mlp.up_proj.q_scale_max', 'model.layers.52.mlp.up_proj.q_scale_max'}, {'model.layers.22.mlp.up_proj.q_weight', 'model.layers.52.mlp.up_proj.q_weight'}, {'model.layers.22.post_attention_layernorm.weight', 'model.layers.52.post_attention_layernorm.weight'}, {'model.layers.52.self_attn.k_proj.q_groups', 'model.layers.22.self_attn.k_proj.q_groups'}, {'model.layers.22.self_attn.k_proj.q_invperm', 'model.layers.52.self_attn.k_proj.q_invperm'}, {'model.layers.52.self_attn.k_proj.q_scale', 'model.layers.22.self_attn.k_proj.q_scale'}, {'model.layers.52.self_attn.k_proj.q_scale_max', 'model.layers.22.self_attn.k_proj.q_scale_max'}, {'model.layers.22.self_attn.k_proj.q_weight', 'model.layers.52.self_attn.k_proj.q_weight'}, {'model.layers.52.self_attn.o_proj.q_groups', 'model.layers.22.self_attn.o_proj.q_groups'}, {'model.layers.52.self_attn.o_proj.q_invperm', 'model.layers.22.self_attn.o_proj.q_invperm'}, {'model.layers.22.self_attn.o_proj.q_scale', 'model.layers.52.self_attn.o_proj.q_scale'}, {'model.layers.52.self_attn.o_proj.q_scale_max', 'model.layers.22.self_attn.o_proj.q_scale_max'}, {'model.layers.22.self_attn.o_proj.q_weight', 'model.layers.52.self_attn.o_proj.q_weight'}, {'model.layers.52.self_attn.q_proj.q_groups', 'model.layers.22.self_attn.q_proj.q_groups'}, {'model.layers.22.self_attn.q_proj.q_invperm', 'model.layers.52.self_attn.q_proj.q_invperm'}, {'model.layers.22.self_attn.q_proj.q_scale', 'model.layers.52.self_attn.q_proj.q_scale'}, {'model.layers.52.self_attn.q_proj.q_scale_max', 'model.layers.22.self_attn.q_proj.q_scale_max'}, {'model.layers.22.self_attn.q_proj.q_weight', 'model.layers.52.self_attn.q_proj.q_weight'}, {'model.layers.52.self_attn.v_proj.q_groups', 'model.layers.22.self_attn.v_proj.q_groups'}, {'model.layers.52.self_attn.v_proj.q_invperm', 'model.layers.22.self_attn.v_proj.q_invperm'}, {'model.layers.22.self_attn.v_proj.q_scale', 'model.layers.52.self_attn.v_proj.q_scale'}, {'model.layers.22.self_attn.v_proj.q_scale_max', 'model.layers.52.self_attn.v_proj.q_scale_max'}, {'model.layers.52.self_attn.v_proj.q_weight', 'model.layers.22.self_attn.v_proj.q_weight'}, {'model.layers.53.input_layernorm.weight', 'model.layers.23.input_layernorm.weight'}, {'model.layers.53.mlp.down_proj.q_groups', 'model.layers.23.mlp.down_proj.q_groups'}, {'model.layers.53.mlp.down_proj.q_invperm', 'model.layers.23.mlp.down_proj.q_invperm'}, {'model.layers.53.mlp.down_proj.q_scale', 'model.layers.23.mlp.down_proj.q_scale'}, {'model.layers.53.mlp.down_proj.q_scale_max', 'model.layers.23.mlp.down_proj.q_scale_max'}, {'model.layers.23.mlp.down_proj.q_weight', 'model.layers.53.mlp.down_proj.q_weight'}, {'model.layers.23.mlp.gate_proj.q_groups', 'model.layers.53.mlp.gate_proj.q_groups'}, {'model.layers.53.mlp.gate_proj.q_invperm', 'model.layers.23.mlp.gate_proj.q_invperm'}, {'model.layers.53.mlp.gate_proj.q_scale', 'model.layers.23.mlp.gate_proj.q_scale'}, {'model.layers.53.mlp.gate_proj.q_scale_max', 'model.layers.23.mlp.gate_proj.q_scale_max'}, {'model.layers.23.mlp.gate_proj.q_weight', 'model.layers.53.mlp.gate_proj.q_weight'}, {'model.layers.53.mlp.up_proj.q_groups', 'model.layers.23.mlp.up_proj.q_groups'}, {'model.layers.53.mlp.up_proj.q_invperm', 'model.layers.23.mlp.up_proj.q_invperm'}, {'model.layers.53.mlp.up_proj.q_scale', 'model.layers.23.mlp.up_proj.q_scale'}, {'model.layers.53.mlp.up_proj.q_scale_max', 'model.layers.23.mlp.up_proj.q_scale_max'}, {'model.layers.23.mlp.up_proj.q_weight', 'model.layers.53.mlp.up_proj.q_weight'}, {'model.layers.53.post_attention_layernorm.weight', 'model.layers.23.post_attention_layernorm.weight'}, {'model.layers.23.self_attn.k_proj.q_groups', 'model.layers.53.self_attn.k_proj.q_groups'}, {'model.layers.53.self_attn.k_proj.q_invperm', 'model.layers.23.self_attn.k_proj.q_invperm'}, {'model.layers.23.self_attn.k_proj.q_scale', 'model.layers.53.self_attn.k_proj.q_scale'}, {'model.layers.23.self_attn.k_proj.q_scale_max', 'model.layers.53.self_attn.k_proj.q_scale_max'}, {'model.layers.53.self_attn.k_proj.q_weight', 'model.layers.23.self_attn.k_proj.q_weight'}, {'model.layers.53.self_attn.o_proj.q_groups', 'model.layers.23.self_attn.o_proj.q_groups'}, {'model.layers.53.self_attn.o_proj.q_invperm', 'model.layers.23.self_attn.o_proj.q_invperm'}, {'model.layers.23.self_attn.o_proj.q_scale', 'model.layers.53.self_attn.o_proj.q_scale'}, {'model.layers.53.self_attn.o_proj.q_scale_max', 'model.layers.23.self_attn.o_proj.q_scale_max'}, {'model.layers.23.self_attn.o_proj.q_weight', 'model.layers.53.self_attn.o_proj.q_weight'}, {'model.layers.23.self_attn.q_proj.q_groups', 'model.layers.53.self_attn.q_proj.q_groups'}, {'model.layers.23.self_attn.q_proj.q_invperm', 'model.layers.53.self_attn.q_proj.q_invperm'}, {'model.layers.53.self_attn.q_proj.q_scale', 'model.layers.23.self_attn.q_proj.q_scale'}, {'model.layers.23.self_attn.q_proj.q_scale_max', 'model.layers.53.self_attn.q_proj.q_scale_max'}, {'model.layers.23.self_attn.q_proj.q_weight', 'model.layers.53.self_attn.q_proj.q_weight'}, {'model.layers.53.self_attn.v_proj.q_groups', 'model.layers.23.self_attn.v_proj.q_groups'}, {'model.layers.53.self_attn.v_proj.q_invperm', 'model.layers.23.self_attn.v_proj.q_invperm'}, {'model.layers.23.self_attn.v_proj.q_scale', 'model.layers.53.self_attn.v_proj.q_scale'}, {'model.layers.23.self_attn.v_proj.q_scale_max', 'model.layers.53.self_attn.v_proj.q_scale_max'}, {'model.layers.23.self_attn.v_proj.q_weight', 'model.layers.53.self_attn.v_proj.q_weight'}, {'model.layers.24.input_layernorm.weight', 'model.layers.54.input_layernorm.weight'}, {'model.layers.24.mlp.down_proj.q_groups', 'model.layers.54.mlp.down_proj.q_groups'}, {'model.layers.24.mlp.down_proj.q_invperm', 'model.layers.54.mlp.down_proj.q_invperm'}, {'model.layers.24.mlp.down_proj.q_scale', 'model.layers.54.mlp.down_proj.q_scale'}, {'model.layers.24.mlp.down_proj.q_scale_max', 'model.layers.54.mlp.down_proj.q_scale_max'}, {'model.layers.54.mlp.down_proj.q_weight', 'model.layers.24.mlp.down_proj.q_weight'}, {'model.layers.54.mlp.gate_proj.q_groups', 'model.layers.24.mlp.gate_proj.q_groups'}, {'model.layers.24.mlp.gate_proj.q_invperm', 'model.layers.54.mlp.gate_proj.q_invperm'}, {'model.layers.24.mlp.gate_proj.q_scale', 'model.layers.54.mlp.gate_proj.q_scale'}, {'model.layers.54.mlp.gate_proj.q_scale_max', 'model.layers.24.mlp.gate_proj.q_scale_max'}, {'model.layers.24.mlp.gate_proj.q_weight', 'model.layers.54.mlp.gate_proj.q_weight'}, {'model.layers.54.mlp.up_proj.q_groups', 'model.layers.24.mlp.up_proj.q_groups'}, {'model.layers.54.mlp.up_proj.q_invperm', 'model.layers.24.mlp.up_proj.q_invperm'}, {'model.layers.24.mlp.up_proj.q_scale', 'model.layers.54.mlp.up_proj.q_scale'}, {'model.layers.54.mlp.up_proj.q_scale_max', 'model.layers.24.mlp.up_proj.q_scale_max'}, {'model.layers.24.mlp.up_proj.q_weight', 'model.layers.54.mlp.up_proj.q_weight'}, {'model.layers.54.post_attention_layernorm.weight', 'model.layers.24.post_attention_layernorm.weight'}, {'model.layers.24.self_attn.k_proj.q_groups', 'model.layers.54.self_attn.k_proj.q_groups'}, {'model.layers.24.self_attn.k_proj.q_invperm', 'model.layers.54.self_attn.k_proj.q_invperm'}, {'model.layers.54.self_attn.k_proj.q_scale', 'model.layers.24.self_attn.k_proj.q_scale'}, {'model.layers.54.self_attn.k_proj.q_scale_max', 'model.layers.24.self_attn.k_proj.q_scale_max'}, {'model.layers.24.self_attn.k_proj.q_weight', 'model.layers.54.self_attn.k_proj.q_weight'}, {'model.layers.24.self_attn.o_proj.q_groups', 'model.layers.54.self_attn.o_proj.q_groups'}, {'model.layers.24.self_attn.o_proj.q_invperm', 'model.layers.54.self_attn.o_proj.q_invperm'}, {'model.layers.54.self_attn.o_proj.q_scale', 'model.layers.24.self_attn.o_proj.q_scale'}, {'model.layers.54.self_attn.o_proj.q_scale_max', 'model.layers.24.self_attn.o_proj.q_scale_max'}, {'model.layers.54.self_attn.o_proj.q_weight', 'model.layers.24.self_attn.o_proj.q_weight'}, {'model.layers.24.self_attn.q_proj.q_groups', 'model.layers.54.self_attn.q_proj.q_groups'}, {'model.layers.24.self_attn.q_proj.q_invperm', 'model.layers.54.self_attn.q_proj.q_invperm'}, {'model.layers.24.self_attn.q_proj.q_scale', 'model.layers.54.self_attn.q_proj.q_scale'}, {'model.layers.54.self_attn.q_proj.q_scale_max', 'model.layers.24.self_attn.q_proj.q_scale_max'}, {'model.layers.54.self_attn.q_proj.q_weight', 'model.layers.24.self_attn.q_proj.q_weight'}, {'model.layers.24.self_attn.v_proj.q_groups', 'model.layers.54.self_attn.v_proj.q_groups'}, {'model.layers.24.self_attn.v_proj.q_invperm', 'model.layers.54.self_attn.v_proj.q_invperm'}, {'model.layers.54.self_attn.v_proj.q_scale', 'model.layers.24.self_attn.v_proj.q_scale'}, {'model.layers.54.self_attn.v_proj.q_scale_max', 'model.layers.24.self_attn.v_proj.q_scale_max'}, {'model.layers.54.self_attn.v_proj.q_weight', 'model.layers.24.self_attn.v_proj.q_weight'}, {'model.layers.55.input_layernorm.weight', 'model.layers.25.input_layernorm.weight'}, {'model.layers.25.mlp.down_proj.q_groups', 'model.layers.55.mlp.down_proj.q_groups'}, {'model.layers.55.mlp.down_proj.q_invperm', 'model.layers.25.mlp.down_proj.q_invperm'}, {'model.layers.55.mlp.down_proj.q_scale', 'model.layers.25.mlp.down_proj.q_scale'}, {'model.layers.25.mlp.down_proj.q_scale_max', 'model.layers.55.mlp.down_proj.q_scale_max'}, {'model.layers.25.mlp.down_proj.q_weight', 'model.layers.55.mlp.down_proj.q_weight'}, {'model.layers.25.mlp.gate_proj.q_groups', 'model.layers.55.mlp.gate_proj.q_groups'}, {'model.layers.55.mlp.gate_proj.q_invperm', 'model.layers.25.mlp.gate_proj.q_invperm'}, {'model.layers.25.mlp.gate_proj.q_scale', 'model.layers.55.mlp.gate_proj.q_scale'}, {'model.layers.25.mlp.gate_proj.q_scale_max', 'model.layers.55.mlp.gate_proj.q_scale_max'}, {'model.layers.25.mlp.gate_proj.q_weight', 'model.layers.55.mlp.gate_proj.q_weight'}, {'model.layers.25.mlp.up_proj.q_groups', 'model.layers.55.mlp.up_proj.q_groups'}, {'model.layers.55.mlp.up_proj.q_invperm', 'model.layers.25.mlp.up_proj.q_invperm'}, {'model.layers.25.mlp.up_proj.q_scale', 'model.layers.55.mlp.up_proj.q_scale'}, {'model.layers.55.mlp.up_proj.q_scale_max', 'model.layers.25.mlp.up_proj.q_scale_max'}, {'model.layers.25.mlp.up_proj.q_weight', 'model.layers.55.mlp.up_proj.q_weight'}, {'model.layers.25.post_attention_layernorm.weight', 'model.layers.55.post_attention_layernorm.weight'}, {'model.layers.55.self_attn.k_proj.q_groups', 'model.layers.25.self_attn.k_proj.q_groups'}, {'model.layers.55.self_attn.k_proj.q_invperm', 'model.layers.25.self_attn.k_proj.q_invperm'}, {'model.layers.55.self_attn.k_proj.q_scale', 'model.layers.25.self_attn.k_proj.q_scale'}, {'model.layers.55.self_attn.k_proj.q_scale_max', 'model.layers.25.self_attn.k_proj.q_scale_max'}, {'model.layers.25.self_attn.k_proj.q_weight', 'model.layers.55.self_attn.k_proj.q_weight'}, {'model.layers.55.self_attn.o_proj.q_groups', 'model.layers.25.self_attn.o_proj.q_groups'}, {'model.layers.55.self_attn.o_proj.q_invperm', 'model.layers.25.self_attn.o_proj.q_invperm'}, {'model.layers.25.self_attn.o_proj.q_scale', 'model.layers.55.self_attn.o_proj.q_scale'}, {'model.layers.55.self_attn.o_proj.q_scale_max', 'model.layers.25.self_attn.o_proj.q_scale_max'}, {'model.layers.55.self_attn.o_proj.q_weight', 'model.layers.25.self_attn.o_proj.q_weight'}, {'model.layers.55.self_attn.q_proj.q_groups', 'model.layers.25.self_attn.q_proj.q_groups'}, {'model.layers.25.self_attn.q_proj.q_invperm', 'model.layers.55.self_attn.q_proj.q_invperm'}, {'model.layers.55.self_attn.q_proj.q_scale', 'model.layers.25.self_attn.q_proj.q_scale'}, {'model.layers.55.self_attn.q_proj.q_scale_max', 'model.layers.25.self_attn.q_proj.q_scale_max'}, {'model.layers.55.self_attn.q_proj.q_weight', 'model.layers.25.self_attn.q_proj.q_weight'}, {'model.layers.55.self_attn.v_proj.q_groups', 'model.layers.25.self_attn.v_proj.q_groups'}, {'model.layers.25.self_attn.v_proj.q_invperm', 'model.layers.55.self_attn.v_proj.q_invperm'}, {'model.layers.25.self_attn.v_proj.q_scale', 'model.layers.55.self_attn.v_proj.q_scale'}, {'model.layers.55.self_attn.v_proj.q_scale_max', 'model.layers.25.self_attn.v_proj.q_scale_max'}, {'model.layers.55.self_attn.v_proj.q_weight', 'model.layers.25.self_attn.v_proj.q_weight'}, {'model.layers.56.input_layernorm.weight', 'model.layers.26.input_layernorm.weight'}, {'model.layers.26.mlp.down_proj.q_groups', 'model.layers.56.mlp.down_proj.q_groups'}, {'model.layers.26.mlp.down_proj.q_invperm', 'model.layers.56.mlp.down_proj.q_invperm'}, {'model.layers.56.mlp.down_proj.q_scale', 'model.layers.26.mlp.down_proj.q_scale'}, {'model.layers.56.mlp.down_proj.q_scale_max', 'model.layers.26.mlp.down_proj.q_scale_max'}, {'model.layers.56.mlp.down_proj.q_weight', 'model.layers.26.mlp.down_proj.q_weight'}, {'model.layers.26.mlp.gate_proj.q_groups', 'model.layers.56.mlp.gate_proj.q_groups'}, {'model.layers.26.mlp.gate_proj.q_invperm', 'model.layers.56.mlp.gate_proj.q_invperm'}, {'model.layers.56.mlp.gate_proj.q_scale', 'model.layers.26.mlp.gate_proj.q_scale'}, {'model.layers.26.mlp.gate_proj.q_scale_max', 'model.layers.56.mlp.gate_proj.q_scale_max'}, {'model.layers.26.mlp.gate_proj.q_weight', 'model.layers.56.mlp.gate_proj.q_weight'}, {'model.layers.56.mlp.up_proj.q_groups', 'model.layers.26.mlp.up_proj.q_groups'}, {'model.layers.56.mlp.up_proj.q_invperm', 'model.layers.26.mlp.up_proj.q_invperm'}, {'model.layers.26.mlp.up_proj.q_scale', 'model.layers.56.mlp.up_proj.q_scale'}, {'model.layers.56.mlp.up_proj.q_scale_max', 'model.layers.26.mlp.up_proj.q_scale_max'}, {'model.layers.26.mlp.up_proj.q_weight', 'model.layers.56.mlp.up_proj.q_weight'}, {'model.layers.26.post_attention_layernorm.weight', 'model.layers.56.post_attention_layernorm.weight'}, {'model.layers.26.self_attn.k_proj.q_groups', 'model.layers.56.self_attn.k_proj.q_groups'}, {'model.layers.26.self_attn.k_proj.q_invperm', 'model.layers.56.self_attn.k_proj.q_invperm'}, {'model.layers.56.self_attn.k_proj.q_scale', 'model.layers.26.self_attn.k_proj.q_scale'}, {'model.layers.26.self_attn.k_proj.q_scale_max', 'model.layers.56.self_attn.k_proj.q_scale_max'}, {'model.layers.56.self_attn.k_proj.q_weight', 'model.layers.26.self_attn.k_proj.q_weight'}, {'model.layers.56.self_attn.o_proj.q_groups', 'model.layers.26.self_attn.o_proj.q_groups'}, {'model.layers.56.self_attn.o_proj.q_invperm', 'model.layers.26.self_attn.o_proj.q_invperm'}, {'model.layers.56.self_attn.o_proj.q_scale', 'model.layers.26.self_attn.o_proj.q_scale'}, {'model.layers.26.self_attn.o_proj.q_scale_max', 'model.layers.56.self_attn.o_proj.q_scale_max'}, {'model.layers.56.self_attn.o_proj.q_weight', 'model.layers.26.self_attn.o_proj.q_weight'}, {'model.layers.56.self_attn.q_proj.q_groups', 'model.layers.26.self_attn.q_proj.q_groups'}, {'model.layers.26.self_attn.q_proj.q_invperm', 'model.layers.56.self_attn.q_proj.q_invperm'}, {'model.layers.26.self_attn.q_proj.q_scale', 'model.layers.56.self_attn.q_proj.q_scale'}, {'model.layers.26.self_attn.q_proj.q_scale_max', 'model.layers.56.self_attn.q_proj.q_scale_max'}, {'model.layers.56.self_attn.q_proj.q_weight', 'model.layers.26.self_attn.q_proj.q_weight'}, {'model.layers.26.self_attn.v_proj.q_groups', 'model.layers.56.self_attn.v_proj.q_groups'}, {'model.layers.56.self_attn.v_proj.q_invperm', 'model.layers.26.self_attn.v_proj.q_invperm'}, {'model.layers.26.self_attn.v_proj.q_scale', 'model.layers.56.self_attn.v_proj.q_scale'}, {'model.layers.56.self_attn.v_proj.q_scale_max', 'model.layers.26.self_attn.v_proj.q_scale_max'}, {'model.layers.56.self_attn.v_proj.q_weight', 'model.layers.26.self_attn.v_proj.q_weight'}, {'model.layers.57.input_layernorm.weight', 'model.layers.27.input_layernorm.weight'}, {'model.layers.27.mlp.down_proj.q_groups', 'model.layers.57.mlp.down_proj.q_groups'}, {'model.layers.57.mlp.down_proj.q_invperm', 'model.layers.27.mlp.down_proj.q_invperm'}, {'model.layers.27.mlp.down_proj.q_scale', 'model.layers.57.mlp.down_proj.q_scale'}, {'model.layers.27.mlp.down_proj.q_scale_max', 'model.layers.57.mlp.down_proj.q_scale_max'}, {'model.layers.57.mlp.down_proj.q_weight', 'model.layers.27.mlp.down_proj.q_weight'}, {'model.layers.27.mlp.gate_proj.q_groups', 'model.layers.57.mlp.gate_proj.q_groups'}, {'model.layers.27.mlp.gate_proj.q_invperm', 'model.layers.57.mlp.gate_proj.q_invperm'}, {'model.layers.27.mlp.gate_proj.q_scale', 'model.layers.57.mlp.gate_proj.q_scale'}, {'model.layers.57.mlp.gate_proj.q_scale_max', 'model.layers.27.mlp.gate_proj.q_scale_max'}, {'model.layers.57.mlp.gate_proj.q_weight', 'model.layers.27.mlp.gate_proj.q_weight'}, {'model.layers.27.mlp.up_proj.q_groups', 'model.layers.57.mlp.up_proj.q_groups'}, {'model.layers.57.mlp.up_proj.q_invperm', 'model.layers.27.mlp.up_proj.q_invperm'}, {'model.layers.57.mlp.up_proj.q_scale', 'model.layers.27.mlp.up_proj.q_scale'}, {'model.layers.27.mlp.up_proj.q_scale_max', 'model.layers.57.mlp.up_proj.q_scale_max'}, {'model.layers.57.mlp.up_proj.q_weight', 'model.layers.27.mlp.up_proj.q_weight'}, {'model.layers.27.post_attention_layernorm.weight', 'model.layers.57.post_attention_layernorm.weight'}, {'model.layers.27.self_attn.k_proj.q_groups', 'model.layers.57.self_attn.k_proj.q_groups'}, {'model.layers.57.self_attn.k_proj.q_invperm', 'model.layers.27.self_attn.k_proj.q_invperm'}, {'model.layers.57.self_attn.k_proj.q_scale', 'model.layers.27.self_attn.k_proj.q_scale'}, {'model.layers.27.self_attn.k_proj.q_scale_max', 'model.layers.57.self_attn.k_proj.q_scale_max'}, {'model.layers.57.self_attn.k_proj.q_weight', 'model.layers.27.self_attn.k_proj.q_weight'}, {'model.layers.27.self_attn.o_proj.q_groups', 'model.layers.57.self_attn.o_proj.q_groups'}, {'model.layers.27.self_attn.o_proj.q_invperm', 'model.layers.57.self_attn.o_proj.q_invperm'}, {'model.layers.57.self_attn.o_proj.q_scale', 'model.layers.27.self_attn.o_proj.q_scale'}, {'model.layers.27.self_attn.o_proj.q_scale_max', 'model.layers.57.self_attn.o_proj.q_scale_max'}, {'model.layers.57.self_attn.o_proj.q_weight', 'model.layers.27.self_attn.o_proj.q_weight'}, {'model.layers.27.self_attn.q_proj.q_groups', 'model.layers.57.self_attn.q_proj.q_groups'}, {'model.layers.27.self_attn.q_proj.q_invperm', 'model.layers.57.self_attn.q_proj.q_invperm'}, {'model.layers.57.self_attn.q_proj.q_scale', 'model.layers.27.self_attn.q_proj.q_scale'}, {'model.layers.27.self_attn.q_proj.q_scale_max', 'model.layers.57.self_attn.q_proj.q_scale_max'}, {'model.layers.27.self_attn.q_proj.q_weight', 'model.layers.57.self_attn.q_proj.q_weight'}, {'model.layers.27.self_attn.v_proj.q_groups', 'model.layers.57.self_attn.v_proj.q_groups'}, {'model.layers.27.self_attn.v_proj.q_invperm', 'model.layers.57.self_attn.v_proj.q_invperm'}, {'model.layers.57.self_attn.v_proj.q_scale', 'model.layers.27.self_attn.v_proj.q_scale'}, {'model.layers.27.self_attn.v_proj.q_scale_max', 'model.layers.57.self_attn.v_proj.q_scale_max'}, {'model.layers.57.self_attn.v_proj.q_weight', 'model.layers.27.self_attn.v_proj.q_weight'}, {'model.layers.28.input_layernorm.weight', 'model.layers.58.input_layernorm.weight'}, {'model.layers.58.mlp.down_proj.q_groups', 'model.layers.28.mlp.down_proj.q_groups'}, {'model.layers.58.mlp.down_proj.q_invperm', 'model.layers.28.mlp.down_proj.q_invperm'}, {'model.layers.58.mlp.down_proj.q_scale', 'model.layers.28.mlp.down_proj.q_scale'}, {'model.layers.28.mlp.down_proj.q_scale_max', 'model.layers.58.mlp.down_proj.q_scale_max'}, {'model.layers.58.mlp.down_proj.q_weight', 'model.layers.28.mlp.down_proj.q_weight'}, {'model.layers.58.mlp.gate_proj.q_groups', 'model.layers.28.mlp.gate_proj.q_groups'}, {'model.layers.58.mlp.gate_proj.q_invperm', 'model.layers.28.mlp.gate_proj.q_invperm'}, {'model.layers.58.mlp.gate_proj.q_scale', 'model.layers.28.mlp.gate_proj.q_scale'}, {'model.layers.58.mlp.gate_proj.q_scale_max', 'model.layers.28.mlp.gate_proj.q_scale_max'}, {'model.layers.28.mlp.gate_proj.q_weight', 'model.layers.58.mlp.gate_proj.q_weight'}, {'model.layers.28.mlp.up_proj.q_groups', 'model.layers.58.mlp.up_proj.q_groups'}, {'model.layers.28.mlp.up_proj.q_invperm', 'model.layers.58.mlp.up_proj.q_invperm'}, {'model.layers.28.mlp.up_proj.q_scale', 'model.layers.58.mlp.up_proj.q_scale'}, {'model.layers.28.mlp.up_proj.q_scale_max', 'model.layers.58.mlp.up_proj.q_scale_max'}, {'model.layers.28.mlp.up_proj.q_weight', 'model.layers.58.mlp.up_proj.q_weight'}, {'model.layers.58.post_attention_layernorm.weight', 'model.layers.28.post_attention_layernorm.weight'}, {'model.layers.28.self_attn.k_proj.q_groups', 'model.layers.58.self_attn.k_proj.q_groups'}, {'model.layers.58.self_attn.k_proj.q_invperm', 'model.layers.28.self_attn.k_proj.q_invperm'}, {'model.layers.28.self_attn.k_proj.q_scale', 'model.layers.58.self_attn.k_proj.q_scale'}, {'model.layers.28.self_attn.k_proj.q_scale_max', 'model.layers.58.self_attn.k_proj.q_scale_max'}, {'model.layers.28.self_attn.k_proj.q_weight', 'model.layers.58.self_attn.k_proj.q_weight'}, {'model.layers.58.self_attn.o_proj.q_groups', 'model.layers.28.self_attn.o_proj.q_groups'}, {'model.layers.28.self_attn.o_proj.q_invperm', 'model.layers.58.self_attn.o_proj.q_invperm'}, {'model.layers.58.self_attn.o_proj.q_scale', 'model.layers.28.self_attn.o_proj.q_scale'}, {'model.layers.28.self_attn.o_proj.q_scale_max', 'model.layers.58.self_attn.o_proj.q_scale_max'}, {'model.layers.58.self_attn.o_proj.q_weight', 'model.layers.28.self_attn.o_proj.q_weight'}, {'model.layers.28.self_attn.q_proj.q_groups', 'model.layers.58.self_attn.q_proj.q_groups'}, {'model.layers.28.self_attn.q_proj.q_invperm', 'model.layers.58.self_attn.q_proj.q_invperm'}, {'model.layers.28.self_attn.q_proj.q_scale', 'model.layers.58.self_attn.q_proj.q_scale'}, {'model.layers.58.self_attn.q_proj.q_scale_max', 'model.layers.28.self_attn.q_proj.q_scale_max'}, {'model.layers.58.self_attn.q_proj.q_weight', 'model.layers.28.self_attn.q_proj.q_weight'}, {'model.layers.28.self_attn.v_proj.q_groups', 'model.layers.58.self_attn.v_proj.q_groups'}, {'model.layers.28.self_attn.v_proj.q_invperm', 'model.layers.58.self_attn.v_proj.q_invperm'}, {'model.layers.28.self_attn.v_proj.q_scale', 'model.layers.58.self_attn.v_proj.q_scale'}, {'model.layers.28.self_attn.v_proj.q_scale_max', 'model.layers.58.self_attn.v_proj.q_scale_max'}, {'model.layers.58.self_attn.v_proj.q_weight', 'model.layers.28.self_attn.v_proj.q_weight'}, {'model.layers.59.input_layernorm.weight', 'model.layers.29.input_layernorm.weight'}, {'model.layers.29.mlp.down_proj.q_groups', 'model.layers.59.mlp.down_proj.q_groups'}, {'model.layers.59.mlp.down_proj.q_invperm', 'model.layers.29.mlp.down_proj.q_invperm'}, {'model.layers.29.mlp.down_proj.q_scale', 'model.layers.59.mlp.down_proj.q_scale'}, {'model.layers.59.mlp.down_proj.q_scale_max', 'model.layers.29.mlp.down_proj.q_scale_max'}, {'model.layers.29.mlp.down_proj.q_weight', 'model.layers.59.mlp.down_proj.q_weight'}, {'model.layers.29.mlp.gate_proj.q_groups', 'model.layers.59.mlp.gate_proj.q_groups'}, {'model.layers.59.mlp.gate_proj.q_invperm', 'model.layers.29.mlp.gate_proj.q_invperm'}, {'model.layers.59.mlp.gate_proj.q_scale', 'model.layers.29.mlp.gate_proj.q_scale'}, {'model.layers.59.mlp.gate_proj.q_scale_max', 'model.layers.29.mlp.gate_proj.q_scale_max'}, {'model.layers.59.mlp.gate_proj.q_weight', 'model.layers.29.mlp.gate_proj.q_weight'}, {'model.layers.59.mlp.up_proj.q_groups', 'model.layers.29.mlp.up_proj.q_groups'}, {'model.layers.59.mlp.up_proj.q_invperm', 'model.layers.29.mlp.up_proj.q_invperm'}, {'model.layers.29.mlp.up_proj.q_scale', 'model.layers.59.mlp.up_proj.q_scale'}, {'model.layers.59.mlp.up_proj.q_scale_max', 'model.layers.29.mlp.up_proj.q_scale_max'}, {'model.layers.29.mlp.up_proj.q_weight', 'model.layers.59.mlp.up_proj.q_weight'}, {'model.layers.59.post_attention_layernorm.weight', 'model.layers.29.post_attention_layernorm.weight'}, {'model.layers.29.self_attn.k_proj.q_groups', 'model.layers.59.self_attn.k_proj.q_groups'}, {'model.layers.29.self_attn.k_proj.q_invperm', 'model.layers.59.self_attn.k_proj.q_invperm'}, {'model.layers.29.self_attn.k_proj.q_scale', 'model.layers.59.self_attn.k_proj.q_scale'}, {'model.layers.29.self_attn.k_proj.q_scale_max', 'model.layers.59.self_attn.k_proj.q_scale_max'}, {'model.layers.29.self_attn.k_proj.q_weight', 'model.layers.59.self_attn.k_proj.q_weight'}, {'model.layers.59.self_attn.o_proj.q_groups', 'model.layers.29.self_attn.o_proj.q_groups'}, {'model.layers.29.self_attn.o_proj.q_invperm', 'model.layers.59.self_attn.o_proj.q_invperm'}, {'model.layers.59.self_attn.o_proj.q_scale', 'model.layers.29.self_attn.o_proj.q_scale'}, {'model.layers.59.self_attn.o_proj.q_scale_max', 'model.layers.29.self_attn.o_proj.q_scale_max'}, {'model.layers.59.self_attn.o_proj.q_weight', 'model.layers.29.self_attn.o_proj.q_weight'}, {'model.layers.29.self_attn.q_proj.q_groups', 'model.layers.59.self_attn.q_proj.q_groups'}, {'model.layers.29.self_attn.q_proj.q_invperm', 'model.layers.59.self_attn.q_proj.q_invperm'}, {'model.layers.29.self_attn.q_proj.q_scale', 'model.layers.59.self_attn.q_proj.q_scale'}, {'model.layers.29.self_attn.q_proj.q_scale_max', 'model.layers.59.self_attn.q_proj.q_scale_max'}, {'model.layers.59.self_attn.q_proj.q_weight', 'model.layers.29.self_attn.q_proj.q_weight'}, {'model.layers.29.self_attn.v_proj.q_groups', 'model.layers.59.self_attn.v_proj.q_groups'}, {'model.layers.59.self_attn.v_proj.q_invperm', 'model.layers.29.self_attn.v_proj.q_invperm'}, {'model.layers.29.self_attn.v_proj.q_scale', 'model.layers.59.self_attn.v_proj.q_scale'}, {'model.layers.29.self_attn.v_proj.q_scale_max', 'model.layers.59.self_attn.v_proj.q_scale_max'}, {'model.layers.59.self_attn.v_proj.q_weight', 'model.layers.29.self_attn.v_proj.q_weight'}].\n            A potential way to correctly save your model is to use `save_model`.\n            More information at https://huggingface.co/docs/safetensors/torch_shared_tensors\n            "
     ]
    }
   ],
   "source": [
    "save_file(tensors, \"output.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/dnhkng/miniforge3/envs/exllama/lib/python3.10/site-packages/exllamav2_ext.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda9SetDeviceEi",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexllamav2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexllamav2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/exllama/lib/python3.10/site-packages/exllamav2/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexllamav2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexllamav2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExLlamaV2\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexllamav2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExLlamaV2CacheBase\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexllamav2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExLlamaV2Cache\n",
      "File \u001b[0;32m~/miniforge3/envs/exllama/lib/python3.10/site-packages/exllamav2/model.py:16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexllamav2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExLlamaV2Config\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexllamav2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExLlamaV2CacheBase\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexllamav2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExLlamaV2Linear\n",
      "File \u001b[0;32m~/miniforge3/envs/exllama/lib/python3.10/site-packages/exllamav2/config.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexllamav2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfasttensors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m STFile\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mglob\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mExLlamaV2Config\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/exllama/lib/python3.10/site-packages/exllamav2/fasttensors.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexllamav2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exllamav2_ext \u001b[38;5;28;01mas\u001b[39;00m ext_c\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_dtype\u001b[39m(dt: \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/miniforge3/envs/exllama/lib/python3.10/site-packages/exllamav2/ext.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m build_jit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mexllamav2_ext\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     build_jit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: /home/dnhkng/miniforge3/envs/exllama/lib/python3.10/site-packages/exllamav2_ext.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda9SetDeviceEi"
     ]
    }
   ],
   "source": [
    "from exllamav2 import *\n",
    "from exllamav2.generator import *\n",
    "import sys, torch\n",
    "from copy import copy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 5\n",
    "stop = 30\n",
    "num_layers = 80\n",
    "\n",
    "layers = list(range(stop)) + list(range(start,stop)) + list(range(stop,num_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (1, 1),\n",
       " (2, 2),\n",
       " (3, 3),\n",
       " (4, 4),\n",
       " (5, 5),\n",
       " (6, 6),\n",
       " (7, 7),\n",
       " (8, 8),\n",
       " (9, 9),\n",
       " (10, 10),\n",
       " (11, 11),\n",
       " (12, 12),\n",
       " (13, 13),\n",
       " (14, 14),\n",
       " (15, 15),\n",
       " (16, 16),\n",
       " (17, 17),\n",
       " (18, 18),\n",
       " (19, 19),\n",
       " (20, 20),\n",
       " (21, 21),\n",
       " (22, 22),\n",
       " (23, 23),\n",
       " (24, 24),\n",
       " (25, 25),\n",
       " (26, 26),\n",
       " (27, 27),\n",
       " (28, 28),\n",
       " (29, 29),\n",
       " (30, 5),\n",
       " (31, 6),\n",
       " (32, 7),\n",
       " (33, 8),\n",
       " (34, 9),\n",
       " (35, 10),\n",
       " (36, 11),\n",
       " (37, 12),\n",
       " (38, 13),\n",
       " (39, 14),\n",
       " (40, 15),\n",
       " (41, 16),\n",
       " (42, 17),\n",
       " (43, 18),\n",
       " (44, 19),\n",
       " (45, 20),\n",
       " (46, 21),\n",
       " (47, 22),\n",
       " (48, 23),\n",
       " (49, 24),\n",
       " (50, 25),\n",
       " (51, 26),\n",
       " (52, 27),\n",
       " (53, 28),\n",
       " (54, 29),\n",
       " (55, 30),\n",
       " (56, 31),\n",
       " (57, 32),\n",
       " (58, 33),\n",
       " (59, 34),\n",
       " (60, 35),\n",
       " (61, 36),\n",
       " (62, 37),\n",
       " (63, 38),\n",
       " (64, 39),\n",
       " (65, 40),\n",
       " (66, 41),\n",
       " (67, 42),\n",
       " (68, 43),\n",
       " (69, 44),\n",
       " (70, 45),\n",
       " (71, 46),\n",
       " (72, 47),\n",
       " (73, 48),\n",
       " (74, 49),\n",
       " (75, 50),\n",
       " (76, 51),\n",
       " (77, 52),\n",
       " (78, 53),\n",
       " (79, 54),\n",
       " (80, 55),\n",
       " (81, 56),\n",
       " (82, 57),\n",
       " (83, 58),\n",
       " (84, 59),\n",
       " (85, 60),\n",
       " (86, 61),\n",
       " (87, 62),\n",
       " (88, 63),\n",
       " (89, 64),\n",
       " (90, 65),\n",
       " (91, 66),\n",
       " (92, 67),\n",
       " (93, 68),\n",
       " (94, 69),\n",
       " (95, 70),\n",
       " (96, 71),\n",
       " (97, 72),\n",
       " (98, 73),\n",
       " (99, 74),\n",
       " (100, 75),\n",
       " (101, 76),\n",
       " (102, 77),\n",
       " (103, 78),\n",
       " (104, 79)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exllama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
