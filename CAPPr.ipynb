{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dnhkng/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "from cappr.huggingface.classify import predict, predict_proba\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.57s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/dnhkng/Documents/models/Llama-2-7B-Chat-GPTQ\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "\n",
    "config.max_seq_len = 4096\n",
    "config.max_answer_len= 128\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map = 'cuda:0', config=config )\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cuda:1! (when checking argument for argument tensors in method wrapper_CUDA_cat)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhich planet is closer to the Sun: Mercury or Earth?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m completions \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMercury\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEarth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_and_tokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Mercury\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/utils/classify.py:529\u001b[0m, in \u001b[0;36m_predict.<locals>.wrapper\u001b[0;34m(prompts, completions, *args, **kwargs)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(completions) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompletions only has one completion. predict will trivially return \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mback this completion. Perhaps you meant to call predict_proba with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalize=False instead of predict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m pred_probs: npt\u001b[38;5;241m.\u001b[39mNDArray \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_proba_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# We need completions to support 0-indexed __getitem__\u001b[39;00m\n\u001b[1;32m    533\u001b[0m completions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(completions)\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/huggingface/classify.py:1305\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(prompts, completions, model_and_tokenizer, prior, end_of_prompt, discount_completions, log_marg_probs_completions, show_progress_bar, batch_size, batch_size_completions)\u001b[0m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;129m@classify\u001b[39m\u001b[38;5;241m.\u001b[39m_predict\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m   1212\u001b[0m     prompts: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m Sequence[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     batch_size_completions: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1222\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m   1223\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;124;03m    Predict which completion is most likely to follow each prompt.\u001b[39;00m\n\u001b[1;32m   1225\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1303\u001b[0m \u001b[38;5;124;03m        #  'in the freezer']\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/utils/classify.py:420\u001b[0m, in \u001b[0;36m_predict_proba.<locals>.wrapper\u001b[0;34m(prompts, completions, *args, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_marg_probs_completions is set, but they will not be used \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbecause discount_completions was not set.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m     )\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# Do the expensive model calls\u001b[39;00m\n\u001b[0;32m--> 420\u001b[0m log_probs_completions \u001b[38;5;241m=\u001b[39m \u001b[43mlog_probs_conditional\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m is_single_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(prompts, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    426\u001b[0m \u001b[38;5;66;03m# Maybe apply discount\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/huggingface/classify.py:1122\u001b[0m, in \u001b[0;36mpredict_proba\u001b[0;34m(prompts, completions, model_and_tokenizer, prior, end_of_prompt, normalize, discount_completions, log_marg_probs_completions, show_progress_bar, batch_size, batch_size_completions)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;129m@classify\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_proba\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\n\u001b[1;32m   1008\u001b[0m     prompts: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m Sequence[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     batch_size_completions: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1019\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mfloating]:\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;124;03m    Predict probabilities of each completion coming after each prompt.\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;124;03m        # 0.4\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlog_probs_conditional\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/utils/classify.py:316\u001b[0m, in \u001b[0;36m_log_probs_conditional.<locals>.wrapper\u001b[0;34m(prompts, completions, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m _check\u001b[38;5;241m.\u001b[39mcompletions(completions)\n\u001b[1;32m    315\u001b[0m _check\u001b[38;5;241m.\u001b[39mend_of_prompt(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_of_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrap_call_unwrap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_probs_conditional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/utils/classify.py:280\u001b[0m, in \u001b[0;36m_wrap_call_unwrap\u001b[0;34m(type_indicating_singleness, func, input, *args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m is_single_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, type_indicating_singleness)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28minput\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m is_single_input \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m--> 280\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m is_single_input \u001b[38;5;28;01melse\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/huggingface/classify.py:889\u001b[0m, in \u001b[0;36mlog_probs_conditional\u001b[0;34m(prompts, completions, model_and_tokenizer, end_of_prompt, show_progress_bar, batch_size, batch_size_completions, **kwargs)\u001b[0m\n\u001b[1;32m    880\u001b[0m     logits, encodings \u001b[38;5;241m=\u001b[39m _logits_completions_given_prompts(\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;241m*\u001b[39mmodel_and_tokenizer,\n\u001b[1;32m    882\u001b[0m         prompts,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    885\u001b[0m         batch_size_completions\u001b[38;5;241m=\u001b[39mbatch_size_completions,\n\u001b[1;32m    886\u001b[0m     )\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _logits_to_log_probs_completions(logits, encodings, from_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 889\u001b[0m log_probs_completions \u001b[38;5;241m=\u001b[39m \u001b[43mlog_probs_completions_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_batch\u001b[38;5;241m.\u001b[39mconstant(log_probs_completions, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(completions)))\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/utils/_batch.py:147\u001b[0m, in \u001b[0;36mflatten.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(batchified_func)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 147\u001b[0m     nested_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mbatchified_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [output \u001b[38;5;28;01mfor\u001b[39;00m inner_outputs \u001b[38;5;129;01min\u001b[39;00m nested_outputs \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m inner_outputs]\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/utils/_batch.py:131\u001b[0m, in \u001b[0;36mbatchify.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_ \u001b[38;5;129;01min\u001b[39;00m constant(batchable, batch_size):\n\u001b[1;32m    130\u001b[0m         args[batchable_arg_idx] \u001b[38;5;241m=\u001b[39m batch_\n\u001b[0;32m--> 131\u001b[0m         outputs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    132\u001b[0m         progress_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(batch_))\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/huggingface/classify.py:880\u001b[0m, in \u001b[0;36mlog_probs_conditional.<locals>.log_probs_completions_batch\u001b[0;34m(prompts, show_progress_bar, batch_size)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;129m@_batch\u001b[39m\u001b[38;5;241m.\u001b[39mflatten\n\u001b[1;32m    876\u001b[0m \u001b[38;5;129m@_batch\u001b[39m\u001b[38;5;241m.\u001b[39mbatchify(batchable_arg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompts\u001b[39m\u001b[38;5;124m\"\u001b[39m, progress_bar_desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconditional log-probs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_probs_completions_batch\u001b[39m(\n\u001b[1;32m    878\u001b[0m     prompts, show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar, batch_size\u001b[38;5;241m=\u001b[39mbatch_size\n\u001b[1;32m    879\u001b[0m ):\n\u001b[0;32m--> 880\u001b[0m     logits, encodings \u001b[38;5;241m=\u001b[39m \u001b[43m_logits_completions_given_prompts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_and_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend_of_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_of_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size_completions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size_completions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _logits_to_log_probs_completions(logits, encodings, from_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/huggingface/classify.py:707\u001b[0m, in \u001b[0;36m_logits_completions_given_prompts\u001b[0;34m(model, tokenizer, prompts, completions, end_of_prompt, batch_size_completions)\u001b[0m\n\u001b[1;32m    705\u001b[0m     end_of_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    706\u001b[0m completions \u001b[38;5;241m=\u001b[39m [end_of_prompt \u001b[38;5;241m+\u001b[39m completion \u001b[38;5;28;01mfor\u001b[39;00m completion \u001b[38;5;129;01min\u001b[39;00m completions]\n\u001b[0;32m--> 707\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_blessed_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_completions_per_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompletions_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size_completions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size_completions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/huggingface/classify.py:661\u001b[0m, in \u001b[0;36m_blessed_helper\u001b[0;34m(model, tokenizer, prompts, completions, num_completions_per_prompt, completions_repeats, batch_size_completions)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m    660\u001b[0m     cached_prompts_model\u001b[38;5;241m.\u001b[39m_cappr\u001b[38;5;241m.\u001b[39mbatch_idxs \u001b[38;5;241m=\u001b[39m prompts_idxs[batch_idx]\n\u001b[0;32m--> 661\u001b[0m     out: CausalLMOutput \u001b[38;5;241m=\u001b[39m \u001b[43mcached_prompts_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompletions_input_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompletions_attention_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;66;03m# B/c logits_all=False, out.logits only has completion token logits\u001b[39;00m\n\u001b[1;32m    666\u001b[0m     completions_logits\u001b[38;5;241m.\u001b[39mappend(out\u001b[38;5;241m.\u001b[39mlogits)\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/huggingface/classify.py:313\u001b[0m, in \u001b[0;36m_ModelWithCache.__call__\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28mself\u001b[39m, input_ids: torch\u001b[38;5;241m.\u001b[39mTensor, attention_mask: torch\u001b[38;5;241m.\u001b[39mTensor\n\u001b[1;32m    312\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CausalLMOutputWithPast:\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/huggingface/classify.py:272\u001b[0m, in \u001b[0;36m_ModelWithCache.forward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m    263\u001b[0m     batch_idxs: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cappr\u001b[38;5;241m.\u001b[39mbatch_idxs\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mequal(\n\u001b[1;32m    266\u001b[0m     batch_idxs,\n\u001b[1;32m    267\u001b[0m     torch\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    270\u001b[0m ):\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# Must extract past by converting the tuple to a tensor and back\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m     past_key_values \u001b[38;5;241m=\u001b[39m \u001b[43m_past_key_values_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_past\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     past_key_values \u001b[38;5;241m=\u001b[39m out_past\u001b[38;5;241m.\u001b[39mpast_key_values\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/huggingface/classify.py:171\u001b[0m, in \u001b[0;36m_past_key_values_get\u001b[0;34m(past_key_values, batch_idxs)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_past_key_values_get\u001b[39m(\n\u001b[1;32m    167\u001b[0m     past_key_values: _PastKeyValues,\n\u001b[1;32m    168\u001b[0m     batch_idxs: Sequence[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    169\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _PastKeyValues:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _past_key_values_tensor_to_tuple(\n\u001b[0;32m--> 171\u001b[0m         \u001b[43m_past_key_values_tuple_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m)\u001b[49m[:, :, batch_idxs, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m    172\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/huggingface/classify.py:157\u001b[0m, in \u001b[0;36m_past_key_values_tuple_to_tensor\u001b[0;34m(past_key_values)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values is None. Can your model be configured to output it? If \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot, please use cappr.huggingface.classify_no_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m     )  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblock\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cuda:1! (when checking argument for argument tensors in method wrapper_CUDA_cat)"
     ]
    }
   ],
   "source": [
    "prompt = \"Which planet is closer to the Sun: Mercury or Earth?\"\n",
    "completions = (\"Mercury\", \"Earth\")\n",
    "\n",
    "pred = predict(prompt, completions, model_and_tokenizer=(model, tokenizer))\n",
    "print(pred)\n",
    "# Mercury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For prompt 1\n",
      "------------\n",
      "Stephen Curry is a basketball player\n",
      "Stephen Curry is a tennis player\n",
      "Stephen Curry is a scientist\n",
      "\n",
      "For prompt 2\n",
      "------------\n",
      "Martina Navratilova was a basketball player\n",
      "Martina Navratilova was a tennis player\n",
      "Martina Navratilova was a scientist\n",
      "\n",
      "For prompt 3\n",
      "------------\n",
      "Dexter, from the TV Series Dexter's Laboratory, is a basketball player\n",
      "Dexter, from the TV Series Dexter's Laboratory, is a tennis player\n",
      "Dexter, from the TV Series Dexter's Laboratory, is a scientist\n",
      "\n",
      "For prompt 4\n",
      "------------\n",
      "LeBron James is a basketball player\n",
      "LeBron James is a tennis player\n",
      "LeBron James is a scientist\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Stephen Curry is a\",\n",
    "    \"Martina Navratilova was a\",\n",
    "    \"Dexter, from the TV Series Dexter's Laboratory, is a\",\n",
    "    \"LeBron James is a\",\n",
    "]\n",
    "end_of_prompt = \" \"\n",
    "\n",
    "# Each of the prompts could possibly be completed with one of these:\n",
    "class_names = (\"basketball player\", \"tennis player\", \"scientist\")\n",
    "\n",
    "# What strings will CAPPr see?\n",
    "for i, prompt in enumerate(prompts):\n",
    "    print(f\"For prompt {i + 1}\")\n",
    "    print(\"------------\")\n",
    "    for completion in class_names:\n",
    "        print(f\"{prompt}{end_of_prompt}{completion}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every input belongs to one of these categories:\n",
      "basketball player\n",
      "tennis player\n",
      "scientist\n"
     ]
    }
   ],
   "source": [
    "class_names = (\"basketball player\", \"tennis player\", \"scientist\")\n",
    "class_names_str = '\\n'.join(class_names)\n",
    "prompt_prefix = f'''Every input belongs to one of these categories:\n",
    "{class_names_str}'''\n",
    "print(prompt_prefix)\n",
    "# Every input belongs to one of these categories:\n",
    "# basketball player\n",
    "# tennis player\n",
    "# scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99755741 0.00244259]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Which planet is closer to the Sun: Mercury or Earth?\"\n",
    "completions = (\"Mercury\", \"Earth\")\n",
    "\n",
    "pred = predict_proba(prompt, completions, model_and_tokenizer=(model, tokenizer))\n",
    "print(pred)\n",
    "# Mercury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# the ratings are on a scale of 0-10, with 0 being the worst and 10 being the best\n",
    "craftsmanshipDict = {\n",
    "    \"Incoherent\": \"Completely lacks structure, clarity, and basic understanding of writing principles.\",\n",
    "    \"Amateurish\": \"Lacks basic structure and polish.\",\n",
    "    \"Inexperienced\": \"Shows some understanding but is fundamentally flawed.\",\n",
    "    \"Developing\": \"Basic skills present but lacking refinement.\",\n",
    "    \"Competent\": \"Adequate execution with some errors.\",\n",
    "    \"Skilled\": \"Good quality with minor lapses.\",\n",
    "    \"Proficient\": \"Strong, consistent quality with few errors.\",\n",
    "    \"Artistic\": \"Shows flair and style beyond mere technical proficiency.\",\n",
    "    \"Masterful\": \"Exceptional skill and precision.\",\n",
    "    \"Brilliant\": \"Outstanding craftsmanship, innovative and flawless.\",\n",
    "    \"Transcendent\": \"Sets a new standard, impeccable in every aspect.\",\n",
    "}\n",
    "\n",
    "creativityDict = {\n",
    "    \"Clone\": \"Offers no original thought or perspective; a mere copy of existing works.\",\n",
    "    \"Unimaginative\": \"Completely derivative and lacking originality.\",\n",
    "    \"Basic\": \"Few original ideas, mostly predictable.\",\n",
    "    \"Simple\": \"Shows some originality but largely conventional.\",\n",
    "    \"Interesting\": \"Regular flashes of creativity.\",\n",
    "    \"Inventive\": \"Consistently creative and engaging.\",\n",
    "    \"Inspired\": \"Rich in original ideas and perspectives.\",\n",
    "    \"Innovative\": \"Breaks new ground, very original.\",\n",
    "    \"Visionary\": \"Exceptionally creative and forward-thinking.\",\n",
    "    \"Revolutionary\": \"Radically original, transforming norms.\",\n",
    "    \"Genius\": \"Redefines the concept of creativity.\",\n",
    "}\n",
    "\n",
    "consistencyDict = {\n",
    "    \"Disconnected\": \"Shows no understanding or recognition of the theme; entirely unrelated.\",\n",
    "    \"Irrelevant\": \"Fails to address the theme.\",\n",
    "    \"Off-Topic\": \"Barely touches on the theme.\",\n",
    "    \"Wandering\": \"Occasionally relevant but often strays.\",\n",
    "    \"Variable\": \"Inconsistent adherence to the theme.\",\n",
    "    \"Steady\": \"Generally sticks to the theme with some lapses.\",\n",
    "    \"Focused\": \"Consistently on-theme with minor deviations.\",\n",
    "    \"Harmonious\": \"Well-integrated with the theme, showing depth.\",\n",
    "    \"Unified\": \"Seamlessly blends all elements with the theme.\",\n",
    "    \"Exemplary\": \"Outstanding representation of the theme.\",\n",
    "    \"Definitive\": \"The ultimate expression of the theme.\",\n",
    "}\n",
    "\n",
    "# Format the dictionaries into a string for the prompt\n",
    "formattedCraftsmanshipDict = \"\\n\".join(\n",
    "    [f\"{key}: {value}\" for key, value in craftsmanshipDict.items()]\n",
    ")\n",
    "formattedCreativityDict = \"\\n\".join(\n",
    "    [f\"{key}: {value}\" for key, value in creativityDict.items()]\n",
    ")\n",
    "formattedConsistencyDict = \"\\n\".join(\n",
    "    [f\"{key}: {value}\" for key, value in consistencyDict.items()]\n",
    ")\n",
    "\n",
    "# Examples for calibrating the rating system\n",
    "themeExample = \"Imagine what alien communication might be like and create a hypothetical scenario for initial contact.\"\n",
    "entryExample = \"\"\"Title: \"Whispers from the Cosmos: A Symphony of Stars\"\n",
    "In the vast expanse of the cosmos, where stars are born and die in a celestial ballet, a new player entered the stage. A planet, hitherto unknown to us, orbited a star in the constellation of Cygnus. This planet, christened as Kepler-438b, was a veritable gem, with conditions conducive to life.\n",
    "One fateful day, as the sun set on the eastern horizon of our planet, an anomaly occurred. The radio telescopes at SETI (Search for Extraterrestrial Intelligence) Institute picked up a signal. It was unlike anything they had ever encountered before. The signal, pulsating at regular intervals, was not random but seemed to carry a pattern.\n",
    "The scientists were baffled. They worked tirelessly, decoding the signal, trying to make sense of it. Days turned into weeks, and weeks into months. The signal was not a noise; it was a message.\n",
    "The message was a series of complex mathematical equations, interwoven with intricate melodies. It was a language, unlike any human language. The team at SETI, led by Dr. Amelia Hartman, worked tirelessly to decode the message. They discovered that the message contained instructions to build a device, which they named the \"Cosmic Harmonizer.\"\n",
    "The Cosmic Harmonizer was a device that could transmit and receive signals across interstellar distances. It was a marvel of engineering, a testament to the advanced technology of the extraterrestrial beings.\n",
    "Dr. Hartman and her team built the Cosmic Harmonizer, and they sent a response. They transmitted a message, a greeting to the aliens, containing information about Earth and its inhabitants. They also included a recording of Beethoven's \"Moonlight Sonata,\" a piece of music that transcended language and culture.\n",
    "The response was met with silence. But then, a few days later, they received another message. It was a reply, a musical composition, a melody that resonated with the frequencies of the \"Moonlight Sonata.\" It was a beautiful symphony, a conversation starter between two civilizations separated by light-years.\n",
    "The initial contact had been made. The aliens had communicated, not through words, but through music and mathematics. It was a beautiful, harmonious exchange, a testament to the power of communication and the universality of art.\n",
    "From that day forward, humanity and the extraterrestrial beings began a dialogue, a conversation that spanned the cosmos. They shared knowledge, ideas, and cultures. They learned from each other, growing together as one interconnected civilization. And so, the universe sang a new song, a symphony of stars, a testament to the power of communication and the boundless possibilities of the cosmos.\"\"\"\n",
    "ratingExample = \"craftsmanship: Skilled, creativity: Interesting, consistency: Focused\"\n",
    "\n",
    "systemPrompt = f\"\"\"You are an expert teacher and editor with profound experience in rating prose.\n",
    "For the competition, participants were given a theme to write about. This is a competition for the world's best writer!  You will receive an text fragment, and must grade the text based on these three criteria:\n",
    "- Craftsmanship: focuses on the writer's skill in structuring sentences, paragraphs, and stylistic precision.\n",
    "- Creativity: encompasses the writer's flair for innovation, the use of vivid and original imagery, and the ability to engage readers with fresh perspectives and unexpected narrative turns.\n",
    "- Consistency: indicates the writer's skill in maintaining relevance to the theme, ensuring that all parts of the writing contribute to and resonate with the central idea, without deviating or diluting the thematic focus.\n",
    "\n",
    "Rate the each story on the three criteria above, using these guidelines:\n",
    "\n",
    "***** Craftsmanship *****\n",
    "{formattedCraftsmanshipDict}\n",
    "\n",
    "***** Creativity *****\n",
    "{formattedCreativityDict}\n",
    "\n",
    "***** Consistency *****\n",
    "{formattedConsistencyDict}\n",
    "\n",
    "Be very hard in your assesment! A skilled writer can hope to obtain 5's for a given criteria.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "userExamplePrompt = f\"\"\"***** Given Theme *****\n",
    "{themeExample}\n",
    "\n",
    "***** Competition Entry *****\n",
    "{entryExample}\n",
    "\n",
    "***** Rating *****\n",
    "{ratingExample}\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert teacher and editor with profound experience in rating prose.\n",
      "For the competition, participants were given a theme to write about. This is a competition for the world's best writer!  You will receive an text fragment, and must grade the text based on these three criteria:\n",
      "- Craftsmanship: focuses on the writer's skill in structuring sentences, paragraphs, and stylistic precision.\n",
      "- Creativity: encompasses the writer's flair for innovation, the use of vivid and original imagery, and the ability to engage readers with fresh perspectives and unexpected narrative turns.\n",
      "- Consistency: indicates the writer's skill in maintaining relevance to the theme, ensuring that all parts of the writing contribute to and resonate with the central idea, without deviating or diluting the thematic focus.\n",
      "\n",
      "Rate the each story on the three criteria above, using these guidelines:\n",
      "\n",
      "***** Craftsmanship *****\n",
      "Incoherent: Completely lacks structure, clarity, and basic understanding of writing principles.\n",
      "Amateurish: Lacks basic structure and polish.\n",
      "Inexperienced: Shows some understanding but is fundamentally flawed.\n",
      "Developing: Basic skills present but lacking refinement.\n",
      "Competent: Adequate execution with some errors.\n",
      "Skilled: Good quality with minor lapses.\n",
      "Proficient: Strong, consistent quality with few errors.\n",
      "Artistic: Shows flair and style beyond mere technical proficiency.\n",
      "Masterful: Exceptional skill and precision.\n",
      "Brilliant: Outstanding craftsmanship, innovative and flawless.\n",
      "Transcendent: Sets a new standard, impeccable in every aspect.\n",
      "\n",
      "***** Creativity *****\n",
      "Clone: Offers no original thought or perspective; a mere copy of existing works.\n",
      "Unimaginative: Completely derivative and lacking originality.\n",
      "Basic: Few original ideas, mostly predictable.\n",
      "Simple: Shows some originality but largely conventional.\n",
      "Interesting: Regular flashes of creativity.\n",
      "Inventive: Consistently creative and engaging.\n",
      "Inspired: Rich in original ideas and perspectives.\n",
      "Innovative: Breaks new ground, very original.\n",
      "Visionary: Exceptionally creative and forward-thinking.\n",
      "Revolutionary: Radically original, transforming norms.\n",
      "Genius: Redefines the concept of creativity.\n",
      "\n",
      "***** Consistency *****\n",
      "Disconnected: Shows no understanding or recognition of the theme; entirely unrelated.\n",
      "Irrelevant: Fails to address the theme.\n",
      "Off-Topic: Barely touches on the theme.\n",
      "Wandering: Occasionally relevant but often strays.\n",
      "Variable: Inconsistent adherence to the theme.\n",
      "Steady: Generally sticks to the theme with some lapses.\n",
      "Focused: Consistently on-theme with minor deviations.\n",
      "Harmonious: Well-integrated with the theme, showing depth.\n",
      "Unified: Seamlessly blends all elements with the theme.\n",
      "Exemplary: Outstanding representation of the theme.\n",
      "Definitive: The ultimate expression of the theme.\n",
      "\n",
      "Be very hard in your assesment! A skilled writer can hope to obtain 5's for a given criteria.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(systemPrompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = \"\"\"***** Entry *****\n",
    "In the heart of the Old World, where the sun sets in a blaze of crimson and gold, lies the bustling seaport of Port Royal. Its cobblestone streets echo with the cacophony of merchants hawking their wares, sailors singing shanties, and children laughing. But beneath this veneer of merriment, lurks an inescapable truth: this is a town built on the blood of the damned. I am its grim guardian.\n",
    "I, the Hooded Reaper, have borne witness to countless lives claimed by the merciless sea and the even more merciless men who ply her waters. Today, I stand at the precipice of another tale of infamy, as the life of a notorious pirate comes to an end.\n",
    "The sun had barely risen when the shackled figure was led before me. His name was Blackbeard, the terror of the Seven Seas. His legend had grown like a cancer, spreading fear and awe in equal measure. He stood tall and defiant, his eyes burning with the fire of rebellion. But as he looked upon me, he knew his time had come.\n",
    "As the crowd gathered, I could feel the weight of their anticipation. They came to see justice served, to witness the spectacle of a pirate's end. I, too, had grown weary of Blackbeard's reign of terror. Yet, as I prepared to execute him, I couldn't help but feel a pang of sadness. For beneath the fear and the violence, there was a man - a man who had once been a part of this very community.\n",
    "Blackbeard's hands were bound, his beard hidden beneath a thick hood. He looked every inch the pirate king, his eyes filled with a mixture of defiance and resignation. As I approached, he spoke, his voice barely above a whisper.\n",
    "\"Reaper,\" he said, \"I know what you are. I've seen the likes of you before. But I've lived a good life, taken what I wanted, and given as good as I got. I've earned my place in the afterlife.\"\n",
    "I remained silent, my face hidden behind the mask of my hood. I had heard such words before, from men and women who thought they had lived lives worth living. But the law was the law, and there was no room for mercy in its cold, unyielding grasp.\n",
    "As the noose was placed around his neck, Blackbeard's demeanor changed. He closed his eyes, took a deep breath, and spoke one final words.\n",
    "\"Farewell, Reaper. May the sea be kind to you.\"\n",
    "With that, he jumped from the makeshift gallows, the noose tightening around his neck. The crowd gasped in shock, but I knew what was coming. I watched as the life drained from his eyes, his body twitching and convulsing in its final moments. And then, silence.\n",
    "As the sun set over Port Royal, I stood there, the Hooded Reaper, watching as the tide carried Blackbeard's lifeless body away. Another pirate's tale had come to an end, another chapter in the endless saga of the sea written in the blood of the damned. But as I turned to leave, I couldn't help but wonder: would there ever be an end to this cycle of violence and retribution? Or would the sea forever be stained with the blood of those who dared to defy the law?\n",
    "And so, I continue my vigil, the Hooded Reaper, the grim guardian of Port Royal, waiting for the next tale of infamy to unfold. For the sea is a cruel mistress, and her children are a restless, violent lot. But I will be there, ready to mete out justice, no matter the cost.\n",
    "\n",
    "***** Rating *****\n",
    "craftsmanship: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Given Theme *****\n",
      "Imagine what alien communication might be like and create a hypothetical scenario for initial contact.\n",
      "\n",
      "***** Competition Entry *****\n",
      "Title: \"Whispers from the Cosmos: A Symphony of Stars\"\n",
      "In the vast expanse of the cosmos, where stars are born and die in a celestial ballet, a new player entered the stage. A planet, hitherto unknown to us, orbited a star in the constellation of Cygnus. This planet, christened as Kepler-438b, was a veritable gem, with conditions conducive to life.\n",
      "One fateful day, as the sun set on the eastern horizon of our planet, an anomaly occurred. The radio telescopes at SETI (Search for Extraterrestrial Intelligence) Institute picked up a signal. It was unlike anything they had ever encountered before. The signal, pulsating at regular intervals, was not random but seemed to carry a pattern.\n",
      "The scientists were baffled. They worked tirelessly, decoding the signal, trying to make sense of it. Days turned into weeks, and weeks into months. The signal was not a noise; it was a message.\n",
      "The message was a series of complex mathematical equations, interwoven with intricate melodies. It was a language, unlike any human language. The team at SETI, led by Dr. Amelia Hartman, worked tirelessly to decode the message. They discovered that the message contained instructions to build a device, which they named the \"Cosmic Harmonizer.\"\n",
      "The Cosmic Harmonizer was a device that could transmit and receive signals across interstellar distances. It was a marvel of engineering, a testament to the advanced technology of the extraterrestrial beings.\n",
      "Dr. Hartman and her team built the Cosmic Harmonizer, and they sent a response. They transmitted a message, a greeting to the aliens, containing information about Earth and its inhabitants. They also included a recording of Beethoven's \"Moonlight Sonata,\" a piece of music that transcended language and culture.\n",
      "The response was met with silence. But then, a few days later, they received another message. It was a reply, a musical composition, a melody that resonated with the frequencies of the \"Moonlight Sonata.\" It was a beautiful symphony, a conversation starter between two civilizations separated by light-years.\n",
      "The initial contact had been made. The aliens had communicated, not through words, but through music and mathematics. It was a beautiful, harmonious exchange, a testament to the power of communication and the universality of art.\n",
      "From that day forward, humanity and the extraterrestrial beings began a dialogue, a conversation that spanned the cosmos. They shared knowledge, ideas, and cultures. They learned from each other, growing together as one interconnected civilization. And so, the universe sang a new song, a symphony of stars, a testament to the power of communication and the boundless possibilities of the cosmos.\n",
      "\n",
      "***** Rating *****\n",
      "craftsmanship: Skilled, creativity: Interesting, consistency: Focused\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(userExamplePrompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions = (\n",
    "    'Clone',\n",
    "    'Unimaginative',\n",
    "    'Basic',\n",
    "    'Simple',\n",
    "    'Interesting',\n",
    "    'Inventive',\n",
    "    'Inspired',\n",
    "    'Innovative',\n",
    "    'Visionary',\n",
    "    'Revolutionary',\n",
    "    'Genius'\n",
    ")\n",
    "\n",
    "prior = (\n",
    "    1 / 11,\n",
    "    1 / 11,\n",
    "    1 / 11,\n",
    "    1 / 11,\n",
    "    1 / 11,\n",
    "    1 / 11,\n",
    "    1 / 11,\n",
    "    1 / 11,\n",
    "    1 / 11,\n",
    "    1 / 11,\n",
    "    1 / 11,\n",
    ")\n",
    "\n",
    "# pred_probs = predict_proba(systemPrompt+userExamplePrompt, completions, (model,tokenizer) )\n",
    "\n",
    "# print(pred_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 47.56 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 765.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# pred = predict(prompt, completions, model_and_tokenizer=(model, tokenizer))\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pred_probs \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43msystemPrompt\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mentry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred_probs)\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/utils/classify.py:420\u001b[0m, in \u001b[0;36m_predict_proba.<locals>.wrapper\u001b[0;34m(prompts, completions, *args, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_marg_probs_completions is set, but they will not be used \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbecause discount_completions was not set.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m     )\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# Do the expensive model calls\u001b[39;00m\n\u001b[0;32m--> 420\u001b[0m log_probs_completions \u001b[38;5;241m=\u001b[39m \u001b[43mlog_probs_conditional\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m is_single_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(prompts, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    426\u001b[0m \u001b[38;5;66;03m# Maybe apply discount\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/huggingface/classify.py:1122\u001b[0m, in \u001b[0;36mpredict_proba\u001b[0;34m(prompts, completions, model_and_tokenizer, prior, end_of_prompt, normalize, discount_completions, log_marg_probs_completions, show_progress_bar, batch_size, batch_size_completions)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;129m@classify\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_proba\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\n\u001b[1;32m   1008\u001b[0m     prompts: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m Sequence[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     batch_size_completions: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1019\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mfloating]:\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;124;03m    Predict probabilities of each completion coming after each prompt.\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;124;03m        # 0.4\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlog_probs_conditional\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/utils/classify.py:316\u001b[0m, in \u001b[0;36m_log_probs_conditional.<locals>.wrapper\u001b[0;34m(prompts, completions, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m _check\u001b[38;5;241m.\u001b[39mcompletions(completions)\n\u001b[1;32m    315\u001b[0m _check\u001b[38;5;241m.\u001b[39mend_of_prompt(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_of_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrap_call_unwrap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_probs_conditional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/utils/classify.py:280\u001b[0m, in \u001b[0;36m_wrap_call_unwrap\u001b[0;34m(type_indicating_singleness, func, input, *args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m is_single_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, type_indicating_singleness)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28minput\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m is_single_input \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m--> 280\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m is_single_input \u001b[38;5;28;01melse\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/huggingface/classify.py:889\u001b[0m, in \u001b[0;36mlog_probs_conditional\u001b[0;34m(prompts, completions, model_and_tokenizer, end_of_prompt, show_progress_bar, batch_size, batch_size_completions, **kwargs)\u001b[0m\n\u001b[1;32m    880\u001b[0m     logits, encodings \u001b[38;5;241m=\u001b[39m _logits_completions_given_prompts(\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;241m*\u001b[39mmodel_and_tokenizer,\n\u001b[1;32m    882\u001b[0m         prompts,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    885\u001b[0m         batch_size_completions\u001b[38;5;241m=\u001b[39mbatch_size_completions,\n\u001b[1;32m    886\u001b[0m     )\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _logits_to_log_probs_completions(logits, encodings, from_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 889\u001b[0m log_probs_completions \u001b[38;5;241m=\u001b[39m \u001b[43mlog_probs_completions_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_batch\u001b[38;5;241m.\u001b[39mconstant(log_probs_completions, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(completions)))\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/utils/_batch.py:147\u001b[0m, in \u001b[0;36mflatten.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(batchified_func)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 147\u001b[0m     nested_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mbatchified_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [output \u001b[38;5;28;01mfor\u001b[39;00m inner_outputs \u001b[38;5;129;01min\u001b[39;00m nested_outputs \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m inner_outputs]\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/utils/_batch.py:131\u001b[0m, in \u001b[0;36mbatchify.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_ \u001b[38;5;129;01min\u001b[39;00m constant(batchable, batch_size):\n\u001b[1;32m    130\u001b[0m         args[batchable_arg_idx] \u001b[38;5;241m=\u001b[39m batch_\n\u001b[0;32m--> 131\u001b[0m         outputs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    132\u001b[0m         progress_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(batch_))\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/huggingface/classify.py:880\u001b[0m, in \u001b[0;36mlog_probs_conditional.<locals>.log_probs_completions_batch\u001b[0;34m(prompts, show_progress_bar, batch_size)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;129m@_batch\u001b[39m\u001b[38;5;241m.\u001b[39mflatten\n\u001b[1;32m    876\u001b[0m \u001b[38;5;129m@_batch\u001b[39m\u001b[38;5;241m.\u001b[39mbatchify(batchable_arg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompts\u001b[39m\u001b[38;5;124m\"\u001b[39m, progress_bar_desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconditional log-probs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_probs_completions_batch\u001b[39m(\n\u001b[1;32m    878\u001b[0m     prompts, show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar, batch_size\u001b[38;5;241m=\u001b[39mbatch_size\n\u001b[1;32m    879\u001b[0m ):\n\u001b[0;32m--> 880\u001b[0m     logits, encodings \u001b[38;5;241m=\u001b[39m \u001b[43m_logits_completions_given_prompts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_and_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend_of_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_of_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size_completions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size_completions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _logits_to_log_probs_completions(logits, encodings, from_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/huggingface/classify.py:707\u001b[0m, in \u001b[0;36m_logits_completions_given_prompts\u001b[0;34m(model, tokenizer, prompts, completions, end_of_prompt, batch_size_completions)\u001b[0m\n\u001b[1;32m    705\u001b[0m     end_of_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    706\u001b[0m completions \u001b[38;5;241m=\u001b[39m [end_of_prompt \u001b[38;5;241m+\u001b[39m completion \u001b[38;5;28;01mfor\u001b[39;00m completion \u001b[38;5;129;01min\u001b[39;00m completions]\n\u001b[0;32m--> 707\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_blessed_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_completions_per_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompletions_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size_completions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size_completions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/huggingface/classify.py:661\u001b[0m, in \u001b[0;36m_blessed_helper\u001b[0;34m(model, tokenizer, prompts, completions, num_completions_per_prompt, completions_repeats, batch_size_completions)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m    660\u001b[0m     cached_prompts_model\u001b[38;5;241m.\u001b[39m_cappr\u001b[38;5;241m.\u001b[39mbatch_idxs \u001b[38;5;241m=\u001b[39m prompts_idxs[batch_idx]\n\u001b[0;32m--> 661\u001b[0m     out: CausalLMOutput \u001b[38;5;241m=\u001b[39m \u001b[43mcached_prompts_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompletions_input_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompletions_attention_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;66;03m# B/c logits_all=False, out.logits only has completion token logits\u001b[39;00m\n\u001b[1;32m    666\u001b[0m     completions_logits\u001b[38;5;241m.\u001b[39mappend(out\u001b[38;5;241m.\u001b[39mlogits)\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/huggingface/classify.py:313\u001b[0m, in \u001b[0;36m_ModelWithCache.__call__\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28mself\u001b[39m, input_ids: torch\u001b[38;5;241m.\u001b[39mTensor, attention_mask: torch\u001b[38;5;241m.\u001b[39mTensor\n\u001b[1;32m    312\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CausalLMOutputWithPast:\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/cappr/huggingface/classify.py:290\u001b[0m, in \u001b[0;36m_ModelWithCache.forward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m    284\u001b[0m position_ids_present \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    285\u001b[0m     torch\u001b[38;5;241m.\u001b[39marange(input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cappr\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;241m+\u001b[39m offsets[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    287\u001b[0m )\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m hf\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39mset_up_model(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cappr\u001b[38;5;241m.\u001b[39mmodel):\n\u001b[0;32m--> 290\u001b[0m     out: CausalLMOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cappr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask_past_cat_present\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids_present\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;66;03m# past_key_values is already concatenated in out.past_key_values\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cappr\u001b[38;5;241m.\u001b[39mlogits_all:\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1181\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1178\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1181\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1068\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1059\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1060\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1065\u001b[0m         use_cache,\n\u001b[1;32m   1066\u001b[0m     )\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1068\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1077\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:796\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    793\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    795\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 796\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:708\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    707\u001b[0m     cache_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msin\u001b[39m\u001b[38;5;124m\"\u001b[39m: sin, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos\u001b[39m\u001b[38;5;124m\"\u001b[39m: cos}  \u001b[38;5;66;03m# Specific to RoPE models\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m     key_states, value_states \u001b[38;5;241m=\u001b[39m \u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    710\u001b[0m key_states \u001b[38;5;241m=\u001b[39m repeat_kv(key_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_groups)\n\u001b[1;32m    711\u001b[0m value_states \u001b[38;5;241m=\u001b[39m repeat_kv(value_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_groups)\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/transformers/cache_utils.py:128\u001b[0m, in \u001b[0;36mDynamicCache.update\u001b[0;34m(self, key_states, value_states, layer_idx, cache_kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_cache[layer_idx] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_cache[layer_idx], key_states], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_cache[layer_idx] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_cache[layer_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_cache[layer_idx]\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 47.56 MiB is free. Including non-PyTorch memory, this process has 23.59 GiB memory in use. Of the allocated memory 22.39 GiB is allocated by PyTorch, and 765.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# pred = predict(prompt, completions, model_and_tokenizer=(model, tokenizer))\n",
    "pred_probs = predict_proba(systemPrompt+ entry, completions, (model,tokenizer) )\n",
    "\n",
    "print(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert teacher and editor with profound experience in rating prose.\n",
      "For the competition, participants were given a theme to write about. This is a competition for the world's best writer!  You will receive an text fragment, and must grade the text based on these three criteria:\n",
      "- Craftsmanship: focuses on the writer's skill in structuring sentences, paragraphs, and stylistic precision.\n",
      "- Creativity: encompasses the writer's flair for innovation, the use of vivid and original imagery, and the ability to engage readers with fresh perspectives and unexpected narrative turns.\n",
      "- Consistency: indicates the writer's skill in maintaining relevance to the theme, ensuring that all parts of the writing contribute to and resonate with the central idea, without deviating or diluting the thematic focus.\n",
      "\n",
      "Rate the each story on the three criteria above, using these guidelines:\n",
      "\n",
      "***** Craftsmanship *****\n",
      "Incoherent: Completely lacks structure, clarity, and basic understanding of writing principles.\n",
      "Amateurish: Lacks basic structure and polish.\n",
      "Inexperienced: Shows some understanding but is fundamentally flawed.\n",
      "Developing: Basic skills present but lacking refinement.\n",
      "Competent: Adequate execution with some errors.\n",
      "Skilled: Good quality with minor lapses.\n",
      "Proficient: Strong, consistent quality with few errors.\n",
      "Artistic: Shows flair and style beyond mere technical proficiency.\n",
      "Masterful: Exceptional skill and precision.\n",
      "Brilliant: Outstanding craftsmanship, innovative and flawless.\n",
      "Transcendent: Sets a new standard, impeccable in every aspect.\n",
      "\n",
      "***** Creativity *****\n",
      "Clone: Offers no original thought or perspective; a mere copy of existing works.\n",
      "Unimaginative: Completely derivative and lacking originality.\n",
      "Basic: Few original ideas, mostly predictable.\n",
      "Simple: Shows some originality but largely conventional.\n",
      "Interesting: Regular flashes of creativity.\n",
      "Inventive: Consistently creative and engaging.\n",
      "Inspired: Rich in original ideas and perspectives.\n",
      "Innovative: Breaks new ground, very original.\n",
      "Visionary: Exceptionally creative and forward-thinking.\n",
      "Revolutionary: Radically original, transforming norms.\n",
      "Genius: Redefines the concept of creativity.\n",
      "\n",
      "***** Consistency *****\n",
      "Disconnected: Shows no understanding or recognition of the theme; entirely unrelated.\n",
      "Irrelevant: Fails to address the theme.\n",
      "Off-Topic: Barely touches on the theme.\n",
      "Wandering: Occasionally relevant but often strays.\n",
      "Variable: Inconsistent adherence to the theme.\n",
      "Steady: Generally sticks to the theme with some lapses.\n",
      "Focused: Consistently on-theme with minor deviations.\n",
      "Harmonious: Well-integrated with the theme, showing depth.\n",
      "Unified: Seamlessly blends all elements with the theme.\n",
      "Exemplary: Outstanding representation of the theme.\n",
      "Definitive: The ultimate expression of the theme.\n",
      "\n",
      "Be very hard in your assesment! A skilled writer can hope to obtain 5's for a given criteria.\n",
      "\n",
      "***** Given Theme *****\n",
      "Imagine what alien communication might be like and create a hypothetical scenario for initial contact.\n",
      "\n",
      "***** Competition Entry *****\n",
      "Title: \"Whispers from the Cosmos: A Symphony of Stars\"\n",
      "In the vast expanse of the cosmos, where stars are born and die in a celestial ballet, a new player entered the stage. A planet, hitherto unknown to us, orbited a star in the constellation of Cygnus. This planet, christened as Kepler-438b, was a veritable gem, with conditions conducive to life.\n",
      "One fateful day, as the sun set on the eastern horizon of our planet, an anomaly occurred. The radio telescopes at SETI (Search for Extraterrestrial Intelligence) Institute picked up a signal. It was unlike anything they had ever encountered before. The signal, pulsating at regular intervals, was not random but seemed to carry a pattern.\n",
      "The scientists were baffled. They worked tirelessly, decoding the signal, trying to make sense of it. Days turned into weeks, and weeks into months. The signal was not a noise; it was a message.\n",
      "The message was a series of complex mathematical equations, interwoven with intricate melodies. It was a language, unlike any human language. The team at SETI, led by Dr. Amelia Hartman, worked tirelessly to decode the message. They discovered that the message contained instructions to build a device, which they named the \"Cosmic Harmonizer.\"\n",
      "The Cosmic Harmonizer was a device that could transmit and receive signals across interstellar distances. It was a marvel of engineering, a testament to the advanced technology of the extraterrestrial beings.\n",
      "Dr. Hartman and her team built the Cosmic Harmonizer, and they sent a response. They transmitted a message, a greeting to the aliens, containing information about Earth and its inhabitants. They also included a recording of Beethoven's \"Moonlight Sonata,\" a piece of music that transcended language and culture.\n",
      "The response was met with silence. But then, a few days later, they received another message. It was a reply, a musical composition, a melody that resonated with the frequencies of the \"Moonlight Sonata.\" It was a beautiful symphony, a conversation starter between two civilizations separated by light-years.\n",
      "The initial contact had been made. The aliens had communicated, not through words, but through music and mathematics. It was a beautiful, harmonious exchange, a testament to the power of communication and the universality of art.\n",
      "From that day forward, humanity and the extraterrestrial beings began a dialogue, a conversation that spanned the cosmos. They shared knowledge, ideas, and cultures. They learned from each other, growing together as one interconnected civilization. And so, the universe sang a new song, a symphony of stars, a testament to the power of communication and the boundless possibilities of the cosmos.\n",
      "\n",
      "***** Rating *****\n",
      "craftsmanship:Skilled, creativity:Interesting, consistency:Focused\n",
      "***** Entry *****\n",
      "In the heart of the Old World, where the sun sets in a blaze of crimson and gold, lies the bustling seaport of Port Royal. Its cobblestone streets echo with the cacophony of merchants hawking their wares, sailors singing shanties, and children laughing. But beneath this veneer of merriment, lurks an inescapable truth: this is a town built on the blood of the damned. I am its grim guardian.\n",
      "\n",
      "I, the Hooded Reaper, have borne witness to countless lives claimed by the merciless sea and the even more merciless men who ply her waters. Today, I stand at the precipice of another tale of infamy, as the life of a notorious pirate comes to an end.\n",
      "\n",
      "The sun had barely risen when the shackled figure was led before me. His name was Blackbeard, the terror of the Seven Seas. His legend had grown like a cancer, spreading fear and awe in equal measure. He stood tall and defiant, his eyes burning with the fire of rebellion. But as he looked upon me, he knew his time had come.\n",
      "\n",
      "As the crowd gathered, I could feel the weight of their anticipation. They came to see justice served, to witness the spectacle of a pirate's end. I, too, had grown weary of Blackbeard's reign of terror. Yet, as I prepared to execute him, I couldn't help but feel a pang of sadness. For beneath the fear and the violence, there was a man - a man who had once been a part of this very community.\n",
      "\n",
      "Blackbeard's hands were bound, his beard hidden beneath a thick hood. He looked every inch the pirate king, his eyes filled with a mixture of defiance and resignation. As I approached, he spoke, his voice barely above a whisper.\n",
      "\n",
      "\"Reaper,\" he said, \"I know what you are. I've seen the likes of you before. But I've lived a good life, taken what I wanted, and given as good as I got. I've earned my place in the afterlife.\"\n",
      "\n",
      "I remained silent, my face hidden behind the mask of my hood. I had heard such words before, from men and women who thought they had lived lives worth living. But the law was the law, and there was no room for mercy in its cold, unyielding grasp.\n",
      "\n",
      "As the noose was placed around his neck, Blackbeard's demeanor changed. He closed his eyes, took a deep breath, and spoke one final words.\n",
      "\n",
      "\"Farewell, Reaper. May the sea be kind to you.\"\n",
      "\n",
      "With that, he jumped from the makeshift gallows, the noose tightening around his neck. The crowd gasped in shock, but I knew what was coming. I watched as the life drained from his eyes, his body twitching and convulsing in its final moments. And then, silence.\n",
      "\n",
      "As the sun set over Port Royal, I stood there, the Hooded Reaper, watching as the tide carried Blackbeard's lifeless body away. Another pirate's tale had come to an end, another chapter in the endless saga of the sea written in the blood of the damned. But as I turned to leave, I couldn't help but wonder: would there ever be an end to this cycle of violence and retribution? Or would the sea forever be stained with the blood of those who dared to defy the law?\n",
      "\n",
      "And so, I continue my vigil, the Hooded Reaper, the grim guardian of Port Royal, waiting for the next tale of infamy to unfold. For the sea is a cruel mistress, and her children are a restless, violent lot. But I will be there, ready to mete out justice, no matter the cost.\n",
      "\n",
      "***** Rating *****\n",
      "craftsmanship: \n"
     ]
    }
   ],
   "source": [
    "print(systemPrompt + userExamplePrompt +entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "import enum\n",
    "\n",
    "\n",
    "\n",
    "# the ratings are on a scale of 0-10, with 0 being the worst and 10 being the best\n",
    "craftsmanshipDict = {\n",
    "    \"Incoherent\": \"Completely lacks structure, clarity, and basic understanding of writing principles.\",\n",
    "    \"Amateurish\": \"Lacks basic structure and polish.\",\n",
    "    \"Inexperienced\": \"Shows some understanding but is fundamentally flawed.\",\n",
    "    \"Developing\": \"Basic skills present but lacking refinement.\",\n",
    "    \"Competent\": \"Adequate execution with some errors.\",\n",
    "    \"Skilled\": \"Good quality with minor lapses.\",\n",
    "    \"Proficient\": \"Strong, consistent quality with few errors.\",\n",
    "    \"Artistic\": \"Shows flair and style beyond mere technical proficiency.\",\n",
    "    \"Masterful\": \"Exceptional skill and precision.\",\n",
    "    \"Brilliant\": \"Outstanding craftsmanship, innovative and flawless.\",\n",
    "    \"Transcendent\": \"Sets a new standard, impeccable in every aspect.\",\n",
    "}\n",
    "\n",
    "creativityDict = {\n",
    "    \"Clone\": \"Offers no original thought or perspective; a mere copy of existing works.\",\n",
    "    \"Unimaginative\": \"Completely derivative and lacking originality.\",\n",
    "    \"Basic\": \"Few original ideas, mostly predictable.\",\n",
    "    \"Simple\": \"Shows some originality but largely conventional.\",\n",
    "    \"Interesting\": \"Regular flashes of creativity.\",\n",
    "    \"Inventive\": \"Consistently creative and engaging.\",\n",
    "    \"Inspired\": \"Rich in original ideas and perspectives.\",\n",
    "    \"Innovative\": \"Breaks new ground, very original.\",\n",
    "    \"Visionary\": \"Exceptionally creative and forward-thinking.\",\n",
    "    \"Revolutionary\": \"Radically original, transforming norms.\",\n",
    "    \"Genius\": \"Redefines the concept of creativity.\",\n",
    "}\n",
    "\n",
    "consistencyDict = {\n",
    "    \"Disconnected\": \"Shows no understanding or recognition of the theme; entirely unrelated.\",\n",
    "    \"Irrelevant\": \"Fails to address the theme.\",\n",
    "    \"Off-Topic\": \"Barely touches on the theme.\",\n",
    "    \"Wandering\": \"Occasionally relevant but often strays.\",\n",
    "    \"Variable\": \"Inconsistent adherence to the theme.\",\n",
    "    \"Steady\": \"Generally sticks to the theme with some lapses.\",\n",
    "    \"Focused\": \"Consistently on-theme with minor deviations.\",\n",
    "    \"Harmonious\": \"Well-integrated with the theme, showing depth.\",\n",
    "    \"Unified\": \"Seamlessly blends all elements with the theme.\",\n",
    "    \"Exemplary\": \"Outstanding representation of the theme.\",\n",
    "    \"Definitive\": \"The ultimate expression of the theme.\",\n",
    "}\n",
    "\n",
    "class Review(BaseModel):\n",
    "    craftsmanship: enum.IntEnum(\n",
    "        \"Craftsmanship\", {key: i for i, key in enumerate(craftsmanshipDict)}\n",
    "    )\n",
    "    creativity: enum.IntEnum(\n",
    "        \"Creativity\", {key: i for i, key in enumerate(creativityDict)}\n",
    "    )\n",
    "    consistency: enum.IntEnum(\n",
    "        \"Consistency\", {key: i for i, key in enumerate(consistencyDict)}\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<class '__main__.Review'> cannot be parametrized because it does not inherit from typing.Generic",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mReview\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCraftsmanship\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/frankenmerge/lib/python3.10/site-packages/pydantic/main.py:634\u001b[0m, in \u001b[0;36mBaseModel.__class_getitem__\u001b[0;34m(cls, typevar_values)\u001b[0m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType parameters should be placed on typing.Generic, not BaseModel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__parameters__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be parametrized because it does not inherit from typing.Generic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_generic_metadata__[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m typing\u001b[38;5;241m.\u001b[39mGeneric \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__bases__\u001b[39m:\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a generic class\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: <class '__main__.Review'> cannot be parametrized because it does not inherit from typing.Generic"
     ]
    }
   ],
   "source": [
    "Review['Craftsmanship']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Disconnected': 0,\n",
       " 'Irrelevant': 1,\n",
       " 'Off-Topic': 2,\n",
       " 'Wandering': 3,\n",
       " 'Variable': 4,\n",
       " 'Steady': 5,\n",
       " 'Focused': 6,\n",
       " 'Harmonious': 7,\n",
       " 'Unified': 8,\n",
       " 'Exemplary': 9,\n",
       " 'Definitive': 10}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key: i for i, key in enumerate(consistencyDict)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "formattedConsistencyDict = \"\\n\".join(\n",
    "    [f\"{key} = {i}: {value}\" for i, (key, value) in enumerate(consistencyDict.items())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Disconnected = 0: Shows no understanding or recognition of the theme; entirely unrelated.\\nIrrelevant = 1: Fails to address the theme.\\nOff-Topic = 2: Barely touches on the theme.\\nWandering = 3: Occasionally relevant but often strays.\\nVariable = 4: Inconsistent adherence to the theme.\\nSteady = 5: Generally sticks to the theme with some lapses.\\nFocused = 6: Consistently on-theme with minor deviations.\\nHarmonious = 7: Well-integrated with the theme, showing depth.\\nUnified = 8: Seamlessly blends all elements with the theme.\\nExemplary = 9: Outstanding representation of the theme.\\nDefinitive = 10: The ultimate expression of the theme.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formattedConsistencyDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i: i for i, key in enumerate(craftsmanshipDict)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Incoherent': 0,\n",
       " 'Amateurish': 1,\n",
       " 'Inexperienced': 2,\n",
       " 'Developing': 3,\n",
       " 'Competent': 4,\n",
       " 'Skilled': 5,\n",
       " 'Proficient': 6,\n",
       " 'Artistic': 7,\n",
       " 'Masterful': 8,\n",
       " 'Brilliant': 9,\n",
       " 'Transcendent': 10}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key: i for i, key in enumerate(craftsmanshipDict)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frankenmerge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
